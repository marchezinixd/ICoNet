{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Input, Dense, merge,Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10000\n",
    "X = np.random.randn(4,size)\n",
    "X2 = np.random.randn(4,size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = [1]*int(size/3) + [3]*int(size/3) + [5]*int(size/3) + [1.5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro definimos as variáveis utilizadas:\n",
    "\n",
    "X0, X1, X2, X3 variáveis aleatórias geradas por uma distribuição normal\n",
    "\n",
    "X4 Variável em que 1/3 os valores são -1, 1/3 são 0 e 1/3 são 1\n",
    "\n",
    "\n",
    "Depois definimos a função para o Y dada por:\n",
    "\n",
    "Y = X0 * X1 + X2 * X3 + X1 * X3 + X4 * X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X[0]*X[1]+X[2]*X[3]+X[1]*X[3] + X4*((X[1])-X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y2 = X2[0]+X2[1]+X2[2]+X2[3]+X2[0]*X2[1] + X4*((X2[1])-X2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(np.transpose(X),columns= ['X0','X1','X2', 'X3'])\n",
    "X2 = pd.DataFrame(np.transpose(X2),columns= ['X0','X1','X2', 'X3'])\n",
    "X['X4'] = X4\n",
    "X2['X4'] = X4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos os dados em treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/pandas/core/frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "x4_train = X_train['X4']\n",
    "X_train.drop('X4',axis=1,inplace=True)\n",
    "x4_test = X_test['X4']\n",
    "X_test.drop('X4',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "     X2, Y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = pd.DataFrame(np.transpose([y_train, y2_train]), columns = ['y1','y2'])\n",
    "ys_test =  pd.DataFrame(np.transpose([y_test, y2_test]), columns = ['y1','y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x42_train = X2_train['X4']\n",
    "X2_train.drop('X4',axis=1,inplace=True)\n",
    "x42_test = X2_test['X4']\n",
    "X2_test.drop('X4',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamos um modelo de rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50),activation='relu',max_iter=1000, verbose=1,n_iter_no_change = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 10.83718857\n",
      "Iteration 2, loss = 3.86792843\n",
      "Iteration 3, loss = 2.86249210\n",
      "Iteration 4, loss = 2.77087292\n",
      "Iteration 5, loss = 2.76781721\n",
      "Iteration 6, loss = 2.74991989\n",
      "Iteration 7, loss = 2.70765249\n",
      "Iteration 8, loss = 2.68569266\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo o R² de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7957101379657049"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o R² de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941396080681464"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_pred_mae(X_train, value):\n",
    "    x_a = X_train.copy()#drop(['error','y'],axis=1).copy()\n",
    "    x_a['X1'] = x_a['X1'] + value\n",
    "    c1 = x_a['X0']*x_a['X1']+x_a['X2']*x_a['X3']+x_a['X1']*x_a['X3'] + x4_train*((x_a['X1'])-x_a['X2'])\n",
    "    cp = model.predict(x_a)\n",
    "    print(mean_absolute_error(cp, c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6002515444544425\n",
      "1.597771418378902\n"
     ]
    }
   ],
   "source": [
    "print_simple_pred_mae(X_train, 0.3)\n",
    "print_simple_pred_mae(X_train, -0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5618165832028463\n",
      "1.563546673789024\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_train_pred,y_train))\n",
    "print(mean_absolute_error(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74709043645146"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos o erro de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_error =   y_pred -y_test\n",
    "train_error = y_train - y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X_train['error'] = train_error\n",
    "X_test['error'] = model_error\n",
    "X_train['y'] = y_train\n",
    "X_test['y'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50),activation='relu',max_iter=1000,verbose=1,n_iter_no_change = 30,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.31125027\n",
      "Iteration 2, loss = 2.75450957\n",
      "Iteration 3, loss = 2.73692985\n",
      "Iteration 4, loss = 2.73073599\n",
      "Iteration 5, loss = 2.72763062\n",
      "Iteration 6, loss = 2.71821627\n",
      "Iteration 7, loss = 2.72731451\n",
      "Iteration 8, loss = 2.72244366\n",
      "Iteration 9, loss = 2.71646672\n",
      "Iteration 10, loss = 2.71681939\n",
      "Iteration 11, loss = 2.70499164\n",
      "Iteration 12, loss = 2.70190209\n",
      "Iteration 13, loss = 2.70338777\n",
      "Iteration 14, loss = 2.70818512\n",
      "Iteration 15, loss = 2.70514729\n",
      "Iteration 16, loss = 2.70373449\n",
      "Iteration 17, loss = 2.70267264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/envs/tf36/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size=128, beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(50, 50, 50, 50, 50), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "             momentum=0.9, n_iter_no_change=30, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtendo o R² de treino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8106932987479856"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(X2_train,y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E o R² de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112253847985506"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(X2_test,y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07678687, 16.16609737, -1.49484458, ..., -7.92560256,\n",
       "        2.97335431, -7.12707131])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X2_train['X1'] = X2_train['X1'] + 1\n",
    "c2 = X2_train['X0']+X2_train['X1']+X2_train['X2']+X2_train['X3']+X2_train['X0']*X2_train['X1'] + x4_train*((X2_train['X1'])-X2_train['X2'])\n",
    "cp2 = model.predict(X2_train)\n",
    "mean_absolute_error(cp2, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = model.predict(X2_test)\n",
    "y2_train_pred = model.predict(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5847652578333733\n",
      "2.5804741893795393\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y2_train_pred,y2_train))\n",
    "print(mean_absolute_error(y2_pred,y2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos o erro de predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_simple_pred_mae2(X2_train, value):\n",
    "    x2_a = X2_train.copy()#.drop(['error','y'],axis=1).copy()\n",
    "    x2_a['X1'] = x2_a['X1'] + value\n",
    "    c2 = x2_a['X0']+x2_a['X1']+x2_a['X2']+x2_a['X3']+x2_a['X0']*x2_a['X1'] + x4_train*((x2_a['X1'])-x2_a['X2'])\n",
    "    c2p = model2.predict(x2_a)\n",
    "    print(mean_absolute_error(c2p, c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_simple_pred_mae2(X2_train, 0.3)\n",
    "print_simple_pred_mae2(X2_train, -0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_error =   y2_pred -y2_test\n",
    "train2_error = y2_train - y2_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train['error'] = train2_error\n",
    "X2_test['error'] = model2_error\n",
    "X2_train['y'] = y2_train\n",
    "X2_test['y'] = y2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X_train.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X_test.merge(X2_test,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_outs_train = df_encoder_train[['y_y','y_x']]\n",
    "df_outs_test = df_encoder_test[['y_y','y_x']]\n",
    "df_features_train = df_encoder_train.drop(['error_x','error_y','y_y','y_x'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error_x','error_y','y_y','y_x'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "input_dim2 = Input(shape = (ncol - 4, ))\n",
    "# Encoder Layers\n",
    "encoded1 = Dense(10, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(8, activation = 'relu')(encoded1)\n",
    "encoded3 = Dense(5, activation = 'relu')(encoded2)\n",
    "encoded4 = Dense(3, activation = 'relu')(encoded3)\n",
    "encoded5 = Dense(1, activation = 'relu')(encoded4)\n",
    "encoded13 = Dense(encoding_dim, activation = 'linear')(encoded5)\n",
    "merged = keras.layers.concatenate([encoded13, input_dim2], axis=-1)\n",
    "# Decoder Layers\n",
    "decoded1 = Dense(30, activation = 'tanh')(merged)\n",
    "drop1 = Dropout(0.2)(decoded1)\n",
    "decoded2 = Dense(40, activation = 'tanh')(drop1)\n",
    "decoded3 = Dense(50, activation = 'tanh')(decoded2)\n",
    "decoded4 = Dense(40, activation = 'tanh')(decoded3)\n",
    "decoded5 = Dense(30, activation = 'tanh')(decoded4)\n",
    "decoded13 = Dense(2, activation = 'linear')(decoded5)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder = Model(inputs = [input_dim, input_dim2], outputs = [decoded13])\n",
    "sgd = optimizers.SGD(lr=0.1, decay=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile the Model\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                              min_delta=0,\n",
    "                              patience=800,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=False)\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "autoencoder.fit(x = [df_encoder_train, df_features_train], y = df_outs_train, epochs = 1000, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                \n",
    "               callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))\n",
    "encoded_train = pd.DataFrame(encoder.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_absolute_error(encoded_train['feature_0'], df_outs_train['y_y']))\n",
    "print(mean_absolute_error(encoded_train['feature_1'], df_outs_train['y_x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(encoded_train['feature_0'], df_outs_train['y_y']))\n",
    "print(r2_score(encoded_train['feature_1'], df_outs_train['y_x']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_and_check(df_features_train_ori,feat,modifier):\n",
    "    df_features_train = df_features_train_ori.copy()\n",
    "    df_features_train[feat] = df_features_train[feat] + modifier\n",
    "    encoded_train = pd.DataFrame(encoder.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    X_t = df_features_train\n",
    "    contra = X_t['X0_x']*X_t['X1_x']+X_t['X2_x']*X_t['X3_x']+X_t['X1_x']*X_t['X3_x'] + x4_train*((X_t['X1_x'])-X_t['X2_x'])\n",
    "    contra2 = X_t['X0_y']+X_t['X1_y']+X_t['X2_y']+X_t['X3_y']+X_t['X0_y']*X_t['X1_y'] + x4_train*((X_t['X1_y'])-X_t['X2_y'])\n",
    "    if feat[-1]=='x':\n",
    "        print('MAE C1: ' + str(mean_absolute_error(encoded_train['feature_1'], contra)))\n",
    "        print('R2 C1: ' + str(r2_score(contra, encoded_train['feature_1'])))\n",
    "    if feat[-1]=='y':\n",
    "        print('MAE C2: ' + str(mean_absolute_error( encoded_train['feature_0'],contra2)))\n",
    "        print('R2 C2: ' + str(r2_score(contra2, encoded_train['feature_0'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_and_check(df_features_train,'X0_x',1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_and_check(df_features_train,'X1_y',+0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_and_check(df_features_train,'X1_x',-0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_and_check(df_features_train,'X1_x',+0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ys_train.iloc[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_absolute_error(contra, encoded_train['feature_3'])\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpe_sum = 0\n",
    "for real, prediction in zip(contra, encoded_train['feature_3']):\n",
    "    mpe_sum += ((real - prediction)/real)\n",
    "mpe = mpe_sum/len(contra)\n",
    "print(mpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse / np.mean(contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse / np.std(contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(contra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X_train.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X_test.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['error_x','error_y','y_y','y_x']]\n",
    "df_outs_test = df_encoder_test[['error_x','error_y','y_y','y_x']]\n",
    "df_features_train = df_encoder_train.drop(['error_x','error_y','y_y','y_x'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error_x','error_y','y_y','y_x'], axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf36]",
   "language": "python",
   "name": "conda-env-tf36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
