{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./test_tables/BD_Demographics_Database_BSI_WhoQol.csv', sep = ',',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['database', 'sex', 'age_months', 'age_years', 'education',\n",
       "       'marital_status', 'ethnicity', 'cceb_class', 'BSI_1', 'BSI_2', 'BSI_3',\n",
       "       'BSI_4', 'BSI_5', 'BSI_6', 'BSI_7', 'BSI_8', 'BSI_9', 'BSI_10',\n",
       "       'BSI_11', 'BSI_12', 'BSI_13', 'BSI_14', 'BSI_15', 'BSI_16', 'BSI_17',\n",
       "       'BSI_18', 'BSI_19', 'BSI_20', 'BSI_21', 'BSI_22', 'BSI_23', 'BSI_24',\n",
       "       'BSI_25', 'BSI_26', 'BSI_27', 'BSI_28', 'BSI_29', 'BSI_30', 'BSI_31',\n",
       "       'BSI_32', 'BSI_33', 'BSI_34', 'BSI_35', 'BSI_36', 'BSI_37', 'BSI_38',\n",
       "       'BSI_39', 'BSI_40', 'BSI_41', 'BSI_42', 'BSI_43', 'BSI_44', 'BSI_45',\n",
       "       'BSI_46', 'BSI_47', 'BSI_48', 'BSI_49', 'BSI_50', 'BSI_51', 'BSI_52',\n",
       "       'BSI_53', 'WHOQoL_1', 'WHOQoL_2', 'WHOQoL_3', 'WHOQoL_4', 'WHOQoL_5',\n",
       "       'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_8', 'WHOQoL_9', 'WHOQoL_10',\n",
       "       'WHOQoL_11', 'WHOQoL_12', 'WHOQoL_14', 'WHOQoL_15', 'WHOQoL_16',\n",
       "       'WHOQoL_17', 'WHOQoL_18', 'WHOQoL_19', 'WHOQoL_20', 'WHOQoL_21',\n",
       "       'WHOQoL_22', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', 'WHOQoL_26',\n",
       "       'BSI_GSI_EB', 'BSI_Somatization_EB', 'BSI_ObsCom_EB', 'BSI_IntSens_EB',\n",
       "       'BSI_Depression_EB', 'BSI_Anxiety_EB', 'BSI_Hostility_EB',\n",
       "       'BSI_Phobic_EB', 'BSI_Paranoid_EB', 'BSI_Psychoticism_EB',\n",
       "       'WQOL.Fisico', 'WQOL.Psicologico', 'WQOL.RSociais', 'WQOL_MAmbiente'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = 23489\n",
    "idn2 = 70776\n",
    "idn3 = 52594\n",
    "idn4 = 24047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database',\n",
       " 'sex',\n",
       " 'age_months',\n",
       " 'age_years',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'ethnicity',\n",
       " 'cceb_class',\n",
       " 'BSI_1',\n",
       " 'BSI_2',\n",
       " 'BSI_3',\n",
       " 'BSI_4',\n",
       " 'BSI_5',\n",
       " 'BSI_6',\n",
       " 'BSI_7',\n",
       " 'BSI_8',\n",
       " 'BSI_9',\n",
       " 'BSI_10',\n",
       " 'BSI_11',\n",
       " 'BSI_12',\n",
       " 'BSI_13',\n",
       " 'BSI_14',\n",
       " 'BSI_15',\n",
       " 'BSI_16',\n",
       " 'BSI_17',\n",
       " 'BSI_18',\n",
       " 'BSI_19',\n",
       " 'BSI_20',\n",
       " 'BSI_21',\n",
       " 'BSI_22',\n",
       " 'BSI_23',\n",
       " 'BSI_24',\n",
       " 'BSI_25',\n",
       " 'BSI_26',\n",
       " 'BSI_27',\n",
       " 'BSI_28',\n",
       " 'BSI_29',\n",
       " 'BSI_30',\n",
       " 'BSI_31',\n",
       " 'BSI_32',\n",
       " 'BSI_33',\n",
       " 'BSI_34',\n",
       " 'BSI_35',\n",
       " 'BSI_36',\n",
       " 'BSI_37',\n",
       " 'BSI_38',\n",
       " 'BSI_39',\n",
       " 'BSI_40',\n",
       " 'BSI_41',\n",
       " 'BSI_42',\n",
       " 'BSI_43',\n",
       " 'BSI_44',\n",
       " 'BSI_45',\n",
       " 'BSI_46',\n",
       " 'BSI_47',\n",
       " 'BSI_48',\n",
       " 'BSI_49',\n",
       " 'BSI_50',\n",
       " 'BSI_51',\n",
       " 'BSI_52',\n",
       " 'BSI_53',\n",
       " 'WHOQoL_1',\n",
       " 'WHOQoL_2',\n",
       " 'WHOQoL_3',\n",
       " 'WHOQoL_4',\n",
       " 'WHOQoL_5',\n",
       " 'WHOQoL_6',\n",
       " 'WHOQoL_7',\n",
       " 'WHOQoL_8',\n",
       " 'WHOQoL_9',\n",
       " 'WHOQoL_10',\n",
       " 'WHOQoL_11',\n",
       " 'WHOQoL_12',\n",
       " 'WHOQoL_14',\n",
       " 'WHOQoL_15',\n",
       " 'WHOQoL_16',\n",
       " 'WHOQoL_17',\n",
       " 'WHOQoL_18',\n",
       " 'WHOQoL_19',\n",
       " 'WHOQoL_20',\n",
       " 'WHOQoL_21',\n",
       " 'WHOQoL_22',\n",
       " 'WHOQoL_23',\n",
       " 'WHOQoL_24',\n",
       " 'WHOQoL_25',\n",
       " 'WHOQoL_26',\n",
       " 'BSI_GSI_EB',\n",
       " 'BSI_Somatization_EB',\n",
       " 'BSI_ObsCom_EB',\n",
       " 'BSI_IntSens_EB',\n",
       " 'BSI_Depression_EB',\n",
       " 'BSI_Anxiety_EB',\n",
       " 'BSI_Hostility_EB',\n",
       " 'BSI_Phobic_EB',\n",
       " 'BSI_Paranoid_EB',\n",
       " 'BSI_Psychoticism_EB',\n",
       " 'WQOL.Fisico',\n",
       " 'WQOL.Psicologico',\n",
       " 'WQOL.RSociais',\n",
       " 'WQOL_MAmbiente']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_feat = []#list(data.columns)[42:141]\n",
    "\n",
    "'''new_feat += [\n",
    "           'WHOQoL_1', 'WHOQoL_2', 'WHOQoL_5', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', \n",
    "    'WHOQoL_15', 'WHOQoL_22', 'WHOQoL_23',              \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "            ]'''\n",
    "'''new_feat += [\n",
    "           'WHOQoL_6', 'WHOQoL_10', 'WHOQoL_14', 'WHOQoL_16', 'WHOQoL_18', 'WHOQoL_19', \n",
    "    'WHOQoL_20', 'WHOQoL_22', 'WHOQoL_25', 'WHOQoL_26',             \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]'''\n",
    "\n",
    "new_feat += [\n",
    "           'WHOQoL_2', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', 'WHOQoL_10', 'WHOQoL_11', \n",
    "    'WHOQoL_12', 'WHOQoL_17', 'WHOQoL_19', 'WHOQoL_23', 'WHOQoL_24','WHOQoL_26',\n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = []\n",
    "for col in data.columns:\n",
    "    if 'WQOL' in col:\n",
    "        result_cols.append(col)\n",
    "    elif 'BSI_' in col and len(col)>6:\n",
    "        result_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsi = []\n",
    "whoqol = []\n",
    "for col in data.columns:\n",
    "    if 'WQOL' in col:\n",
    "        whoqol.append(col)\n",
    "    elif 'BSI_' in col and len(col)>6:\n",
    "        bsi.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsi_feat = []\n",
    "whoqol_feat = []\n",
    "for col in data.columns:\n",
    "    if 'WHOQoL' in col:\n",
    "        whoqol_feat.append(col)\n",
    "    elif 'BSI_' in col and len(col)<=6:\n",
    "        bsi_feat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[result_cols] = data[result_cols].replace(' ', np.nan)\n",
    "data = data.replace(' ', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = result_cols, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['WHOQoL_3'] = abs(data['WHOQoL_3']-6)\n",
    "data['WHOQoL_4'] = abs(data['WHOQoL_4']-6)\n",
    "data['WHOQoL_26'] = abs(data['WHOQoL_26']-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(['ID_covid', 'sample', 'date_created','consent', 'sgID', 'date_birth', 'region','city_br','Occupation_other', 'working_hours','religion_other', 'cceb_class',\n",
    "#'social_support_n_family','social_support_n_friends'],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[bsi] = data[bsi].apply(lambda x: x.str.replace(',','.'))\n",
    "#data[whoqol] = data[whoqol].apply(lambda x: x.str.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[bsi_feat] = data[bsi_feat].astype(float)\n",
    "\n",
    "#data[whoqol_feat] = data[whoqol_feat].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database\n",
      "sex\n",
      "education\n",
      "marital_status\n",
      "ethnicity\n",
      "cceb_class\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    try:\n",
    "        data[col] = data[col].astype(float)\n",
    "    except:\n",
    "        (print(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import  Dense, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].nunique()==1:\n",
    "        data.drop(col,inplace = True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WQOL.Fisico', 'WQOL.Psicologico', 'WQOL.RSociais', 'WQOL_MAmbiente']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whoqol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>cceb_class</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BSI_Depression_EB</th>\n",
       "      <th>BSI_Anxiety_EB</th>\n",
       "      <th>BSI_Hostility_EB</th>\n",
       "      <th>BSI_Phobic_EB</th>\n",
       "      <th>BSI_Paranoid_EB</th>\n",
       "      <th>BSI_Psychoticism_EB</th>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <th>WQOL.RSociais</th>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>436.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>400.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>579.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>468.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>292.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>383.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>536.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>273.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>376.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>563.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>689.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>275.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>351.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>377.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>285.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>443.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>341.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>404.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>371.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>585.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>324.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>335.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>334.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186317</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>449.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186319</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>567.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186320</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>216.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186321</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>310.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186322</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>431.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186323</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>459.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186325</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>594.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186327</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>644.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186328</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>349.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186330</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>584.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186331</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>614.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186333</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>672.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186334</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>679.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186335</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>730.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186336</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>758.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186338</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>433.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186339</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>556.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186340</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>304.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186341</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>432.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186342</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186344</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>610.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186345</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>696.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186346</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>793.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186347</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>809.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186348</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>815.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186349</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>526.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186350</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>652.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186351</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186352</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>823.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186353</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>888.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153514 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       database        sex  age_months  age_years  \\\n",
       "0           SUS   Feminino       436.0       36.0   \n",
       "1           SUS   Feminino       400.0       33.0   \n",
       "2           SUS  Masculino       579.0       48.0   \n",
       "4           SUS   Feminino       468.0       39.0   \n",
       "5           SUS   Feminino       292.0       24.0   \n",
       "6           SUS   Feminino       383.0       31.0   \n",
       "7           SUS   Feminino       321.0       26.0   \n",
       "8           SUS   Feminino       536.0       44.0   \n",
       "9           SUS   Feminino       419.0       34.0   \n",
       "10          SUS   Feminino       273.0       22.0   \n",
       "11          SUS   Feminino       376.0       31.0   \n",
       "12          SUS   Feminino       563.0       46.0   \n",
       "15          SUS  Masculino       689.0       57.0   \n",
       "16          SUS   Feminino       275.0       22.0   \n",
       "18          SUS  Masculino       351.0       29.0   \n",
       "19          SUS   Feminino       321.0       26.0   \n",
       "20          SUS   Feminino       377.0       31.0   \n",
       "21          SUS   Feminino       285.0       23.0   \n",
       "22          SUS   Feminino       443.0       36.0   \n",
       "23          SUS  Masculino       341.0       28.0   \n",
       "24          SUS  Masculino       485.0       40.0   \n",
       "25          SUS   Feminino       404.0       33.0   \n",
       "26          SUS  Masculino       371.0       30.0   \n",
       "27          SUS   Feminino       690.0       57.0   \n",
       "28          SUS   Feminino       585.0       48.0   \n",
       "29          SUS   Feminino       321.0       26.0   \n",
       "30          SUS   Feminino       324.0       27.0   \n",
       "31          SUS   Feminino       335.0       27.0   \n",
       "32          SUS   Feminino       334.0       27.0   \n",
       "33          SUS   Feminino       288.0       24.0   \n",
       "...         ...        ...         ...        ...   \n",
       "186317  general  Masculino       449.0       37.0   \n",
       "186319  general   Feminino       567.0       47.0   \n",
       "186320  general   Feminino       216.0       18.0   \n",
       "186321  general   Feminino       310.0       25.0   \n",
       "186322  general  Masculino       431.0       35.0   \n",
       "186323  general   Feminino       459.0       38.0   \n",
       "186325  general   Feminino       594.0       49.0   \n",
       "186327  general   Feminino       644.0       53.0   \n",
       "186328  general   Feminino       349.0       29.0   \n",
       "186330  general   Feminino       584.0       48.0   \n",
       "186331  general   Feminino       614.0       51.0   \n",
       "186333  general   Feminino       672.0       56.0   \n",
       "186334  general   Feminino       679.0       56.0   \n",
       "186335  general   Feminino       730.0       60.0   \n",
       "186336  general   Feminino       758.0       63.0   \n",
       "186338  general   Feminino       433.0       36.0   \n",
       "186339  general  Masculino       556.0       46.0   \n",
       "186340  general   Feminino       304.0       25.0   \n",
       "186341  general   Feminino       432.0       36.0   \n",
       "186342  general   Feminino       503.0       41.0   \n",
       "186344  general   Feminino       610.0       50.0   \n",
       "186345  general   Feminino       696.0       58.0   \n",
       "186346  general   Feminino       793.0       66.0   \n",
       "186347  general   Feminino       809.0       67.0   \n",
       "186348  general   Feminino       815.0       67.0   \n",
       "186349  general   Feminino       526.0       43.0   \n",
       "186350  general   Feminino       652.0       54.0   \n",
       "186351  general   Feminino       690.0       57.0   \n",
       "186352  general   Feminino       823.0       68.0   \n",
       "186353  general   Feminino       888.0       74.0   \n",
       "\n",
       "                                                education  \\\n",
       "0                                       Superior completo   \n",
       "1                                       Superior completo   \n",
       "2                                       Superior completo   \n",
       "4                                       Superior completo   \n",
       "5                                       Superior completo   \n",
       "6                                                Mestrado   \n",
       "7                                       Superior completo   \n",
       "8                                                Mestrado   \n",
       "9                                       Superior completo   \n",
       "10                                      Superior completo   \n",
       "11                                      Superior completo   \n",
       "12                                      Superior completo   \n",
       "15                                              Doutorado   \n",
       "16                                                    NaN   \n",
       "18                                      Superior completo   \n",
       "19                                      Superior completo   \n",
       "20                                      Superior completo   \n",
       "21                                                    NaN   \n",
       "22                                      Superior completo   \n",
       "23                                      Superior completo   \n",
       "24                                      Superior completo   \n",
       "25                                      Superior completo   \n",
       "26                                      Superior completo   \n",
       "27                                      Superior completo   \n",
       "28                                      Superior completo   \n",
       "29                                      Superior completo   \n",
       "30                                      Superior completo   \n",
       "31                                      Superior completo   \n",
       "32                                      Superior completo   \n",
       "33                                      Superior completo   \n",
       "...                                                   ...   \n",
       "186317                                           Mestrado   \n",
       "186319                                           Mestrado   \n",
       "186320  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186321                                           Mestrado   \n",
       "186322  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186323                                  Superior completo   \n",
       "186325                                           Mestrado   \n",
       "186327  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186328  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186330                                  Superior completo   \n",
       "186331                                           Mestrado   \n",
       "186333                                  Superior completo   \n",
       "186334                                  Superior completo   \n",
       "186335                                  Superior completo   \n",
       "186336                                  Superior completo   \n",
       "186338                                  Superior completo   \n",
       "186339                                          Doutorado   \n",
       "186340  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186341  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186342                                  Superior completo   \n",
       "186344  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186345                                  Superior completo   \n",
       "186346                                  Superior completo   \n",
       "186347  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186348                                  Superior completo   \n",
       "186349                                  Superior completo   \n",
       "186350  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186351                                           Mestrado   \n",
       "186352                                  Superior completo   \n",
       "186353  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "\n",
       "                   marital_status ethnicity cceb_class  BSI_1  BSI_2  ...  \\\n",
       "0            Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "1            Casado(a)/Vive junto     Parda         C1    2.0    0.0  ...   \n",
       "2            Casado(a)/Vive junto     Preta         B2    1.0    1.0  ...   \n",
       "4                     Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "5                     Solteiro(a)     Parda         C2    2.0    0.0  ...   \n",
       "6                     Solteiro(a)     Parda         C2    3.0    0.0  ...   \n",
       "7                     Solteiro(a)    Branca         B2    0.0    0.0  ...   \n",
       "8            Casado(a)/Vive junto    Branca         C1    3.0    0.0  ...   \n",
       "9                     Solteiro(a)     Preta         C1    2.0    0.0  ...   \n",
       "10                    Solteiro(a)    Branca         C2    2.0    0.0  ...   \n",
       "11           Casado(a)/Vive junto     Preta         B2    0.0    0.0  ...   \n",
       "12                    Solteiro(a)     Parda         C1    1.0    0.0  ...   \n",
       "15           Casado(a)/Vive junto     Parda         B2    0.0    0.0  ...   \n",
       "16                    Solteiro(a)     Parda         DE    2.0    2.0  ...   \n",
       "18           Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "19           Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "20                    Solteiro(a)    Branca         DE    4.0    1.0  ...   \n",
       "21                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "22           Casado(a)/Vive junto    Branca         C2    0.0    0.0  ...   \n",
       "23                    Solteiro(a)       NaN        NaN    0.0    0.0  ...   \n",
       "24           Casado(a)/Vive junto     Preta         C1    0.0    0.0  ...   \n",
       "25      Separado(a)/Divorciado(a)    Branca         C1    3.0    0.0  ...   \n",
       "26                    Solteiro(a)       NaN        NaN    1.0    0.0  ...   \n",
       "27           Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "28      Separado(a)/Divorciado(a)     Parda         C2    1.0    0.0  ...   \n",
       "29                    Solteiro(a)     Parda         DE    0.0    0.0  ...   \n",
       "30                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "31           Casado(a)/Vive junto    Branca         C1    2.0    0.0  ...   \n",
       "32           Casado(a)/Vive junto    Branca         DE    1.0    0.0  ...   \n",
       "33                    Solteiro(a)    Branca         C1    1.0    0.0  ...   \n",
       "...                           ...       ...        ...    ...    ...  ...   \n",
       "186317       Casado(a)/Vive junto    Branca         B1    0.0    0.0  ...   \n",
       "186319       Casado(a)/Vive junto       NaN        NaN    3.0    1.0  ...   \n",
       "186320                Solteiro(a)       NaN        NaN    0.0    0.0  ...   \n",
       "186321       Casado(a)/Vive junto    Branca         B1    2.0    0.0  ...   \n",
       "186322                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186323                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "186325  Separado(a)/Divorciado(a)    Branca         B1    0.0    0.0  ...   \n",
       "186327       Casado(a)/Vive junto    Branca         C1    4.0    1.0  ...   \n",
       "186328                Solteiro(a)    Branca         DE    3.0    2.0  ...   \n",
       "186330  Separado(a)/Divorciado(a)     Preta         B2    4.0    0.0  ...   \n",
       "186331       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186333                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186334  Separado(a)/Divorciado(a)    Branca          A    0.0    1.0  ...   \n",
       "186335       Casado(a)/Vive junto    Branca         C2    1.0    0.0  ...   \n",
       "186336       Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "186338       Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "186339       Casado(a)/Vive junto     Parda         C1    0.0    0.0  ...   \n",
       "186340                Solteiro(a)       NaN        NaN    2.0    3.0  ...   \n",
       "186341       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186342       Casado(a)/Vive junto    Branca         B2    3.0    2.0  ...   \n",
       "186344       Casado(a)/Vive junto    Branca         C1    2.0    1.0  ...   \n",
       "186345                Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "186346                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186347  Separado(a)/Divorciado(a)    Branca         B2    1.0    0.0  ...   \n",
       "186348  Separado(a)/Divorciado(a)       NaN        NaN    2.0    1.0  ...   \n",
       "186349                Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "186350       Casado(a)/Vive junto    Branca         C1    1.0    0.0  ...   \n",
       "186351  Separado(a)/Divorciado(a)    Branca         B2    3.0    0.0  ...   \n",
       "186352       Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "186353                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "\n",
       "        BSI_Depression_EB  BSI_Anxiety_EB  BSI_Hostility_EB  BSI_Phobic_EB  \\\n",
       "0                0.333333        0.500000               0.0            0.2   \n",
       "1                0.833333        1.500000               1.0            1.0   \n",
       "2                0.166667        0.500000               0.0            0.6   \n",
       "4                0.500000        0.666667               0.0            1.6   \n",
       "5                1.833333        1.666667               1.0            1.4   \n",
       "6                1.166667        0.833333               0.4            0.4   \n",
       "7                0.000000        0.000000               0.0            0.0   \n",
       "8                1.000000        1.500000               0.8            1.2   \n",
       "9                0.166667        0.666667               0.2            0.2   \n",
       "10               0.000000        0.833333               0.0            0.0   \n",
       "11               0.166667        0.000000               0.2            0.2   \n",
       "12               0.166667        0.166667               0.0            0.0   \n",
       "15               0.000000        0.000000               0.0            0.0   \n",
       "16               1.333333        1.500000               0.4            0.2   \n",
       "18               0.166667        0.000000               0.0            0.2   \n",
       "19               1.333333        2.333333               1.6            2.0   \n",
       "20               2.166667        1.833333               2.0            0.4   \n",
       "21               1.166667        1.500000               1.6            0.6   \n",
       "22               0.166667        0.000000               0.0            0.0   \n",
       "23               1.166667        0.000000               0.2            0.2   \n",
       "24               0.166667        0.000000               0.4            0.8   \n",
       "25               1.333333        1.166667               0.8            0.4   \n",
       "26               0.333333        0.333333               0.0            0.0   \n",
       "27               0.333333        0.333333               0.0            0.0   \n",
       "28               0.500000        0.166667               0.2            0.0   \n",
       "29               0.166667        0.000000               0.0            0.0   \n",
       "30               0.166667        1.166667               0.0            1.6   \n",
       "31               0.500000        0.833333               0.2            0.6   \n",
       "32               0.333333        0.500000               0.0            0.2   \n",
       "33               0.000000        0.166667               0.2            0.0   \n",
       "...                   ...             ...               ...            ...   \n",
       "186317           0.333333        0.166667               0.2            0.0   \n",
       "186319           3.333333        2.833333               2.2            2.6   \n",
       "186320           0.500000        0.500000               1.0            0.8   \n",
       "186321           0.666667        2.333333               3.2            3.4   \n",
       "186322           0.833333        0.666667               0.2            1.4   \n",
       "186323           2.500000        2.000000               0.8            0.8   \n",
       "186325           0.166667        0.000000               0.0            0.0   \n",
       "186327           2.833333        3.000000               1.8            3.6   \n",
       "186328           3.000000        1.666667               0.4            1.6   \n",
       "186330           2.333333        3.333333               1.0            3.8   \n",
       "186331           1.166667        2.333333               2.2            2.4   \n",
       "186333           0.000000        0.000000               0.0            0.4   \n",
       "186334           1.500000        0.500000               1.2            0.2   \n",
       "186335           1.666667        1.000000               1.2            0.8   \n",
       "186336           0.666667        0.500000               0.2            0.4   \n",
       "186338           0.666667        0.666667               2.2            0.2   \n",
       "186339           2.000000        0.333333               0.2            1.2   \n",
       "186340           3.666667        2.166667               3.4            3.6   \n",
       "186341           2.500000        2.500000               2.4            3.0   \n",
       "186342           1.833333        2.166667               1.2            2.6   \n",
       "186344           0.833333        1.333333               0.2            0.8   \n",
       "186345           0.500000        1.000000               0.2            0.6   \n",
       "186346           0.166667        0.000000               0.0            1.0   \n",
       "186347           0.500000        0.333333               0.0            0.4   \n",
       "186348           3.000000        1.333333               0.6            2.6   \n",
       "186349           0.500000        0.333333               0.6            0.0   \n",
       "186350           0.500000        0.500000               0.2            0.4   \n",
       "186351           3.333333        2.000000               1.0            2.6   \n",
       "186352           0.500000        0.166667               0.0            0.0   \n",
       "186353           1.000000        0.666667               0.2            1.6   \n",
       "\n",
       "        BSI_Paranoid_EB  BSI_Psychoticism_EB  WQOL.Fisico  WQOL.Psicologico  \\\n",
       "0                  0.00                  0.0     4.285714          4.166667   \n",
       "1                  1.00                  0.4     2.857143          3.333333   \n",
       "2                  0.75                  0.0     4.166667          3.666667   \n",
       "4                  0.40                  0.0     3.428571          3.333333   \n",
       "5                  2.00                  2.4     3.714286          3.333333   \n",
       "6                  0.20                  0.4     3.285714          3.166667   \n",
       "7                  0.00                  0.0     3.857143          4.166667   \n",
       "8                  0.20                  0.6     3.428571          3.000000   \n",
       "9                  0.00                  0.2     4.000000          4.500000   \n",
       "10                 0.20                  0.0     4.000000          4.333333   \n",
       "11                 0.00                  0.0     4.571429          4.833333   \n",
       "12                 0.00                  0.0     4.000000          3.666667   \n",
       "15                 0.40                  0.0     4.857143          5.000000   \n",
       "16                 0.80                  0.4     3.285714          3.000000   \n",
       "18                 0.20                  0.0     4.428571          4.333333   \n",
       "19                 1.20                  1.6     4.000000          3.833333   \n",
       "20                 1.40                  1.4     3.285714          2.166667   \n",
       "21                 1.40                  1.6     3.857143          3.333333   \n",
       "22                 0.20                  0.2     4.857143          4.833333   \n",
       "23                 0.60                  0.4     4.285714          4.166667   \n",
       "24                 0.20                  0.0     4.142857          4.333333   \n",
       "25                 0.20                  0.8     3.857143          2.833333   \n",
       "26                 0.00                  0.0     4.714286          4.833333   \n",
       "27                 0.00                  0.0     4.428571          3.500000   \n",
       "28                 0.80                  0.0     4.714286          3.666667   \n",
       "29                 0.40                  0.2     4.000000          4.333333   \n",
       "30                 0.60                  0.0     4.428571          3.666667   \n",
       "31                 0.60                  0.4     4.285714          3.833333   \n",
       "32                 1.60                  0.2     4.285714          3.833333   \n",
       "33                 0.00                  0.0     4.142857          3.833333   \n",
       "...                 ...                  ...          ...               ...   \n",
       "186317             0.20                  0.0     3.857143          4.333333   \n",
       "186319             2.00                  2.2     2.000000          1.833333   \n",
       "186320             1.00                  0.4     3.714286          3.666667   \n",
       "186321             1.00                  1.2     4.142857          3.666667   \n",
       "186322             0.00                  0.6     3.428571          2.166667   \n",
       "186323             1.80                  1.2     3.142857          3.666667   \n",
       "186325             0.00                  0.0     3.571429          3.666667   \n",
       "186327             2.20                  2.0     1.857143          2.666667   \n",
       "186328             1.20                  1.8     2.000000          2.333333   \n",
       "186330             1.80                  1.6     2.000000          2.500000   \n",
       "186331             1.00                  1.0     2.428571          2.666667   \n",
       "186333             0.20                  0.0     3.571429          4.166667   \n",
       "186334             2.20                  0.6     3.285714          2.500000   \n",
       "186335             1.00                  0.6     2.714286          1.833333   \n",
       "186336             0.60                  0.4     3.428571          3.500000   \n",
       "186338             1.00                  0.8     4.142857          3.500000   \n",
       "186339             1.60                  1.0     4.000000          2.833333   \n",
       "186340             2.60                  2.2     1.142857          2.000000   \n",
       "186341             2.20                  2.0     2.714286          2.333333   \n",
       "186342             0.60                  0.0     3.000000          2.500000   \n",
       "186344             1.20                  0.4     3.000000          3.166667   \n",
       "186345             0.80                  0.2     3.571429          3.333333   \n",
       "186346             0.00                  0.0     4.000000          4.333333   \n",
       "186347             0.20                  0.4     4.142857          4.333333   \n",
       "186348             2.40                  1.8     1.571429          1.500000   \n",
       "186349             0.40                  0.0     3.857143          2.666667   \n",
       "186350             0.40                  0.0     3.142857          3.333333   \n",
       "186351             1.40                  1.6     2.142857          2.000000   \n",
       "186352             0.00                  0.2     4.285714          4.666667   \n",
       "186353             0.20                  0.2     4.571429          4.166667   \n",
       "\n",
       "        WQOL.RSociais  WQOL_MAmbiente  \n",
       "0            4.000000        3.714286  \n",
       "1            2.333333        3.142857  \n",
       "2            4.000000        2.857143  \n",
       "4            3.000000        4.142857  \n",
       "5            3.666667        3.857143  \n",
       "6            2.666667        3.285714  \n",
       "7            4.666667        4.142857  \n",
       "8            2.666667        3.428571  \n",
       "9            5.000000        3.571429  \n",
       "10           4.000000        4.428571  \n",
       "11           4.333333        4.000000  \n",
       "12           3.333333        2.714286  \n",
       "15           4.333333        3.857143  \n",
       "16           2.666667        3.142857  \n",
       "18           4.666667        3.714286  \n",
       "19           4.000000        3.857143  \n",
       "20           1.333333        2.285714  \n",
       "21           3.333333        3.142857  \n",
       "22           4.000000        3.857143  \n",
       "23           2.666667        3.142857  \n",
       "24           3.333333        3.428571  \n",
       "25           2.666667        3.428571  \n",
       "26           4.333333        4.285714  \n",
       "27           3.666667        3.571429  \n",
       "28           4.333333        3.000000  \n",
       "29           3.000000        2.571429  \n",
       "30           4.000000        3.714286  \n",
       "31           3.666667        3.000000  \n",
       "32           2.333333        4.000000  \n",
       "33           3.333333        3.857143  \n",
       "...               ...             ...  \n",
       "186317       4.000000        3.857143  \n",
       "186319       1.666667        1.714286  \n",
       "186320       3.333333        4.142857  \n",
       "186321       3.333333        4.428571  \n",
       "186322       2.666667        4.142857  \n",
       "186323       2.666667        2.571429  \n",
       "186325       3.666667        3.000000  \n",
       "186327       2.333333        2.571429  \n",
       "186328       2.333333        2.428571  \n",
       "186330       2.666667        2.857143  \n",
       "186331       3.333333        2.714286  \n",
       "186333       4.000000        3.285714  \n",
       "186334       2.000000        3.714286  \n",
       "186335       1.666667        2.857143  \n",
       "186336       3.666667        3.142857  \n",
       "186338       3.666667        3.571429  \n",
       "186339       1.666667        3.428571  \n",
       "186340       2.666667        1.142857  \n",
       "186341       2.333333        2.571429  \n",
       "186342       3.000000        3.142857  \n",
       "186344       4.000000        2.428571  \n",
       "186345       3.666667        3.000000  \n",
       "186346       3.666667        4.142857  \n",
       "186347       4.000000        4.285714  \n",
       "186348       2.000000        1.857143  \n",
       "186349       3.000000        3.428571  \n",
       "186350       2.666667        2.428571  \n",
       "186351       2.666667        3.428571  \n",
       "186352       4.333333        4.285714  \n",
       "186353       4.000000        4.285714  \n",
       "\n",
       "[153514 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.fillna(-1, inplace = True)\n",
    "#data.dropna( inplace = True)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>cceb_class</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BSI_Depression_EB</th>\n",
       "      <th>BSI_Anxiety_EB</th>\n",
       "      <th>BSI_Hostility_EB</th>\n",
       "      <th>BSI_Phobic_EB</th>\n",
       "      <th>BSI_Paranoid_EB</th>\n",
       "      <th>BSI_Psychoticism_EB</th>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <th>WQOL.RSociais</th>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>436.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>400.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>468.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>292.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>383.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>536.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>273.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>376.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>563.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>689.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>351.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>377.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>443.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>404.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>585.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>324.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>335.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>334.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>438.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>421.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>381.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>300.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>407.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186306</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>450.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186307</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>512.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186311</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>205.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Fundamental completo/MÃ©dio incompleto (GinÃ¡s...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186314</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186317</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>449.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186321</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>310.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186322</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>431.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186323</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>459.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186325</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>594.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186327</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>644.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186328</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>349.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186330</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>584.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186331</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>614.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186333</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>672.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186334</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>679.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186335</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>730.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186336</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>758.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186338</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>433.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186339</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>556.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186341</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>432.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186342</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186344</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>610.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186345</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>696.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186346</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>793.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186347</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>809.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186349</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>526.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186350</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>652.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186351</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186352</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>823.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186353</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>888.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112726 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       database        sex  age_months  age_years  \\\n",
       "0           SUS   Feminino       436.0       36.0   \n",
       "1           SUS   Feminino       400.0       33.0   \n",
       "4           SUS   Feminino       468.0       39.0   \n",
       "5           SUS   Feminino       292.0       24.0   \n",
       "6           SUS   Feminino       383.0       31.0   \n",
       "7           SUS   Feminino       321.0       26.0   \n",
       "8           SUS   Feminino       536.0       44.0   \n",
       "9           SUS   Feminino       419.0       34.0   \n",
       "10          SUS   Feminino       273.0       22.0   \n",
       "11          SUS   Feminino       376.0       31.0   \n",
       "12          SUS   Feminino       563.0       46.0   \n",
       "15          SUS  Masculino       689.0       57.0   \n",
       "18          SUS  Masculino       351.0       29.0   \n",
       "19          SUS   Feminino       321.0       26.0   \n",
       "20          SUS   Feminino       377.0       31.0   \n",
       "22          SUS   Feminino       443.0       36.0   \n",
       "24          SUS  Masculino       485.0       40.0   \n",
       "25          SUS   Feminino       404.0       33.0   \n",
       "27          SUS   Feminino       690.0       57.0   \n",
       "28          SUS   Feminino       585.0       48.0   \n",
       "29          SUS   Feminino       321.0       26.0   \n",
       "30          SUS   Feminino       324.0       27.0   \n",
       "31          SUS   Feminino       335.0       27.0   \n",
       "32          SUS   Feminino       334.0       27.0   \n",
       "33          SUS   Feminino       288.0       24.0   \n",
       "35          SUS   Feminino       438.0       36.0   \n",
       "36          SUS   Feminino       421.0       35.0   \n",
       "37          SUS   Feminino       381.0       31.0   \n",
       "38          SUS   Feminino       300.0       25.0   \n",
       "40          SUS  Masculino       407.0       33.0   \n",
       "...         ...        ...         ...        ...   \n",
       "186306  general   Feminino       450.0       37.0   \n",
       "186307  general  Masculino       512.0       42.0   \n",
       "186311  general   Feminino       205.0       17.0   \n",
       "186314  general   Feminino       290.0       24.0   \n",
       "186317  general  Masculino       449.0       37.0   \n",
       "186321  general   Feminino       310.0       25.0   \n",
       "186322  general  Masculino       431.0       35.0   \n",
       "186323  general   Feminino       459.0       38.0   \n",
       "186325  general   Feminino       594.0       49.0   \n",
       "186327  general   Feminino       644.0       53.0   \n",
       "186328  general   Feminino       349.0       29.0   \n",
       "186330  general   Feminino       584.0       48.0   \n",
       "186331  general   Feminino       614.0       51.0   \n",
       "186333  general   Feminino       672.0       56.0   \n",
       "186334  general   Feminino       679.0       56.0   \n",
       "186335  general   Feminino       730.0       60.0   \n",
       "186336  general   Feminino       758.0       63.0   \n",
       "186338  general   Feminino       433.0       36.0   \n",
       "186339  general  Masculino       556.0       46.0   \n",
       "186341  general   Feminino       432.0       36.0   \n",
       "186342  general   Feminino       503.0       41.0   \n",
       "186344  general   Feminino       610.0       50.0   \n",
       "186345  general   Feminino       696.0       58.0   \n",
       "186346  general   Feminino       793.0       66.0   \n",
       "186347  general   Feminino       809.0       67.0   \n",
       "186349  general   Feminino       526.0       43.0   \n",
       "186350  general   Feminino       652.0       54.0   \n",
       "186351  general   Feminino       690.0       57.0   \n",
       "186352  general   Feminino       823.0       68.0   \n",
       "186353  general   Feminino       888.0       74.0   \n",
       "\n",
       "                                                education  \\\n",
       "0                                       Superior completo   \n",
       "1                                       Superior completo   \n",
       "4                                       Superior completo   \n",
       "5                                       Superior completo   \n",
       "6                                                Mestrado   \n",
       "7                                       Superior completo   \n",
       "8                                                Mestrado   \n",
       "9                                       Superior completo   \n",
       "10                                      Superior completo   \n",
       "11                                      Superior completo   \n",
       "12                                      Superior completo   \n",
       "15                                              Doutorado   \n",
       "18                                      Superior completo   \n",
       "19                                      Superior completo   \n",
       "20                                      Superior completo   \n",
       "22                                      Superior completo   \n",
       "24                                      Superior completo   \n",
       "25                                      Superior completo   \n",
       "27                                      Superior completo   \n",
       "28                                      Superior completo   \n",
       "29                                      Superior completo   \n",
       "30                                      Superior completo   \n",
       "31                                      Superior completo   \n",
       "32                                      Superior completo   \n",
       "33                                      Superior completo   \n",
       "35                                      Superior completo   \n",
       "36                                      Superior completo   \n",
       "37                                      Superior completo   \n",
       "38                                      Superior completo   \n",
       "40                                      Superior completo   \n",
       "...                                                   ...   \n",
       "186306                                           Mestrado   \n",
       "186307                                          Doutorado   \n",
       "186311  Fundamental completo/MÃ©dio incompleto (GinÃ¡s...   \n",
       "186314                                  Superior completo   \n",
       "186317                                           Mestrado   \n",
       "186321                                           Mestrado   \n",
       "186322  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186323                                  Superior completo   \n",
       "186325                                           Mestrado   \n",
       "186327  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186328  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186330                                  Superior completo   \n",
       "186331                                           Mestrado   \n",
       "186333                                  Superior completo   \n",
       "186334                                  Superior completo   \n",
       "186335                                  Superior completo   \n",
       "186336                                  Superior completo   \n",
       "186338                                  Superior completo   \n",
       "186339                                          Doutorado   \n",
       "186341  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186342                                  Superior completo   \n",
       "186344  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186345                                  Superior completo   \n",
       "186346                                  Superior completo   \n",
       "186347  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186349                                  Superior completo   \n",
       "186350  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186351                                           Mestrado   \n",
       "186352                                  Superior completo   \n",
       "186353  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "\n",
       "                   marital_status ethnicity cceb_class  BSI_1  BSI_2  ...  \\\n",
       "0            Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "1            Casado(a)/Vive junto     Parda         C1    2.0    0.0  ...   \n",
       "4                     Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "5                     Solteiro(a)     Parda         C2    2.0    0.0  ...   \n",
       "6                     Solteiro(a)     Parda         C2    3.0    0.0  ...   \n",
       "7                     Solteiro(a)    Branca         B2    0.0    0.0  ...   \n",
       "8            Casado(a)/Vive junto    Branca         C1    3.0    0.0  ...   \n",
       "9                     Solteiro(a)     Preta         C1    2.0    0.0  ...   \n",
       "10                    Solteiro(a)    Branca         C2    2.0    0.0  ...   \n",
       "11           Casado(a)/Vive junto     Preta         B2    0.0    0.0  ...   \n",
       "12                    Solteiro(a)     Parda         C1    1.0    0.0  ...   \n",
       "15           Casado(a)/Vive junto     Parda         B2    0.0    0.0  ...   \n",
       "18           Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "19           Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "20                    Solteiro(a)    Branca         DE    4.0    1.0  ...   \n",
       "22           Casado(a)/Vive junto    Branca         C2    0.0    0.0  ...   \n",
       "24           Casado(a)/Vive junto     Preta         C1    0.0    0.0  ...   \n",
       "25      Separado(a)/Divorciado(a)    Branca         C1    3.0    0.0  ...   \n",
       "27           Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "28      Separado(a)/Divorciado(a)     Parda         C2    1.0    0.0  ...   \n",
       "29                    Solteiro(a)     Parda         DE    0.0    0.0  ...   \n",
       "30                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "31           Casado(a)/Vive junto    Branca         C1    2.0    0.0  ...   \n",
       "32           Casado(a)/Vive junto    Branca         DE    1.0    0.0  ...   \n",
       "33                    Solteiro(a)    Branca         C1    1.0    0.0  ...   \n",
       "35           Casado(a)/Vive junto     Preta         C1    2.0    0.0  ...   \n",
       "36                    Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "37                    Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "38                    Solteiro(a)    Branca         DE    3.0    0.0  ...   \n",
       "40           Casado(a)/Vive junto    Branca         C1    0.0    0.0  ...   \n",
       "...                           ...       ...        ...    ...    ...  ...   \n",
       "186306       Casado(a)/Vive junto    Branca          A    1.0    0.0  ...   \n",
       "186307                Solteiro(a)     Parda         B1    3.0    0.0  ...   \n",
       "186311                Solteiro(a)    Branca          A    2.0    0.0  ...   \n",
       "186314       Casado(a)/Vive junto    Branca         C1    3.0    1.0  ...   \n",
       "186317       Casado(a)/Vive junto    Branca         B1    0.0    0.0  ...   \n",
       "186321       Casado(a)/Vive junto    Branca         B1    2.0    0.0  ...   \n",
       "186322                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186323                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "186325  Separado(a)/Divorciado(a)    Branca         B1    0.0    0.0  ...   \n",
       "186327       Casado(a)/Vive junto    Branca         C1    4.0    1.0  ...   \n",
       "186328                Solteiro(a)    Branca         DE    3.0    2.0  ...   \n",
       "186330  Separado(a)/Divorciado(a)     Preta         B2    4.0    0.0  ...   \n",
       "186331       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186333                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186334  Separado(a)/Divorciado(a)    Branca          A    0.0    1.0  ...   \n",
       "186335       Casado(a)/Vive junto    Branca         C2    1.0    0.0  ...   \n",
       "186336       Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "186338       Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "186339       Casado(a)/Vive junto     Parda         C1    0.0    0.0  ...   \n",
       "186341       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186342       Casado(a)/Vive junto    Branca         B2    3.0    2.0  ...   \n",
       "186344       Casado(a)/Vive junto    Branca         C1    2.0    1.0  ...   \n",
       "186345                Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "186346                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186347  Separado(a)/Divorciado(a)    Branca         B2    1.0    0.0  ...   \n",
       "186349                Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "186350       Casado(a)/Vive junto    Branca         C1    1.0    0.0  ...   \n",
       "186351  Separado(a)/Divorciado(a)    Branca         B2    3.0    0.0  ...   \n",
       "186352       Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "186353                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "\n",
       "        BSI_Depression_EB  BSI_Anxiety_EB  BSI_Hostility_EB  BSI_Phobic_EB  \\\n",
       "0                0.333333        0.500000               0.0            0.2   \n",
       "1                0.833333        1.500000               1.0            1.0   \n",
       "4                0.500000        0.666667               0.0            1.6   \n",
       "5                1.833333        1.666667               1.0            1.4   \n",
       "6                1.166667        0.833333               0.4            0.4   \n",
       "7                0.000000        0.000000               0.0            0.0   \n",
       "8                1.000000        1.500000               0.8            1.2   \n",
       "9                0.166667        0.666667               0.2            0.2   \n",
       "10               0.000000        0.833333               0.0            0.0   \n",
       "11               0.166667        0.000000               0.2            0.2   \n",
       "12               0.166667        0.166667               0.0            0.0   \n",
       "15               0.000000        0.000000               0.0            0.0   \n",
       "18               0.166667        0.000000               0.0            0.2   \n",
       "19               1.333333        2.333333               1.6            2.0   \n",
       "20               2.166667        1.833333               2.0            0.4   \n",
       "22               0.166667        0.000000               0.0            0.0   \n",
       "24               0.166667        0.000000               0.4            0.8   \n",
       "25               1.333333        1.166667               0.8            0.4   \n",
       "27               0.333333        0.333333               0.0            0.0   \n",
       "28               0.500000        0.166667               0.2            0.0   \n",
       "29               0.166667        0.000000               0.0            0.0   \n",
       "30               0.166667        1.166667               0.0            1.6   \n",
       "31               0.500000        0.833333               0.2            0.6   \n",
       "32               0.333333        0.500000               0.0            0.2   \n",
       "33               0.000000        0.166667               0.2            0.0   \n",
       "35               1.333333        1.000000               1.0            0.8   \n",
       "36               1.333333        0.666667               0.8            1.2   \n",
       "37               0.333333        0.666667               0.2            1.0   \n",
       "38               2.000000        1.666667               0.6            1.6   \n",
       "40               0.666667        0.333333               0.2            0.6   \n",
       "...                   ...             ...               ...            ...   \n",
       "186306           0.166667        0.500000               0.2            1.2   \n",
       "186307           1.666667        1.666667               0.4            2.0   \n",
       "186311           1.833333        0.833333               1.2            0.8   \n",
       "186314           2.333333        1.500000               1.2            1.8   \n",
       "186317           0.333333        0.166667               0.2            0.0   \n",
       "186321           0.666667        2.333333               3.2            3.4   \n",
       "186322           0.833333        0.666667               0.2            1.4   \n",
       "186323           2.500000        2.000000               0.8            0.8   \n",
       "186325           0.166667        0.000000               0.0            0.0   \n",
       "186327           2.833333        3.000000               1.8            3.6   \n",
       "186328           3.000000        1.666667               0.4            1.6   \n",
       "186330           2.333333        3.333333               1.0            3.8   \n",
       "186331           1.166667        2.333333               2.2            2.4   \n",
       "186333           0.000000        0.000000               0.0            0.4   \n",
       "186334           1.500000        0.500000               1.2            0.2   \n",
       "186335           1.666667        1.000000               1.2            0.8   \n",
       "186336           0.666667        0.500000               0.2            0.4   \n",
       "186338           0.666667        0.666667               2.2            0.2   \n",
       "186339           2.000000        0.333333               0.2            1.2   \n",
       "186341           2.500000        2.500000               2.4            3.0   \n",
       "186342           1.833333        2.166667               1.2            2.6   \n",
       "186344           0.833333        1.333333               0.2            0.8   \n",
       "186345           0.500000        1.000000               0.2            0.6   \n",
       "186346           0.166667        0.000000               0.0            1.0   \n",
       "186347           0.500000        0.333333               0.0            0.4   \n",
       "186349           0.500000        0.333333               0.6            0.0   \n",
       "186350           0.500000        0.500000               0.2            0.4   \n",
       "186351           3.333333        2.000000               1.0            2.6   \n",
       "186352           0.500000        0.166667               0.0            0.0   \n",
       "186353           1.000000        0.666667               0.2            1.6   \n",
       "\n",
       "        BSI_Paranoid_EB  BSI_Psychoticism_EB  WQOL.Fisico  WQOL.Psicologico  \\\n",
       "0                   0.0                  0.0     4.285714          4.166667   \n",
       "1                   1.0                  0.4     2.857143          3.333333   \n",
       "4                   0.4                  0.0     3.428571          3.333333   \n",
       "5                   2.0                  2.4     3.714286          3.333333   \n",
       "6                   0.2                  0.4     3.285714          3.166667   \n",
       "7                   0.0                  0.0     3.857143          4.166667   \n",
       "8                   0.2                  0.6     3.428571          3.000000   \n",
       "9                   0.0                  0.2     4.000000          4.500000   \n",
       "10                  0.2                  0.0     4.000000          4.333333   \n",
       "11                  0.0                  0.0     4.571429          4.833333   \n",
       "12                  0.0                  0.0     4.000000          3.666667   \n",
       "15                  0.4                  0.0     4.857143          5.000000   \n",
       "18                  0.2                  0.0     4.428571          4.333333   \n",
       "19                  1.2                  1.6     4.000000          3.833333   \n",
       "20                  1.4                  1.4     3.285714          2.166667   \n",
       "22                  0.2                  0.2     4.857143          4.833333   \n",
       "24                  0.2                  0.0     4.142857          4.333333   \n",
       "25                  0.2                  0.8     3.857143          2.833333   \n",
       "27                  0.0                  0.0     4.428571          3.500000   \n",
       "28                  0.8                  0.0     4.714286          3.666667   \n",
       "29                  0.4                  0.2     4.000000          4.333333   \n",
       "30                  0.6                  0.0     4.428571          3.666667   \n",
       "31                  0.6                  0.4     4.285714          3.833333   \n",
       "32                  1.6                  0.2     4.285714          3.833333   \n",
       "33                  0.0                  0.0     4.142857          3.833333   \n",
       "35                  1.4                  1.2     3.428571          3.333333   \n",
       "36                  0.4                  1.0     4.285714          3.833333   \n",
       "37                  0.0                  0.0     4.714286          4.166667   \n",
       "38                  0.2                  0.8     3.285714          2.833333   \n",
       "40                  0.4                  0.0     3.857143          3.833333   \n",
       "...                 ...                  ...          ...               ...   \n",
       "186306              0.2                  0.0     4.428571          3.666667   \n",
       "186307              1.0                  2.2     3.714286          2.833333   \n",
       "186311              1.0                  1.2     4.000000          4.166667   \n",
       "186314              1.0                  1.4     3.428571          3.666667   \n",
       "186317              0.2                  0.0     3.857143          4.333333   \n",
       "186321              1.0                  1.2     4.142857          3.666667   \n",
       "186322              0.0                  0.6     3.428571          2.166667   \n",
       "186323              1.8                  1.2     3.142857          3.666667   \n",
       "186325              0.0                  0.0     3.571429          3.666667   \n",
       "186327              2.2                  2.0     1.857143          2.666667   \n",
       "186328              1.2                  1.8     2.000000          2.333333   \n",
       "186330              1.8                  1.6     2.000000          2.500000   \n",
       "186331              1.0                  1.0     2.428571          2.666667   \n",
       "186333              0.2                  0.0     3.571429          4.166667   \n",
       "186334              2.2                  0.6     3.285714          2.500000   \n",
       "186335              1.0                  0.6     2.714286          1.833333   \n",
       "186336              0.6                  0.4     3.428571          3.500000   \n",
       "186338              1.0                  0.8     4.142857          3.500000   \n",
       "186339              1.6                  1.0     4.000000          2.833333   \n",
       "186341              2.2                  2.0     2.714286          2.333333   \n",
       "186342              0.6                  0.0     3.000000          2.500000   \n",
       "186344              1.2                  0.4     3.000000          3.166667   \n",
       "186345              0.8                  0.2     3.571429          3.333333   \n",
       "186346              0.0                  0.0     4.000000          4.333333   \n",
       "186347              0.2                  0.4     4.142857          4.333333   \n",
       "186349              0.4                  0.0     3.857143          2.666667   \n",
       "186350              0.4                  0.0     3.142857          3.333333   \n",
       "186351              1.4                  1.6     2.142857          2.000000   \n",
       "186352              0.0                  0.2     4.285714          4.666667   \n",
       "186353              0.2                  0.2     4.571429          4.166667   \n",
       "\n",
       "        WQOL.RSociais  WQOL_MAmbiente  \n",
       "0            4.000000        3.714286  \n",
       "1            2.333333        3.142857  \n",
       "4            3.000000        4.142857  \n",
       "5            3.666667        3.857143  \n",
       "6            2.666667        3.285714  \n",
       "7            4.666667        4.142857  \n",
       "8            2.666667        3.428571  \n",
       "9            5.000000        3.571429  \n",
       "10           4.000000        4.428571  \n",
       "11           4.333333        4.000000  \n",
       "12           3.333333        2.714286  \n",
       "15           4.333333        3.857143  \n",
       "18           4.666667        3.714286  \n",
       "19           4.000000        3.857143  \n",
       "20           1.333333        2.285714  \n",
       "22           4.000000        3.857143  \n",
       "24           3.333333        3.428571  \n",
       "25           2.666667        3.428571  \n",
       "27           3.666667        3.571429  \n",
       "28           4.333333        3.000000  \n",
       "29           3.000000        2.571429  \n",
       "30           4.000000        3.714286  \n",
       "31           3.666667        3.000000  \n",
       "32           2.333333        4.000000  \n",
       "33           3.333333        3.857143  \n",
       "35           3.333333        3.000000  \n",
       "36           3.333333        2.714286  \n",
       "37           3.000000        4.000000  \n",
       "38           2.333333        2.142857  \n",
       "40           2.333333        2.428571  \n",
       "...               ...             ...  \n",
       "186306       3.333333        4.285714  \n",
       "186307       1.666667        3.714286  \n",
       "186311       5.000000        4.428571  \n",
       "186314       3.333333        3.000000  \n",
       "186317       4.000000        3.857143  \n",
       "186321       3.333333        4.428571  \n",
       "186322       2.666667        4.142857  \n",
       "186323       2.666667        2.571429  \n",
       "186325       3.666667        3.000000  \n",
       "186327       2.333333        2.571429  \n",
       "186328       2.333333        2.428571  \n",
       "186330       2.666667        2.857143  \n",
       "186331       3.333333        2.714286  \n",
       "186333       4.000000        3.285714  \n",
       "186334       2.000000        3.714286  \n",
       "186335       1.666667        2.857143  \n",
       "186336       3.666667        3.142857  \n",
       "186338       3.666667        3.571429  \n",
       "186339       1.666667        3.428571  \n",
       "186341       2.333333        2.571429  \n",
       "186342       3.000000        3.142857  \n",
       "186344       4.000000        2.428571  \n",
       "186345       3.666667        3.000000  \n",
       "186346       3.666667        4.142857  \n",
       "186347       4.000000        4.285714  \n",
       "186349       3.000000        3.428571  \n",
       "186350       2.666667        2.428571  \n",
       "186351       2.666667        3.428571  \n",
       "186352       4.333333        4.285714  \n",
       "186353       4.000000        4.285714  \n",
       "\n",
       "[112726 rows x 100 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "Y1 = data['BSI_Somatization_EB']\n",
    "Y2 = data[whoqol]\n",
    "#data['mean'] = np.round(data['mean']/10)\n",
    "\n",
    "#Y2 = data['\"ARTERIAL_DIAS\"']\n",
    "data.drop(whoqol + bsi ,axis = 1, inplace = True)\n",
    "X = data[bsi_feat]\n",
    "X2 = data[new_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHOQoL_2     4.0\n",
       "WHOQoL_6     4.0\n",
       "WHOQoL_7     4.0\n",
       "WHOQoL_9     4.0\n",
       "WHOQoL_10    4.0\n",
       "WHOQoL_11    3.0\n",
       "WHOQoL_12    3.0\n",
       "WHOQoL_17    4.0\n",
       "WHOQoL_19    4.0\n",
       "WHOQoL_23    5.0\n",
       "WHOQoL_24    4.0\n",
       "WHOQoL_26    3.0\n",
       "BSI_1        1.0\n",
       "BSI_9        0.0\n",
       "BSI_12       0.0\n",
       "BSI_23       0.0\n",
       "BSI_37       0.0\n",
       "BSI_38       1.0\n",
       "BSI_45       0.0\n",
       "BSI_49       0.0\n",
       "Name: 38194, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.iloc[idn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y2 = Y2['WQOL.Fisico']\n",
    "#Y2 = Y2['WQOL.Psicologico']\n",
    "#Y2 = Y2['WQOL.RSociais']\n",
    "#Y2 = Y2['WQOL_MAmbiente']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y1/np.max(Y1)\n",
    "#Y1 = Y1['BSI_GSI']\n",
    "Y2 = Y2/np.max(Y2)\n",
    "#Y2 = Y2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, Y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "     X2, Y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2.loc[185283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(X2_train.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "# Encoder Layers\n",
    "\n",
    "\n",
    "encoded1 = Dense(50, activation = 'tanh')(input_dim)\n",
    "drop1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(50, activation = 'tanh')(encoded1)\n",
    "encoded3 = Dense(50, activation = 'tanh')(encoded2)\n",
    "encoded4 = Dense(50, activation = 'tanh')(encoded3)\n",
    "encoded5 = Dense(50, activation = 'tanh')(encoded4)\n",
    "decoded13 = Dense(1, activation = 'sigmoid')(encoded5)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder = Model(inputs = input_dim, outputs = [decoded13])\n",
    "optimizers.Adam()\n",
    "# Compile the Model\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0469 - val_loss: 0.0424\n",
      "Epoch 2/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0414\n",
      "Epoch 3/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0467\n",
      "Epoch 4/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0397\n",
      "Epoch 5/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0396\n",
      "Epoch 6/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0399\n",
      "Epoch 7/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0396 - val_loss: 0.0399\n",
      "Epoch 8/250\n",
      "591/591 [==============================] - 1s 1000us/step - loss: 0.0394 - val_loss: 0.0399\n",
      "Epoch 9/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0394 - val_loss: 0.0408\n",
      "Epoch 10/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0425\n",
      "Epoch 11/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0393 - val_loss: 0.0395\n",
      "Epoch 12/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0392 - val_loss: 0.0400\n",
      "Epoch 13/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0393 - val_loss: 0.0409\n",
      "Epoch 14/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0392 - val_loss: 0.0392\n",
      "Epoch 15/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0391 - val_loss: 0.0396\n",
      "Epoch 16/250\n",
      "591/591 [==============================] - 1s 996us/step - loss: 0.0391 - val_loss: 0.0396\n",
      "Epoch 17/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0391 - val_loss: 0.0400\n",
      "Epoch 18/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0390 - val_loss: 0.0413\n",
      "Epoch 19/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0391 - val_loss: 0.0392\n",
      "Epoch 20/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0388 - val_loss: 0.0400\n",
      "Epoch 21/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0389 - val_loss: 0.0398\n",
      "Epoch 22/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0390 - val_loss: 0.0414\n",
      "Epoch 23/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 24/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 25/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0387 - val_loss: 0.0402\n",
      "Epoch 26/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0388 - val_loss: 0.0392\n",
      "Epoch 27/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0388 - val_loss: 0.0396\n",
      "Epoch 28/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0387 - val_loss: 0.0397\n",
      "Epoch 29/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0386 - val_loss: 0.0394\n",
      "Epoch 30/250\n",
      "591/591 [==============================] - 1s 991us/step - loss: 0.0387 - val_loss: 0.0394\n",
      "Epoch 31/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0387 - val_loss: 0.0393\n",
      "Epoch 32/250\n",
      "591/591 [==============================] - 1s 1000us/step - loss: 0.0386 - val_loss: 0.0399\n",
      "Epoch 33/250\n",
      "591/591 [==============================] - 1s 991us/step - loss: 0.0388 - val_loss: 0.0393\n",
      "Epoch 34/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0395\n",
      "Epoch 35/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0391\n",
      "Epoch 36/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0403\n",
      "Epoch 37/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0386 - val_loss: 0.0392\n",
      "Epoch 38/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0393\n",
      "Epoch 39/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0396\n",
      "Epoch 40/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0399\n",
      "Epoch 41/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0394\n",
      "Epoch 42/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0385 - val_loss: 0.0418\n",
      "Epoch 43/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0393\n",
      "Epoch 44/250\n",
      "591/591 [==============================] - 1s 987us/step - loss: 0.0385 - val_loss: 0.0390\n",
      "Epoch 45/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0385 - val_loss: 0.0397\n",
      "Epoch 46/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0384 - val_loss: 0.0393\n",
      "Epoch 47/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0383 - val_loss: 0.0396\n",
      "Epoch 48/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 49/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0383 - val_loss: 0.0391\n",
      "Epoch 50/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0384 - val_loss: 0.0394\n",
      "Epoch 51/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0382 - val_loss: 0.0396\n",
      "Epoch 52/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0382 - val_loss: 0.0391\n",
      "Epoch 53/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0383 - val_loss: 0.0399\n",
      "Epoch 54/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0392\n",
      "Epoch 55/250\n",
      "591/591 [==============================] - 1s 987us/step - loss: 0.0382 - val_loss: 0.0398\n",
      "Epoch 56/250\n",
      "591/591 [==============================] - 1s 987us/step - loss: 0.0382 - val_loss: 0.0392\n",
      "Epoch 57/250\n",
      "591/591 [==============================] - 1s 998us/step - loss: 0.0382 - val_loss: 0.0401\n",
      "Epoch 58/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0381 - val_loss: 0.0394\n",
      "Epoch 59/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0394\n",
      "Epoch 60/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0394\n",
      "Epoch 61/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0380 - val_loss: 0.0394\n",
      "Epoch 62/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0380 - val_loss: 0.0393\n",
      "Epoch 63/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0380 - val_loss: 0.0393\n",
      "Epoch 64/250\n",
      "591/591 [==============================] - 1s 996us/step - loss: 0.0380 - val_loss: 0.0392\n",
      "Epoch 65/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0379 - val_loss: 0.0399\n",
      "Epoch 66/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0393\n",
      "Epoch 67/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 68/250\n",
      "591/591 [==============================] - 1s 989us/step - loss: 0.0380 - val_loss: 0.0395\n",
      "Epoch 69/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0379 - val_loss: 0.0396\n",
      "Epoch 70/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0378 - val_loss: 0.0395\n",
      "Epoch 71/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0395\n",
      "Epoch 72/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0397\n",
      "Epoch 73/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0402\n",
      "Epoch 74/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0378 - val_loss: 0.0407\n",
      "Epoch 75/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0394\n",
      "Epoch 76/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0395\n",
      "Epoch 77/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0397\n",
      "Epoch 78/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0400\n",
      "Epoch 79/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0396\n",
      "Epoch 80/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 988us/step - loss: 0.0375 - val_loss: 0.0396\n",
      "Epoch 81/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0376 - val_loss: 0.0400\n",
      "Epoch 82/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0376 - val_loss: 0.0403\n",
      "Epoch 83/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0376 - val_loss: 0.0397\n",
      "Epoch 84/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0395\n",
      "Epoch 85/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0399\n",
      "Epoch 86/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0395\n",
      "Epoch 87/250\n",
      "591/591 [==============================] - 1s 998us/step - loss: 0.0375 - val_loss: 0.0396\n",
      "Epoch 88/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0397\n",
      "Epoch 89/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0374 - val_loss: 0.0395\n",
      "Epoch 90/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 91/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0396\n",
      "Epoch 92/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 93/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0400\n",
      "Epoch 94/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0373 - val_loss: 0.0395\n",
      "Epoch 95/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 96/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 97/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0400\n",
      "Epoch 98/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 99/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0400\n",
      "Epoch 100/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 101/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0397\n",
      "Epoch 102/250\n",
      "591/591 [==============================] - 1s 998us/step - loss: 0.0369 - val_loss: 0.0396\n",
      "Epoch 103/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0395\n",
      "Epoch 104/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 105/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0401\n",
      "Epoch 106/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0399\n",
      "Epoch 107/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0371 - val_loss: 0.0400\n",
      "Epoch 108/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 109/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0371 - val_loss: 0.0401\n",
      "Epoch 110/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0367 - val_loss: 0.0397\n",
      "Epoch 111/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 112/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 113/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0397\n",
      "Epoch 114/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 115/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0367 - val_loss: 0.0407\n",
      "Epoch 116/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0400\n",
      "Epoch 117/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0401\n",
      "Epoch 118/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0367 - val_loss: 0.0403\n",
      "Epoch 119/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 120/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0400\n",
      "Epoch 121/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0366 - val_loss: 0.0400\n",
      "Epoch 122/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0365 - val_loss: 0.0404\n",
      "Epoch 123/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0365 - val_loss: 0.0399\n",
      "Epoch 124/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0366 - val_loss: 0.0400\n",
      "Epoch 125/250\n",
      "591/591 [==============================] - 1s 996us/step - loss: 0.0363 - val_loss: 0.0399\n",
      "Epoch 126/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0364 - val_loss: 0.0400\n",
      "Epoch 127/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0364 - val_loss: 0.0405\n",
      "Epoch 128/250\n",
      "591/591 [==============================] - 1s 994us/step - loss: 0.0363 - val_loss: 0.0401\n",
      "Epoch 129/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0364 - val_loss: 0.0402\n",
      "Epoch 130/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0364 - val_loss: 0.0401\n",
      "Epoch 131/250\n",
      "591/591 [==============================] - 1s 1000us/step - loss: 0.0363 - val_loss: 0.0403\n",
      "Epoch 132/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0364 - val_loss: 0.0400\n",
      "Epoch 133/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0401\n",
      "Epoch 134/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0364 - val_loss: 0.0402\n",
      "Epoch 135/250\n",
      "591/591 [==============================] - 1s 988us/step - loss: 0.0363 - val_loss: 0.0403\n",
      "Epoch 136/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0364 - val_loss: 0.0402\n",
      "Epoch 137/250\n",
      "591/591 [==============================] - 1s 986us/step - loss: 0.0362 - val_loss: 0.0400\n",
      "Epoch 138/250\n",
      "591/591 [==============================] - 1s 991us/step - loss: 0.0362 - val_loss: 0.0403\n",
      "Epoch 139/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0409\n",
      "Epoch 140/250\n",
      "591/591 [==============================] - 1s 991us/step - loss: 0.0361 - val_loss: 0.0402\n",
      "Epoch 141/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0403\n",
      "Epoch 142/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0402\n",
      "Epoch 143/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0360 - val_loss: 0.0400\n",
      "Epoch 144/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0407\n",
      "Epoch 145/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0401\n",
      "Epoch 146/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0360 - val_loss: 0.0403\n",
      "Epoch 147/250\n",
      "591/591 [==============================] - 1s 998us/step - loss: 0.0360 - val_loss: 0.0401\n",
      "Epoch 148/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0408\n",
      "Epoch 149/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0401\n",
      "Epoch 150/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0399\n",
      "Epoch 151/250\n",
      "591/591 [==============================] - 1s 1000us/step - loss: 0.0358 - val_loss: 0.0402\n",
      "Epoch 152/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0403\n",
      "Epoch 153/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0401\n",
      "Epoch 154/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0402\n",
      "Epoch 155/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0403\n",
      "Epoch 156/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0402\n",
      "Epoch 157/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0402\n",
      "Epoch 158/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0357 - val_loss: 0.0407\n",
      "Epoch 159/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 991us/step - loss: 0.0357 - val_loss: 0.0403\n",
      "Epoch 160/250\n",
      "591/591 [==============================] - 1s 990us/step - loss: 0.0356 - val_loss: 0.0404\n",
      "Epoch 161/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0357 - val_loss: 0.0403\n",
      "Epoch 162/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0402\n",
      "Epoch 163/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 164/250\n",
      "591/591 [==============================] - 1s 999us/step - loss: 0.0356 - val_loss: 0.0404\n",
      "Epoch 165/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0403\n",
      "Epoch 166/250\n",
      "591/591 [==============================] - 1s 992us/step - loss: 0.0356 - val_loss: 0.0403\n",
      "Epoch 167/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0407\n",
      "Epoch 168/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0408\n",
      "Epoch 169/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0404\n",
      "Epoch 170/250\n",
      "591/591 [==============================] - 1s 995us/step - loss: 0.0355 - val_loss: 0.0402\n",
      "Epoch 171/250\n",
      "591/591 [==============================] - 1s 993us/step - loss: 0.0354 - val_loss: 0.0403\n",
      "Epoch 172/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0402\n",
      "Epoch 173/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 174/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0406\n",
      "Epoch 175/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0404\n",
      "Epoch 176/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 177/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0402\n",
      "Epoch 178/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0410\n",
      "Epoch 179/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0404\n",
      "Epoch 180/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0404\n",
      "Epoch 181/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0406\n",
      "Epoch 182/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0408\n",
      "Epoch 183/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0405\n",
      "Epoch 184/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0406\n",
      "Epoch 185/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 186/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0406\n",
      "Epoch 187/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0404\n",
      "Epoch 188/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0407\n",
      "Epoch 189/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 190/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 191/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0413\n",
      "Epoch 192/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0404\n",
      "Epoch 193/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0403\n",
      "Epoch 194/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0405\n",
      "Epoch 195/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0408\n",
      "Epoch 196/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0405\n",
      "Epoch 197/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0403\n",
      "Epoch 198/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0405\n",
      "Epoch 199/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0404\n",
      "Epoch 200/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0408\n",
      "Epoch 201/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0406\n",
      "Epoch 202/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0404\n",
      "Epoch 203/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0405\n",
      "Epoch 204/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0404\n",
      "Epoch 205/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0404\n",
      "Epoch 206/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0404\n",
      "Epoch 207/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0406\n",
      "Epoch 208/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0405\n",
      "Epoch 209/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0406\n",
      "Epoch 210/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0412\n",
      "Epoch 211/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0406\n",
      "Epoch 212/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0405\n",
      "Epoch 213/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0405\n",
      "Epoch 214/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0406\n",
      "Epoch 215/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0406\n",
      "Epoch 216/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0407\n",
      "Epoch 217/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0407\n",
      "Epoch 218/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0408\n",
      "Epoch 219/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0407\n",
      "Epoch 220/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0408\n",
      "Epoch 221/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0406\n",
      "Epoch 222/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0407\n",
      "Epoch 223/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0410\n",
      "Epoch 224/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0406\n",
      "Epoch 225/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0408\n",
      "Epoch 226/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0411\n",
      "Epoch 227/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0407\n",
      "Epoch 228/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0406\n",
      "Epoch 229/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0406\n",
      "Epoch 230/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0406\n",
      "Epoch 231/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0408\n",
      "Epoch 232/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0406\n",
      "Epoch 233/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0409\n",
      "Epoch 234/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0407\n",
      "Epoch 235/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0407\n",
      "Epoch 236/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0407\n",
      "Epoch 237/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0406\n",
      "Epoch 238/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0411\n",
      "Epoch 239/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0407\n",
      "Epoch 240/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0407\n",
      "Epoch 241/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0408\n",
      "Epoch 242/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0408\n",
      "Epoch 243/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0408\n",
      "Epoch 244/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0409\n",
      "Epoch 245/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0406\n",
      "Epoch 246/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0408\n",
      "Epoch 247/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0410\n",
      "Epoch 248/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0409\n",
      "Epoch 249/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0407\n",
      "Epoch 250/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0340 - val_loss: 0.0409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ad8cf3748>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=30,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "autoencoder.fit(x = X2_train, y = y_train, epochs = 250, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                 validation_data=(X2_test, y_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "#     X2, Y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = autoencoder.predict(X2_test)\n",
    "#X2_train['pred'] = pred\n",
    "#X2_train['BSI_1'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = autoencoder.predict(X2_train.drop('pred',axis=1))\n",
    "#X2_train['cf'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X2_train[X2_train['cf']- X2_train['pred']>0.001])/len(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10070564516127954"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298181889958025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04091602052277486"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r2_score(pred,y_test))\n",
    "mean_absolute_error(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(X2.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "# Encoder Layers\n",
    "\n",
    "encoded1 = Dense(50, activation = 'tanh')(input_dim)\n",
    "drop1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(50, activation = 'tanh')(encoded1)\n",
    "encoded3 = Dense(50, activation = 'tanh')(encoded2)\n",
    "encoded4 = Dense(50, activation = 'tanh')(encoded3)\n",
    "encoded5 = Dense(50, activation = 'tanh')(encoded4)\n",
    "decoded13 = Dense(1, activation = 'sigmoid')(encoded5)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder2 = Model(inputs = input_dim, outputs = [decoded13])\n",
    "\n",
    "# Compile the Model\n",
    "autoencoder2.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0559 - val_loss: 0.0494\n",
      "Epoch 2/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0492 - val_loss: 0.0487\n",
      "Epoch 3/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0479 - val_loss: 0.0478\n",
      "Epoch 4/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0471 - val_loss: 0.0461\n",
      "Epoch 5/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0466 - val_loss: 0.0458\n",
      "Epoch 6/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0462 - val_loss: 0.0457\n",
      "Epoch 7/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0462 - val_loss: 0.0471\n",
      "Epoch 8/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0460 - val_loss: 0.0463\n",
      "Epoch 9/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0461 - val_loss: 0.0489\n",
      "Epoch 10/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0458 - val_loss: 0.0464\n",
      "Epoch 11/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0458 - val_loss: 0.0501\n",
      "Epoch 12/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0457 - val_loss: 0.0460\n",
      "Epoch 13/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0459 - val_loss: 0.0466\n",
      "Epoch 14/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0456 - val_loss: 0.0491\n",
      "Epoch 15/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0460\n",
      "Epoch 16/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0455 - val_loss: 0.0473\n",
      "Epoch 17/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0456\n",
      "Epoch 18/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0465\n",
      "Epoch 19/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0454 - val_loss: 0.0465\n",
      "Epoch 20/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0474\n",
      "Epoch 21/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0451 - val_loss: 0.0464\n",
      "Epoch 22/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0463\n",
      "Epoch 23/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0453 - val_loss: 0.0457\n",
      "Epoch 24/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0451 - val_loss: 0.0484\n",
      "Epoch 25/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0452\n",
      "Epoch 26/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0451 - val_loss: 0.0451\n",
      "Epoch 27/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0450 - val_loss: 0.0454\n",
      "Epoch 28/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0450 - val_loss: 0.0452\n",
      "Epoch 29/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0465\n",
      "Epoch 30/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0453\n",
      "Epoch 31/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0448 - val_loss: 0.0449\n",
      "Epoch 32/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0448 - val_loss: 0.0458\n",
      "Epoch 33/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0455\n",
      "Epoch 34/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0451\n",
      "Epoch 35/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0447 - val_loss: 0.0452\n",
      "Epoch 36/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0447 - val_loss: 0.0462\n",
      "Epoch 37/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0449 - val_loss: 0.0449\n",
      "Epoch 38/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0447 - val_loss: 0.0460\n",
      "Epoch 39/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0455\n",
      "Epoch 40/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0449\n",
      "Epoch 41/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0449\n",
      "Epoch 42/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0468\n",
      "Epoch 43/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0445 - val_loss: 0.0459\n",
      "Epoch 44/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0446 - val_loss: 0.0451\n",
      "Epoch 45/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0445 - val_loss: 0.0453\n",
      "Epoch 46/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0444 - val_loss: 0.0456\n",
      "Epoch 47/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0445 - val_loss: 0.0449\n",
      "Epoch 48/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0444 - val_loss: 0.0451\n",
      "Epoch 49/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0444 - val_loss: 0.0452\n",
      "Epoch 50/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0443 - val_loss: 0.0489\n",
      "Epoch 51/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0443 - val_loss: 0.0472\n",
      "Epoch 52/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0443 - val_loss: 0.0450\n",
      "Epoch 53/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0443 - val_loss: 0.0451\n",
      "Epoch 54/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0442 - val_loss: 0.0455\n",
      "Epoch 55/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0442 - val_loss: 0.0454\n",
      "Epoch 56/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0441 - val_loss: 0.0451\n",
      "Epoch 57/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0450\n",
      "Epoch 58/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0522\n",
      "Epoch 59/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0441 - val_loss: 0.0451\n",
      "Epoch 60/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0488\n",
      "Epoch 61/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0450\n",
      "Epoch 62/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0454\n",
      "Epoch 63/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0440 - val_loss: 0.0451\n",
      "Epoch 64/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0439 - val_loss: 0.0450\n",
      "Epoch 65/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0438 - val_loss: 0.0458\n",
      "Epoch 66/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0438 - val_loss: 0.0453\n",
      "Epoch 67/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0437 - val_loss: 0.0452\n",
      "Epoch 68/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0437 - val_loss: 0.0466\n",
      "Epoch 69/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0460\n",
      "Epoch 70/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0457\n",
      "Epoch 71/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0460\n",
      "Epoch 72/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0468\n",
      "Epoch 73/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0435 - val_loss: 0.0450\n",
      "Epoch 74/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0435 - val_loss: 0.0455\n",
      "Epoch 75/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0435 - val_loss: 0.0451\n",
      "Epoch 76/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0434 - val_loss: 0.0474\n",
      "Epoch 77/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0435 - val_loss: 0.0462\n",
      "Epoch 78/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0436 - val_loss: 0.0457\n",
      "Epoch 79/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0432 - val_loss: 0.0459\n",
      "Epoch 80/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0433 - val_loss: 0.0455\n",
      "Epoch 81/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0433 - val_loss: 0.0454\n",
      "Epoch 82/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0432 - val_loss: 0.0452\n",
      "Epoch 83/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0452\n",
      "Epoch 84/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0453\n",
      "Epoch 85/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0432 - val_loss: 0.0453\n",
      "Epoch 86/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0461\n",
      "Epoch 87/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0458\n",
      "Epoch 88/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0432 - val_loss: 0.0454\n",
      "Epoch 89/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0431 - val_loss: 0.0456\n",
      "Epoch 90/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0429 - val_loss: 0.0455\n",
      "Epoch 91/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0429 - val_loss: 0.0452\n",
      "Epoch 92/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0466\n",
      "Epoch 93/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0430 - val_loss: 0.0455\n",
      "Epoch 94/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0455\n",
      "Epoch 95/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0464\n",
      "Epoch 96/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0428 - val_loss: 0.0455\n",
      "Epoch 97/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0427 - val_loss: 0.0460\n",
      "Epoch 98/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0427 - val_loss: 0.0459\n",
      "Epoch 99/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0426 - val_loss: 0.0461\n",
      "Epoch 100/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0427 - val_loss: 0.0457\n",
      "Epoch 101/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0427 - val_loss: 0.0455\n",
      "Epoch 102/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0426 - val_loss: 0.0458\n",
      "Epoch 103/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0425 - val_loss: 0.0455\n",
      "Epoch 104/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0425 - val_loss: 0.0456\n",
      "Epoch 105/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0424 - val_loss: 0.0456\n",
      "Epoch 106/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0424 - val_loss: 0.0458\n",
      "Epoch 107/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0423 - val_loss: 0.0457\n",
      "Epoch 108/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0424 - val_loss: 0.0462\n",
      "Epoch 109/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0425 - val_loss: 0.0455\n",
      "Epoch 110/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0423 - val_loss: 0.0467\n",
      "Epoch 111/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0460\n",
      "Epoch 112/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0469\n",
      "Epoch 113/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0463\n",
      "Epoch 114/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0461\n",
      "Epoch 115/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0467\n",
      "Epoch 116/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0422 - val_loss: 0.0460\n",
      "Epoch 117/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0459\n",
      "Epoch 118/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0420 - val_loss: 0.0460\n",
      "Epoch 119/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0421 - val_loss: 0.0463\n",
      "Epoch 120/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0420 - val_loss: 0.0459\n",
      "Epoch 121/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0420 - val_loss: 0.0461\n",
      "Epoch 122/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0470\n",
      "Epoch 123/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0463\n",
      "Epoch 124/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0418 - val_loss: 0.0461\n",
      "Epoch 125/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0418 - val_loss: 0.0482\n",
      "Epoch 126/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0463\n",
      "Epoch 127/250\n",
      "591/591 [==============================] - 1s 2ms/step - loss: 0.0417 - val_loss: 0.0461\n",
      "Epoch 128/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0419 - val_loss: 0.0464\n",
      "Epoch 129/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0417 - val_loss: 0.0463\n",
      "Epoch 130/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0417 - val_loss: 0.0461\n",
      "Epoch 131/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0466\n",
      "Epoch 132/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0462\n",
      "Epoch 133/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0461\n",
      "Epoch 134/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0464\n",
      "Epoch 135/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0416 - val_loss: 0.0468\n",
      "Epoch 136/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0468\n",
      "Epoch 137/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0464\n",
      "Epoch 138/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0415 - val_loss: 0.0463\n",
      "Epoch 139/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0414 - val_loss: 0.0462\n",
      "Epoch 140/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0464\n",
      "Epoch 141/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0414 - val_loss: 0.0464\n",
      "Epoch 142/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0463\n",
      "Epoch 143/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0412 - val_loss: 0.0462\n",
      "Epoch 144/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0465\n",
      "Epoch 145/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0413 - val_loss: 0.0465\n",
      "Epoch 146/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0412 - val_loss: 0.0464\n",
      "Epoch 147/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0411 - val_loss: 0.0464\n",
      "Epoch 148/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0412 - val_loss: 0.0463\n",
      "Epoch 149/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0411 - val_loss: 0.0464\n",
      "Epoch 150/250\n",
      "591/591 [==============================] - 1s 2ms/step - loss: 0.0412 - val_loss: 0.0467\n",
      "Epoch 151/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0411 - val_loss: 0.0474\n",
      "Epoch 152/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0411 - val_loss: 0.0467\n",
      "Epoch 153/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0410 - val_loss: 0.0465\n",
      "Epoch 154/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0410 - val_loss: 0.0468\n",
      "Epoch 155/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0410 - val_loss: 0.0467\n",
      "Epoch 156/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0466\n",
      "Epoch 157/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0465\n",
      "Epoch 158/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0465\n",
      "Epoch 159/250\n",
      "591/591 [==============================] - 1s 2ms/step - loss: 0.0410 - val_loss: 0.0476\n",
      "Epoch 160/250\n",
      "591/591 [==============================] - 1s 2ms/step - loss: 0.0411 - val_loss: 0.0464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0467\n",
      "Epoch 162/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0466\n",
      "Epoch 163/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0468\n",
      "Epoch 164/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0470\n",
      "Epoch 165/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0476\n",
      "Epoch 166/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0409 - val_loss: 0.0469\n",
      "Epoch 167/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0477\n",
      "Epoch 168/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0469\n",
      "Epoch 169/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0466\n",
      "Epoch 170/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0472\n",
      "Epoch 171/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0468\n",
      "Epoch 172/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0472\n",
      "Epoch 173/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0485\n",
      "Epoch 174/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0469\n",
      "Epoch 175/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0407 - val_loss: 0.0470\n",
      "Epoch 176/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0469\n",
      "Epoch 177/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0469\n",
      "Epoch 178/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0469\n",
      "Epoch 179/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0471\n",
      "Epoch 180/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0406 - val_loss: 0.0469\n",
      "Epoch 181/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0468\n",
      "Epoch 182/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0405 - val_loss: 0.0469\n",
      "Epoch 183/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0403 - val_loss: 0.0470\n",
      "Epoch 184/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0403 - val_loss: 0.0471\n",
      "Epoch 185/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0403 - val_loss: 0.0469\n",
      "Epoch 186/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0468\n",
      "Epoch 187/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0469\n",
      "Epoch 188/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0404 - val_loss: 0.0469\n",
      "Epoch 189/250\n",
      "591/591 [==============================] - 1s 998us/step - loss: 0.0403 - val_loss: 0.0471\n",
      "Epoch 190/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0404 - val_loss: 0.0471\n",
      "Epoch 191/250\n",
      "591/591 [==============================] - 1s 997us/step - loss: 0.0401 - val_loss: 0.0475\n",
      "Epoch 192/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0471\n",
      "Epoch 193/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0403 - val_loss: 0.0475\n",
      "Epoch 194/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0471\n",
      "Epoch 195/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0471\n",
      "Epoch 196/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0481\n",
      "Epoch 197/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0477\n",
      "Epoch 198/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0474\n",
      "Epoch 199/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0472\n",
      "Epoch 200/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0471\n",
      "Epoch 201/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0475\n",
      "Epoch 202/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0402 - val_loss: 0.0477\n",
      "Epoch 203/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0475\n",
      "Epoch 204/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0471\n",
      "Epoch 205/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0474\n",
      "Epoch 206/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0474\n",
      "Epoch 207/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0474\n",
      "Epoch 208/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0400 - val_loss: 0.0473\n",
      "Epoch 209/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0473\n",
      "Epoch 210/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0474\n",
      "Epoch 211/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0475\n",
      "Epoch 212/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0475\n",
      "Epoch 213/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0471\n",
      "Epoch 214/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0475\n",
      "Epoch 215/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0484\n",
      "Epoch 216/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0477\n",
      "Epoch 217/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0482\n",
      "Epoch 218/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0474\n",
      "Epoch 219/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0474\n",
      "Epoch 220/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0477\n",
      "Epoch 221/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0473\n",
      "Epoch 222/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0473\n",
      "Epoch 223/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0474\n",
      "Epoch 224/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0476\n",
      "Epoch 225/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0475\n",
      "Epoch 226/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0478\n",
      "Epoch 227/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0487\n",
      "Epoch 228/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0475\n",
      "Epoch 229/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0487\n",
      "Epoch 230/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0480\n",
      "Epoch 231/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0476\n",
      "Epoch 232/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0475\n",
      "Epoch 233/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0480\n",
      "Epoch 234/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0475\n",
      "Epoch 235/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0482\n",
      "Epoch 236/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0479\n",
      "Epoch 237/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0477\n",
      "Epoch 238/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0476\n",
      "Epoch 239/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0475\n",
      "Epoch 240/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0473\n",
      "Epoch 241/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0478\n",
      "Epoch 242/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0478\n",
      "Epoch 243/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0478\n",
      "Epoch 244/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0479\n",
      "Epoch 245/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0476\n",
      "Epoch 246/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0476\n",
      "Epoch 247/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0477\n",
      "Epoch 248/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0393 - val_loss: 0.0479\n",
      "Epoch 249/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0477\n",
      "Epoch 250/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ad6eb94e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=30,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "autoencoder2.fit(x = X2_train, y = y2_train, epochs = 250, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                 validation_data=(X2_test, y2_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = autoencoder2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "     X2, Y2, test_size=0.33, random_state=42)\n",
    "#pred = autoencoder2.predict(X2_train)\n",
    "#X2_train['pred'] = pred\n",
    "#X2_train['WHOQoL_11'] = 1\n",
    "#pred = autoencoder2.predict(X2_train.drop('pred',axis=1))\n",
    "#X2_train['cf'] = pred\n",
    "#len(X2_train[X2_train['cf']- X2_train['pred']>0.001])/len(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8503548 ],\n",
       "       [0.6943644 ],\n",
       "       [0.5513723 ],\n",
       "       [0.95602685],\n",
       "       [0.87793744]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91267     0.885714\n",
       "121226    0.742857\n",
       "98895     0.514286\n",
       "14001     0.942857\n",
       "14356     0.914286\n",
       "Name: WQOL.Fisico, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7538303126981083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.047897559578906734"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(r2_score(pred2,y2_test))\n",
    "mean_absolute_error(pred2,y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train2 = pd.DataFrame(autoencoder2.predict(X2_test))\n",
    "encoded_train2 = encoded_train2.add_prefix('feature_')\n",
    "encoded_train = pd.DataFrame(autoencoder.predict(X2_test))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test = y_test.values - encoded_train['feature_0']\n",
    "error_test2 = y2_test.values - encoded_train2['feature_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train2 = pd.DataFrame(autoencoder2.predict(X2_train))\n",
    "encoded_train2 = encoded_train2.add_prefix('feature_')\n",
    "encoded_train = pd.DataFrame(autoencoder.predict(X2_train))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_train.values - encoded_train['feature_0']\n",
    "error2 = y2_train.values - encoded_train2['feature_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WHOQoL_2</th>\n",
       "      <th>WHOQoL_6</th>\n",
       "      <th>WHOQoL_7</th>\n",
       "      <th>WHOQoL_9</th>\n",
       "      <th>WHOQoL_10</th>\n",
       "      <th>WHOQoL_11</th>\n",
       "      <th>WHOQoL_12</th>\n",
       "      <th>WHOQoL_17</th>\n",
       "      <th>WHOQoL_19</th>\n",
       "      <th>WHOQoL_23</th>\n",
       "      <th>WHOQoL_24</th>\n",
       "      <th>WHOQoL_26</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_9</th>\n",
       "      <th>BSI_12</th>\n",
       "      <th>BSI_23</th>\n",
       "      <th>BSI_37</th>\n",
       "      <th>BSI_38</th>\n",
       "      <th>BSI_45</th>\n",
       "      <th>BSI_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119590</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159619</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163257</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16647</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114054</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WHOQoL_2  WHOQoL_6  WHOQoL_7  WHOQoL_9  WHOQoL_10  WHOQoL_11  \\\n",
       "119590       4.0       4.0       3.0       3.0        3.0        3.0   \n",
       "159619       5.0       5.0       5.0       5.0        4.0        5.0   \n",
       "163257       3.0       2.0       5.0       3.0        2.0        5.0   \n",
       "16647        3.0       4.0       3.0       3.0        3.0        4.0   \n",
       "114054       3.0       3.0       2.0       2.0        1.0        4.0   \n",
       "\n",
       "        WHOQoL_12  WHOQoL_17  WHOQoL_19  WHOQoL_23  WHOQoL_24  WHOQoL_26  \\\n",
       "119590        2.0        2.0        2.0        4.0        1.0        4.0   \n",
       "159619        5.0        5.0        5.0        5.0        2.0        5.0   \n",
       "163257        3.0        4.0        4.0        2.0        4.0        1.0   \n",
       "16647         3.0        4.0        4.0        4.0        3.0        4.0   \n",
       "114054        3.0        1.0        3.0        1.0        4.0        3.0   \n",
       "\n",
       "        BSI_1  BSI_9  BSI_12  BSI_23  BSI_37  BSI_38  BSI_45  BSI_49  \n",
       "119590    2.0    0.0     2.0     0.0     0.0     2.0     0.0     0.0  \n",
       "159619    0.0    0.0     0.0     0.0     0.0     0.0     0.0     0.0  \n",
       "163257    2.0    1.0     1.0     2.0     1.0     3.0     0.0     2.0  \n",
       "16647     1.0    0.0     0.0     0.0     0.0     1.0     0.0     0.0  \n",
       "114054    3.0    0.0     0.0     0.0     1.0     2.0     0.0     2.0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X2_train['error'] = error.values\n",
    "X2_test['error'] = error_test.values\n",
    "X2_train['y'] = y_train.values\n",
    "X2_test['y'] = y_test.values\n",
    "\n",
    "X2_train['error2'] = error2.values\n",
    "X2_test['error2'] = error_test2.values\n",
    "X2_train['y2'] = y2_train.values\n",
    "X2_test['y2'] = y2_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_encoder_train = X_train.merge(X2_train,left_index=True,right_index=True)\n",
    "#df_encoder_test = X_test.merge(X2_test,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(df_encoder_train.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "input_dim2 = Input(shape = (ncol - 4, ))\n",
    "# Encoder Layers\n",
    "encoded1 = Dense(40, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(20, activation = 'relu')(encoded1)\n",
    "encoded5 = Dense(5, activation = 'relu')(encoded2)\n",
    "encoded13 = Dense(encoding_dim, activation = 'linear')(encoded5)\n",
    "merged = keras.layers.concatenate([encoded13, input_dim2], axis=-1)\n",
    "# Decoder Layers\n",
    "decoded1 = Dense(100, activation = 'relu')(merged)\n",
    "decoded2 = Dense(500, activation = 'relu')(decoded1)\n",
    "#drop = Dropout(0.05)(decoded2)\n",
    "decoded3 = Dense(500, activation = 'relu')(decoded2)\n",
    "decoded4 = Dense(250, activation = 'relu')(decoded3)\n",
    "decoded5 = Dense(50, activation = 'relu')(decoded4)\n",
    "#drop2 = Dropout(0.)(decoded4)\n",
    "#decoded5 = Dense(50, activation = 'tanh')(drop2)\n",
    "\n",
    "decoded13 = Dense(2, activation = 'sigmoid')(decoded4)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "counter = Model(inputs = [input_dim, input_dim2], outputs = [decoded13])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr= 0.0001)\n",
    "# Compile the Model\n",
    "counter.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1a680e14a8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.load_weights('./models/phy_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0080 - val_loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f155c457128>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=1000,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "counter.fit(x = [df_encoder_train, df_features_train], y = df_outs_train, epochs = 500, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                validation_data=([df_encoder_test,df_features_test],df_outs_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter.save('./models/phy_model2')\n",
    "#counter.load_weights('./models/phy_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = pd.DataFrame(counter.predict([df_encoder_test,df_features_test]))\n",
    "encoded_test = encoded_test.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1719     0.070030\n",
       "7444     0.211652\n",
       "4709     0.250505\n",
       "20642    0.000002\n",
       "9026     0.105828\n",
       "Name: feature_0, dtype: float32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_test['feature_0']).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0007735599631496018, 0.021859456957279266)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(encoded_test['feature_0'], df_outs_test['y']), mean_absolute_error(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.4913799515058345e-06, 0.0016523092948133276)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(encoded_test['feature_0'], df_outs_test['y']), mean_squared_error(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998121474998052, 0.9032531779014428)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(encoded_test['feature_0'], df_outs_test['y']), r2_score(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0007465450516193247, 0.016653817274958925)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(encoded_train['feature_0'], df_outs_train['y']), mean_absolute_error(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.580251869192855e-06, 0.0008499056217122004)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(encoded_train['feature_0'], df_outs_train['y']), mean_squared_error(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998597474658634, 0.9501384038577394)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(encoded_train['feature_0'], df_outs_train['y']), r2_score(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ind = 59\n",
    "encoded_train.iloc[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_print = []#list(data.columns)[42:141]\n",
    "#new_feat_print += [\n",
    "#    'WHOQoL_8', 'WHOQoL_9',\n",
    "#    'WHOQoL_12','WHOQoL_14', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', \n",
    "#             'BSI_9', 'BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "#            ]\n",
    "m=1\n",
    "val =1\n",
    "equal_limit = 0.01\n",
    "        \n",
    "\n",
    "if m == 1:\n",
    "    new_feat_print = [\n",
    "           \n",
    "           'WHOQoL_2', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', 'WHOQoL_10', 'WHOQoL_11', \n",
    "    'WHOQoL_12', 'WHOQoL_17', 'WHOQoL_19', 'WHOQoL_23', 'WHOQoL_24','WHOQoL_26'            \n",
    "    #'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]\n",
    "if m==2:\n",
    "    new_feat_print = [\n",
    "    \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73030\n",
      "74287\n",
      "74443\n",
      "73908\n",
      "74499\n",
      "72731\n",
      "71126\n",
      "72878\n",
      "72535\n",
      "73734\n",
      "71181\n",
      "72162\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    print(len(df_encoder_train))\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04578940161577434\n",
      "0.375368503237444\n",
      "0.06940880942466048\n",
      "0.08152026844184662\n",
      "0.014027033919918388\n",
      "0.07861847080337132\n",
      "0.04402047071394427\n",
      "0.006504020417684349\n",
      "0.04692906872544289\n",
      "0.08564569940597282\n",
      "0.052514013571037216\n",
      "0.5728361187328511\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    print (pup)\n",
    "    #print (pdo)\n",
    "    #print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877187457209366\n",
      "0.08154858858212069\n",
      "0.8181293069865535\n",
      "0.09850083888077069\n",
      "0.9684827984268245\n",
      "0.8019001526171784\n",
      "0.26114219835222\n",
      "0.9857432970169324\n",
      "0.8219755979871786\n",
      "0.8166788727045867\n",
      "0.7226507073516809\n",
      "0.08741442864665613\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    #print (pup)\n",
    "    print (pdo)\n",
    "    #print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06571272079967137\n",
      "0.6912918814866665\n",
      "0.10994989455019276\n",
      "0.820587757752882\n",
      "0.01895327454059786\n",
      "0.09330271823569042\n",
      "0.689101031971431\n",
      "0.008466203792639754\n",
      "0.12858619976563038\n",
      "0.09324056744514064\n",
      "0.2221379300656074\n",
      "0.4798231756326044\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    #print (pup)\n",
    "    #print (pdo)\n",
    "    print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -4.965067e-05\n",
       "1        1.564037e-09\n",
       "2       -1.677871e-04\n",
       "3        6.026834e-03\n",
       "4        4.348606e-03\n",
       "5       -3.638872e-08\n",
       "6       -7.438660e-05\n",
       "7        4.350543e-04\n",
       "8       -3.494918e-04\n",
       "9        1.578753e-16\n",
       "10       1.212358e-04\n",
       "11      -2.623450e-08\n",
       "12      -1.397729e-04\n",
       "13       4.687995e-03\n",
       "14       1.873841e-04\n",
       "15      -1.316965e-04\n",
       "16      -3.129190e-09\n",
       "17       2.582028e-08\n",
       "18       1.076399e-05\n",
       "19       3.083944e-03\n",
       "20       2.024323e-03\n",
       "21      -2.799741e-09\n",
       "22       5.200624e-03\n",
       "23      -5.158782e-05\n",
       "24       5.476750e-09\n",
       "25       1.681367e-09\n",
       "26      -1.046065e-06\n",
       "27       1.369715e-03\n",
       "28      -6.181002e-05\n",
       "29       2.888918e-03\n",
       "             ...     \n",
       "74722    2.844840e-03\n",
       "74723   -9.730442e-08\n",
       "74724   -2.999390e-10\n",
       "74725    3.378451e-03\n",
       "74726    1.227856e-04\n",
       "74727    1.287997e-03\n",
       "74728    4.825890e-04\n",
       "74729   -1.381934e-03\n",
       "74730   -3.979111e-07\n",
       "74731   -3.682792e-03\n",
       "74732    4.440546e-05\n",
       "74733   -3.067592e-09\n",
       "74734    2.290100e-03\n",
       "74735   -1.999545e-09\n",
       "74736    8.076429e-05\n",
       "74737   -3.439784e-04\n",
       "74738    6.154180e-05\n",
       "74739    3.565159e-02\n",
       "74740    1.538209e-07\n",
       "74741   -1.528554e-10\n",
       "74742   -9.037256e-04\n",
       "74743   -3.265837e-12\n",
       "74744    3.438693e-02\n",
       "74745    3.415048e-03\n",
       "74746   -3.611514e-10\n",
       "74747    3.155622e-02\n",
       "74748   -9.876566e-08\n",
       "74749    1.598187e-08\n",
       "74750    5.599767e-03\n",
       "74751   -3.695623e-06\n",
       "Name: feature_0, Length: 74752, dtype: float32"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0_d - f0_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7478488087654114 0.7439701557159424 WHOQoL_6\n",
      "0.7501007914543152 0.746462345123291 WHOQoL_26\n",
      "0.778795599937439 0.7268580794334412 BSI_23\n",
      "0.778795599937439 0.6921207904815674 BSI_37\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat:\n",
    "    #print(feata)\n",
    "    value = 5\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0'].median()\n",
    "    f1_a = encoded_train['feature_1'].median()\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0'].median()\n",
    "    f1_d = encoded_train['feature_1'].median()\n",
    "    if f1_a> f1_d:\n",
    "        print(f1_a,f1_d,feata)\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "#feata = 'BSI_17'\n",
    "#feata = 'BSI_46'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-79-eaadf95b78a1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-79-eaadf95b78a1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    'WHOQoL_17', 'WHOQoL_10',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "'WHOQoL_1','WHOQoL_6','WHOQoL_9','WHOQoL_14','WHOQoL_19', 'WHOQoL_23',\n",
    "             'WHOQoL_17', 'WHOQoL_10',\n",
    "             'BSI_9', 'BSI_49', 'BSI_45','BSI_38','BSI_12', 'BSI_37', 'BSI_23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features_train[feata] = 1\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train[feata] = 5\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "\n",
    "feata = 'WHOQoL_17'\n",
    "value = 1\n",
    "idn = 851\n",
    "#df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "#df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "#print(encoded_train['feature_0'].iloc[idn])\n",
    "#print(encoded_train['feature_1'].iloc[idn])\n",
    "df_features_train[feata] = value\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "print(encoded_train['feature_0'].iloc[idn])\n",
    "print(encoded_train['feature_1'].iloc[idn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.099875807762146, 0.7640548944473267)"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "np.mean(encoded_train['feature_0']), np.mean(encoded_train['feature_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = 672\n",
    "idn2 = 3905\n",
    "idn3 = 33390\n",
    "idn4 = 40435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti =idn\n",
    "#df_encoder_train.iloc[ti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WHOQoL_2</th>\n",
       "      <th>WHOQoL_6</th>\n",
       "      <th>WHOQoL_7</th>\n",
       "      <th>WHOQoL_9</th>\n",
       "      <th>WHOQoL_10</th>\n",
       "      <th>WHOQoL_11</th>\n",
       "      <th>WHOQoL_12</th>\n",
       "      <th>WHOQoL_17</th>\n",
       "      <th>WHOQoL_19</th>\n",
       "      <th>WHOQoL_23</th>\n",
       "      <th>WHOQoL_24</th>\n",
       "      <th>WHOQoL_26</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_9</th>\n",
       "      <th>BSI_12</th>\n",
       "      <th>BSI_23</th>\n",
       "      <th>BSI_37</th>\n",
       "      <th>BSI_38</th>\n",
       "      <th>BSI_45</th>\n",
       "      <th>BSI_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WHOQoL_2  WHOQoL_6  WHOQoL_7  WHOQoL_9  WHOQoL_10  WHOQoL_11  WHOQoL_12  \\\n",
       "672        3.0       5.0       3.0       3.0        3.0        3.0        3.0   \n",
       "3905       3.0       5.0       3.0       3.0        3.0        3.0        3.0   \n",
       "\n",
       "      WHOQoL_17  WHOQoL_19  WHOQoL_23  WHOQoL_24  WHOQoL_26  BSI_1  BSI_9  \\\n",
       "672         4.0        4.0        5.0        2.0        4.0    1.0    0.0   \n",
       "3905        4.0        4.0        5.0        2.0        4.0    1.0    0.0   \n",
       "\n",
       "      BSI_12  BSI_23  BSI_37  BSI_38  BSI_45  BSI_49  \n",
       "672      1.0     1.0     1.0     1.0     0.0     0.0  \n",
       "3905     1.0     1.0     1.0     1.0     0.0     0.0  "
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#41,20476\n",
    "l = 0 \n",
    "for ii in df_features_train.index:\n",
    "    eq = df_features_train[df_features_train.eq(df_features_train.loc[ii],axis=1).sum(axis = 1)==len(df_features_train.columns)]\n",
    "    if len(eq) >1:\n",
    "        if np.any(df_outs_train.loc[eq.index]['y']>0.2):\n",
    "            break\n",
    "        l+=1\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             y        y2\n",
       "672   0.214286  0.600000\n",
       "3905  0.142857  0.657143"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outs_train.loc[eq.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119590</th>\n",
       "      <td>3.537089e-02</td>\n",
       "      <td>0.745608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159619</th>\n",
       "      <td>4.161549e-09</td>\n",
       "      <td>0.924579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163257</th>\n",
       "      <td>1.088843e-01</td>\n",
       "      <td>0.604677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16647</th>\n",
       "      <td>7.022095e-02</td>\n",
       "      <td>0.855885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114054</th>\n",
       "      <td>2.122420e-01</td>\n",
       "      <td>0.470839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165715</th>\n",
       "      <td>5.311599e-08</td>\n",
       "      <td>0.890312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177850</th>\n",
       "      <td>3.528002e-02</td>\n",
       "      <td>0.896820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76398</th>\n",
       "      <td>1.054550e-01</td>\n",
       "      <td>0.785818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22899</th>\n",
       "      <td>7.197297e-02</td>\n",
       "      <td>0.632168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124666</th>\n",
       "      <td>4.713293e-18</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123551</th>\n",
       "      <td>7.061031e-02</td>\n",
       "      <td>0.805804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41639</th>\n",
       "      <td>2.750937e-08</td>\n",
       "      <td>0.923017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181665</th>\n",
       "      <td>1.068096e-01</td>\n",
       "      <td>0.695441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159918</th>\n",
       "      <td>1.054741e-01</td>\n",
       "      <td>0.808451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9701</th>\n",
       "      <td>2.382663e-07</td>\n",
       "      <td>0.890687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53562</th>\n",
       "      <td>1.069418e-01</td>\n",
       "      <td>0.549620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99522</th>\n",
       "      <td>8.364655e-09</td>\n",
       "      <td>0.779993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155887</th>\n",
       "      <td>1.665945e-07</td>\n",
       "      <td>0.864590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51975</th>\n",
       "      <td>6.736237e-07</td>\n",
       "      <td>0.665872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146642</th>\n",
       "      <td>3.212315e-01</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118111</th>\n",
       "      <td>3.219520e-01</td>\n",
       "      <td>0.493361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52676</th>\n",
       "      <td>7.403101e-09</td>\n",
       "      <td>0.923961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94449</th>\n",
       "      <td>3.850498e-01</td>\n",
       "      <td>0.931872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172459</th>\n",
       "      <td>3.530645e-02</td>\n",
       "      <td>0.836031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65907</th>\n",
       "      <td>1.231411e-07</td>\n",
       "      <td>0.863733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151664</th>\n",
       "      <td>6.636511e-10</td>\n",
       "      <td>0.949950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47027</th>\n",
       "      <td>1.455184e-06</td>\n",
       "      <td>0.692436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26619</th>\n",
       "      <td>2.491831e-01</td>\n",
       "      <td>0.532357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95691</th>\n",
       "      <td>3.525987e-02</td>\n",
       "      <td>0.749476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36925</th>\n",
       "      <td>4.621563e-01</td>\n",
       "      <td>0.643157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154506</th>\n",
       "      <td>1.778395e-01</td>\n",
       "      <td>0.748584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119363</th>\n",
       "      <td>2.717896e-07</td>\n",
       "      <td>0.637356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46438</th>\n",
       "      <td>1.377153e-09</td>\n",
       "      <td>0.948775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142070</th>\n",
       "      <td>1.423927e-01</td>\n",
       "      <td>0.800291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87518</th>\n",
       "      <td>7.015285e-02</td>\n",
       "      <td>0.676444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138373</th>\n",
       "      <td>1.434135e-01</td>\n",
       "      <td>0.670516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173643</th>\n",
       "      <td>1.062374e-01</td>\n",
       "      <td>0.722761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171261</th>\n",
       "      <td>6.025723e-01</td>\n",
       "      <td>0.700206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>4.256526e-07</td>\n",
       "      <td>0.776681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112475</th>\n",
       "      <td>5.650626e-01</td>\n",
       "      <td>0.520861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106975</th>\n",
       "      <td>1.419293e-01</td>\n",
       "      <td>0.670718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103619</th>\n",
       "      <td>2.561203e-08</td>\n",
       "      <td>0.810033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98168</th>\n",
       "      <td>2.494968e-01</td>\n",
       "      <td>0.672003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>2.559068e-09</td>\n",
       "      <td>0.550126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106810</th>\n",
       "      <td>1.065112e-01</td>\n",
       "      <td>0.663979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111178</th>\n",
       "      <td>2.495417e-01</td>\n",
       "      <td>0.576789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65351</th>\n",
       "      <td>7.020554e-02</td>\n",
       "      <td>0.756752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25620</th>\n",
       "      <td>9.066231e-09</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99055</th>\n",
       "      <td>2.844992e-12</td>\n",
       "      <td>0.973835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70384</th>\n",
       "      <td>1.250837e-09</td>\n",
       "      <td>0.949629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145730</th>\n",
       "      <td>3.544301e-02</td>\n",
       "      <td>0.490278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59379</th>\n",
       "      <td>3.260556e-12</td>\n",
       "      <td>0.974796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137163</th>\n",
       "      <td>5.738825e-09</td>\n",
       "      <td>0.949440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10113</th>\n",
       "      <td>2.849859e-01</td>\n",
       "      <td>0.677225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89632</th>\n",
       "      <td>3.855936e-10</td>\n",
       "      <td>0.950415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127617</th>\n",
       "      <td>3.466633e-02</td>\n",
       "      <td>0.953814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182646</th>\n",
       "      <td>9.475508e-08</td>\n",
       "      <td>0.461393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171860</th>\n",
       "      <td>1.817367e-07</td>\n",
       "      <td>0.862021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>1.085139e-01</td>\n",
       "      <td>0.842386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25269</th>\n",
       "      <td>3.885649e-06</td>\n",
       "      <td>0.668756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75526 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature_0  feature_1\n",
       "119590  3.537089e-02   0.745608\n",
       "159619  4.161549e-09   0.924579\n",
       "163257  1.088843e-01   0.604677\n",
       "16647   7.022095e-02   0.855885\n",
       "114054  2.122420e-01   0.470839\n",
       "165715  5.311599e-08   0.890312\n",
       "177850  3.528002e-02   0.896820\n",
       "76398   1.054550e-01   0.785818\n",
       "22899   7.197297e-02   0.632168\n",
       "124666  4.713293e-18   0.999999\n",
       "123551  7.061031e-02   0.805804\n",
       "41639   2.750937e-08   0.923017\n",
       "181665  1.068096e-01   0.695441\n",
       "159918  1.054741e-01   0.808451\n",
       "9701    2.382663e-07   0.890687\n",
       "53562   1.069418e-01   0.549620\n",
       "99522   8.364655e-09   0.779993\n",
       "155887  1.665945e-07   0.864590\n",
       "51975   6.736237e-07   0.665872\n",
       "146642  3.212315e-01   0.689700\n",
       "118111  3.219520e-01   0.493361\n",
       "52676   7.403101e-09   0.923961\n",
       "94449   3.850498e-01   0.931872\n",
       "172459  3.530645e-02   0.836031\n",
       "65907   1.231411e-07   0.863733\n",
       "151664  6.636511e-10   0.949950\n",
       "47027   1.455184e-06   0.692436\n",
       "26619   2.491831e-01   0.532357\n",
       "95691   3.525987e-02   0.749476\n",
       "36925   4.621563e-01   0.643157\n",
       "...              ...        ...\n",
       "154506  1.778395e-01   0.748584\n",
       "119363  2.717896e-07   0.637356\n",
       "46438   1.377153e-09   0.948775\n",
       "142070  1.423927e-01   0.800291\n",
       "87518   7.015285e-02   0.676444\n",
       "138373  1.434135e-01   0.670516\n",
       "173643  1.062374e-01   0.722761\n",
       "171261  6.025723e-01   0.700206\n",
       "8566    4.256526e-07   0.776681\n",
       "112475  5.650626e-01   0.520861\n",
       "106975  1.419293e-01   0.670718\n",
       "103619  2.561203e-08   0.810033\n",
       "98168   2.494968e-01   0.672003\n",
       "1241    2.559068e-09   0.550126\n",
       "106810  1.065112e-01   0.663979\n",
       "111178  2.495417e-01   0.576789\n",
       "65351   7.020554e-02   0.756752\n",
       "25620   9.066231e-09   0.948422\n",
       "99055   2.844992e-12   0.973835\n",
       "70384   1.250837e-09   0.949629\n",
       "145730  3.544301e-02   0.490278\n",
       "59379   3.260556e-12   0.974796\n",
       "137163  5.738825e-09   0.949440\n",
       "10113   2.849859e-01   0.677225\n",
       "89632   3.855936e-10   0.950415\n",
       "127617  3.466633e-02   0.953814\n",
       "182646  9.475508e-08   0.461393\n",
       "171860  1.817367e-07   0.862021\n",
       "1391    1.085139e-01   0.842386\n",
       "25269   3.885649e-06   0.668756\n",
       "\n",
       "[75526 rows x 2 columns]"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_outs_train['y'].loc[ti],df_outs_train['y2'].loc[ti]\n",
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_train[encoded_train['feature_0']>0.7].sample(5)\n",
    "encoded_train.index = df_outs_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2146155 0.14154318 9.84738e-10 9.038204e-10\n",
      "0.7399327 0.6715829 0.9493986 0.94888973\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train['feature_0'].loc[idn],encoded_train['feature_0'].loc[idn2],encoded_train['feature_0'].loc[idn3],encoded_train['feature_0'].loc[idn4])\n",
    "print(encoded_train['feature_1'].loc[idn],encoded_train['feature_1'].loc[idn2],encoded_train['feature_1'].loc[idn3],encoded_train['feature_1'].loc[idn4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_print = []#list(data.columns)[42:141]\n",
    "#new_feat_print += [\n",
    "#    'WHOQoL_8', 'WHOQoL_9',\n",
    "#    'WHOQoL_12','WHOQoL_14', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', \n",
    "#             'BSI_9', 'BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "#            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 2\n",
    "ind = idn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m == 1:\n",
    "    all_values = [0,1,2,3,4]\n",
    "    new_feat_print = [\n",
    "        \n",
    "        'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "                ]\n",
    "if m == 2:\n",
    "    all_values = [1,2,3,4,5]\n",
    "    new_feat_print = [\n",
    "           'WHOQoL_2', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', 'WHOQoL_10', 'WHOQoL_11', \n",
    "    'WHOQoL_12', 'WHOQoL_17', 'WHOQoL_19', 'WHOQoL_23', 'WHOQoL_24','WHOQoL_26'            \n",
    "    #'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]\n",
    "#all_values = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.64078355\n",
      "0.6907905\n",
      "0.62682396\n",
      "0.67233765\n",
      "0.61877\n",
      "0.6362686\n",
      "0.6600602\n",
      "0.5674621\n",
      "0.63611925\n",
      "0.6154047\n",
      "0.66339046\n",
      "0.69411755\n",
      "2\n",
      "0.6570239\n",
      "0.6811236\n",
      "0.6500653\n",
      "0.6720782\n",
      "0.64859176\n",
      "0.655391\n",
      "0.66584635\n",
      "0.59977335\n",
      "0.64843506\n",
      "0.63127583\n",
      "0.6715829\n",
      "0.68562204\n",
      "3\n",
      "0.6715829\n",
      "0.67918766\n",
      "0.6715829\n",
      "0.6715829\n",
      "0.6715829\n",
      "0.6715829\n",
      "0.6715829\n",
      "0.6373414\n",
      "0.6600131\n",
      "0.6459762\n",
      "0.6800064\n",
      "0.6778481\n",
      "4\n",
      "0.68564653\n",
      "0.6753118\n",
      "0.69240826\n",
      "0.67066145\n",
      "0.69606364\n",
      "0.68776774\n",
      "0.6772449\n",
      "0.6715829\n",
      "0.6715829\n",
      "0.65889984\n",
      "0.6883141\n",
      "0.6715829\n",
      "5\n",
      "0.6996353\n",
      "0.6715829\n",
      "0.7126658\n",
      "0.6712163\n",
      "0.71588767\n",
      "0.703454\n",
      "0.6829804\n",
      "0.70657814\n",
      "0.68306315\n",
      "0.6715829\n",
      "0.69281125\n",
      "0.6653038\n"
     ]
    }
   ],
   "source": [
    "for c_value in all_values:\n",
    "    print(c_value)\n",
    "    for feata in new_feat_print:\n",
    "        df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "        df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "        df_outs_train = df_encoder_train[['y','y2']]\n",
    "        df_outs_test = df_encoder_test[['y','y2']]\n",
    "        df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "        df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "        df_features_train[feata] = c_value\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        #counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "        counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "        encoded_input = Input(shape = (encoding_dim, ))\n",
    "        encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "        encoded_train = encoded_train.add_prefix('feature_')\n",
    "        encoded_train.index = df_outs_train.index\n",
    "        if m == 1:\n",
    "            print(encoded_train['feature_0'].loc[[ind]].values[0])\n",
    "        if m == 2:\n",
    "            print(encoded_train['feature_1'].loc[[ind]].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train.iloc[idn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feata = 'BSI_10'\n",
    "\n",
    "df_features_test[feata] = 1\n",
    "\n",
    "#counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))\n",
    "encoded_test = pd.DataFrame(counter.predict([df_encoder_test,df_features_test]))\n",
    "encoded_test = encoded_test.add_prefix('feature_')\n",
    "encoded_test['feature_1'].iloc[[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1143   -0.251098\n",
    "1432   -0.050221\n",
    "774     0.472253\n",
    "863     2.349966\n",
    "380    -0.142225\n",
    "Name: feature_0, dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['BSI_23','BSI_36','BSI_20','BSI_17','BSI_38','BSI_46','BSI_31','BSI_10','BSI_53',\n",
    "             'WHOQoL_16','WHOQoL_17','WHOQoL_18','WHOQoL_19','WHOQoL_20','WHOQoL_21','WHOQoL_22',\n",
    "            'WHOQoL_23','WHOQoL_24','WHOQoL_25','WHOQoL_26']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
