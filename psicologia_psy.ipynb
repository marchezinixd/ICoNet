{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./test_tables/BD_Demographics_Database_BSI_WhoQol.csv', sep = ',',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['database', 'sex', 'age_months', 'age_years', 'education',\n",
       "       'marital_status', 'ethnicity', 'cceb_class', 'BSI_1', 'BSI_2', 'BSI_3',\n",
       "       'BSI_4', 'BSI_5', 'BSI_6', 'BSI_7', 'BSI_8', 'BSI_9', 'BSI_10',\n",
       "       'BSI_11', 'BSI_12', 'BSI_13', 'BSI_14', 'BSI_15', 'BSI_16', 'BSI_17',\n",
       "       'BSI_18', 'BSI_19', 'BSI_20', 'BSI_21', 'BSI_22', 'BSI_23', 'BSI_24',\n",
       "       'BSI_25', 'BSI_26', 'BSI_27', 'BSI_28', 'BSI_29', 'BSI_30', 'BSI_31',\n",
       "       'BSI_32', 'BSI_33', 'BSI_34', 'BSI_35', 'BSI_36', 'BSI_37', 'BSI_38',\n",
       "       'BSI_39', 'BSI_40', 'BSI_41', 'BSI_42', 'BSI_43', 'BSI_44', 'BSI_45',\n",
       "       'BSI_46', 'BSI_47', 'BSI_48', 'BSI_49', 'BSI_50', 'BSI_51', 'BSI_52',\n",
       "       'BSI_53', 'WHOQoL_1', 'WHOQoL_2', 'WHOQoL_3', 'WHOQoL_4', 'WHOQoL_5',\n",
       "       'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_8', 'WHOQoL_9', 'WHOQoL_10',\n",
       "       'WHOQoL_11', 'WHOQoL_12', 'WHOQoL_14', 'WHOQoL_15', 'WHOQoL_16',\n",
       "       'WHOQoL_17', 'WHOQoL_18', 'WHOQoL_19', 'WHOQoL_20', 'WHOQoL_21',\n",
       "       'WHOQoL_22', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', 'WHOQoL_26',\n",
       "       'BSI_GSI_EB', 'BSI_Somatization_EB', 'BSI_ObsCom_EB', 'BSI_IntSens_EB',\n",
       "       'BSI_Depression_EB', 'BSI_Anxiety_EB', 'BSI_Hostility_EB',\n",
       "       'BSI_Phobic_EB', 'BSI_Paranoid_EB', 'BSI_Psychoticism_EB',\n",
       "       'WQOL.Fisico', 'WQOL.Psicologico', 'WQOL.RSociais', 'WQOL_MAmbiente'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = 23489\n",
    "idn2 = 70776\n",
    "idn3 = 52594\n",
    "idn4 = 24047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['database',\n",
       " 'sex',\n",
       " 'age_months',\n",
       " 'age_years',\n",
       " 'education',\n",
       " 'marital_status',\n",
       " 'ethnicity',\n",
       " 'cceb_class',\n",
       " 'BSI_1',\n",
       " 'BSI_2',\n",
       " 'BSI_3',\n",
       " 'BSI_4',\n",
       " 'BSI_5',\n",
       " 'BSI_6',\n",
       " 'BSI_7',\n",
       " 'BSI_8',\n",
       " 'BSI_9',\n",
       " 'BSI_10',\n",
       " 'BSI_11',\n",
       " 'BSI_12',\n",
       " 'BSI_13',\n",
       " 'BSI_14',\n",
       " 'BSI_15',\n",
       " 'BSI_16',\n",
       " 'BSI_17',\n",
       " 'BSI_18',\n",
       " 'BSI_19',\n",
       " 'BSI_20',\n",
       " 'BSI_21',\n",
       " 'BSI_22',\n",
       " 'BSI_23',\n",
       " 'BSI_24',\n",
       " 'BSI_25',\n",
       " 'BSI_26',\n",
       " 'BSI_27',\n",
       " 'BSI_28',\n",
       " 'BSI_29',\n",
       " 'BSI_30',\n",
       " 'BSI_31',\n",
       " 'BSI_32',\n",
       " 'BSI_33',\n",
       " 'BSI_34',\n",
       " 'BSI_35',\n",
       " 'BSI_36',\n",
       " 'BSI_37',\n",
       " 'BSI_38',\n",
       " 'BSI_39',\n",
       " 'BSI_40',\n",
       " 'BSI_41',\n",
       " 'BSI_42',\n",
       " 'BSI_43',\n",
       " 'BSI_44',\n",
       " 'BSI_45',\n",
       " 'BSI_46',\n",
       " 'BSI_47',\n",
       " 'BSI_48',\n",
       " 'BSI_49',\n",
       " 'BSI_50',\n",
       " 'BSI_51',\n",
       " 'BSI_52',\n",
       " 'BSI_53',\n",
       " 'WHOQoL_1',\n",
       " 'WHOQoL_2',\n",
       " 'WHOQoL_3',\n",
       " 'WHOQoL_4',\n",
       " 'WHOQoL_5',\n",
       " 'WHOQoL_6',\n",
       " 'WHOQoL_7',\n",
       " 'WHOQoL_8',\n",
       " 'WHOQoL_9',\n",
       " 'WHOQoL_10',\n",
       " 'WHOQoL_11',\n",
       " 'WHOQoL_12',\n",
       " 'WHOQoL_14',\n",
       " 'WHOQoL_15',\n",
       " 'WHOQoL_16',\n",
       " 'WHOQoL_17',\n",
       " 'WHOQoL_18',\n",
       " 'WHOQoL_19',\n",
       " 'WHOQoL_20',\n",
       " 'WHOQoL_21',\n",
       " 'WHOQoL_22',\n",
       " 'WHOQoL_23',\n",
       " 'WHOQoL_24',\n",
       " 'WHOQoL_25',\n",
       " 'WHOQoL_26',\n",
       " 'BSI_GSI_EB',\n",
       " 'BSI_Somatization_EB',\n",
       " 'BSI_ObsCom_EB',\n",
       " 'BSI_IntSens_EB',\n",
       " 'BSI_Depression_EB',\n",
       " 'BSI_Anxiety_EB',\n",
       " 'BSI_Hostility_EB',\n",
       " 'BSI_Phobic_EB',\n",
       " 'BSI_Paranoid_EB',\n",
       " 'BSI_Psychoticism_EB',\n",
       " 'WQOL.Fisico',\n",
       " 'WQOL.Psicologico',\n",
       " 'WQOL.RSociais',\n",
       " 'WQOL_MAmbiente']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"new_feat += [\\n           'WHOQoL_2', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', 'WHOQoL_10', 'WHOQoL_11', \\n    'WHOQoL_12', 'WHOQoL_17', 'WHOQoL_19', 'WHOQoL_23', 'WHOQoL_24','WHOQoL_26',\\n    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\\n    \\n            ]\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat = []#list(data.columns)[42:141]\n",
    "\n",
    "'''new_feat += [\n",
    "           'WHOQoL_1', 'WHOQoL_2', 'WHOQoL_5', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', \n",
    "    'WHOQoL_15', 'WHOQoL_22', 'WHOQoL_23',              \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "            ]'''\n",
    "new_feat += [\n",
    "           'WHOQoL_6', 'WHOQoL_10', 'WHOQoL_14', 'WHOQoL_16', 'WHOQoL_18', 'WHOQoL_19', \n",
    "    'WHOQoL_20', 'WHOQoL_22', 'WHOQoL_25', 'WHOQoL_26',             \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]\n",
    "\n",
    "'''new_feat += [\n",
    "           'WHOQoL_2', 'WHOQoL_6', 'WHOQoL_7', 'WHOQoL_9', 'WHOQoL_10', 'WHOQoL_11', \n",
    "    'WHOQoL_12', 'WHOQoL_17', 'WHOQoL_19', 'WHOQoL_23', 'WHOQoL_24','WHOQoL_26',\n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cols = []\n",
    "for col in data.columns:\n",
    "    if 'WQOL' in col:\n",
    "        result_cols.append(col)\n",
    "    elif 'BSI_' in col and len(col)>6:\n",
    "        result_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsi = []\n",
    "whoqol = []\n",
    "for col in data.columns:\n",
    "    if 'WQOL' in col:\n",
    "        whoqol.append(col)\n",
    "    elif 'BSI_' in col and len(col)>6:\n",
    "        bsi.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsi_feat = []\n",
    "whoqol_feat = []\n",
    "for col in data.columns:\n",
    "    if 'WHOQoL' in col:\n",
    "        whoqol_feat.append(col)\n",
    "    elif 'BSI_' in col and len(col)<=6:\n",
    "        bsi_feat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[result_cols] = data[result_cols].replace(' ', np.nan)\n",
    "data = data.replace(' ', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = result_cols, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['WHOQoL_3'] = abs(data['WHOQoL_3']-6)\n",
    "data['WHOQoL_4'] = abs(data['WHOQoL_4']-6)\n",
    "data['WHOQoL_26'] = abs(data['WHOQoL_26']-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(['ID_covid', 'sample', 'date_created','consent', 'sgID', 'date_birth', 'region','city_br','Occupation_other', 'working_hours','religion_other', 'cceb_class',\n",
    "#'social_support_n_family','social_support_n_friends'],axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[bsi] = data[bsi].apply(lambda x: x.str.replace(',','.'))\n",
    "#data[whoqol] = data[whoqol].apply(lambda x: x.str.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[bsi_feat] = data[bsi_feat].astype(float)\n",
    "\n",
    "#data[whoqol_feat] = data[whoqol_feat].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database\n",
      "sex\n",
      "education\n",
      "marital_status\n",
      "ethnicity\n",
      "cceb_class\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    try:\n",
    "        data[col] = data[col].astype(float)\n",
    "    except:\n",
    "        (print(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import  Dense, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].nunique()==1:\n",
    "        data.drop(col,inplace = True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WQOL.Fisico', 'WQOL.Psicologico', 'WQOL.RSociais', 'WQOL_MAmbiente']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whoqol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>cceb_class</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BSI_Depression_EB</th>\n",
       "      <th>BSI_Anxiety_EB</th>\n",
       "      <th>BSI_Hostility_EB</th>\n",
       "      <th>BSI_Phobic_EB</th>\n",
       "      <th>BSI_Paranoid_EB</th>\n",
       "      <th>BSI_Psychoticism_EB</th>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <th>WQOL.RSociais</th>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>436.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>400.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>579.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>468.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>292.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>383.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>536.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>273.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>376.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>563.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>689.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>275.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>351.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>377.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>285.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>443.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>341.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>404.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>371.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>585.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>324.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>335.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>334.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186317</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>449.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186319</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>567.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186320</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>216.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186321</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>310.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186322</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>431.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186323</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>459.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186325</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>594.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186327</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>644.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186328</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>349.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186330</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>584.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186331</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>614.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186333</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>672.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186334</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>679.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186335</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>730.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186336</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>758.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186338</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>433.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186339</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>556.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186340</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>304.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186341</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>432.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186342</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186344</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>610.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186345</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>696.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186346</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>793.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186347</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>809.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186348</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>815.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186349</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>526.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186350</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>652.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186351</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186352</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>823.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186353</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>888.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153514 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       database        sex  age_months  age_years  \\\n",
       "0           SUS   Feminino       436.0       36.0   \n",
       "1           SUS   Feminino       400.0       33.0   \n",
       "2           SUS  Masculino       579.0       48.0   \n",
       "4           SUS   Feminino       468.0       39.0   \n",
       "5           SUS   Feminino       292.0       24.0   \n",
       "6           SUS   Feminino       383.0       31.0   \n",
       "7           SUS   Feminino       321.0       26.0   \n",
       "8           SUS   Feminino       536.0       44.0   \n",
       "9           SUS   Feminino       419.0       34.0   \n",
       "10          SUS   Feminino       273.0       22.0   \n",
       "11          SUS   Feminino       376.0       31.0   \n",
       "12          SUS   Feminino       563.0       46.0   \n",
       "15          SUS  Masculino       689.0       57.0   \n",
       "16          SUS   Feminino       275.0       22.0   \n",
       "18          SUS  Masculino       351.0       29.0   \n",
       "19          SUS   Feminino       321.0       26.0   \n",
       "20          SUS   Feminino       377.0       31.0   \n",
       "21          SUS   Feminino       285.0       23.0   \n",
       "22          SUS   Feminino       443.0       36.0   \n",
       "23          SUS  Masculino       341.0       28.0   \n",
       "24          SUS  Masculino       485.0       40.0   \n",
       "25          SUS   Feminino       404.0       33.0   \n",
       "26          SUS  Masculino       371.0       30.0   \n",
       "27          SUS   Feminino       690.0       57.0   \n",
       "28          SUS   Feminino       585.0       48.0   \n",
       "29          SUS   Feminino       321.0       26.0   \n",
       "30          SUS   Feminino       324.0       27.0   \n",
       "31          SUS   Feminino       335.0       27.0   \n",
       "32          SUS   Feminino       334.0       27.0   \n",
       "33          SUS   Feminino       288.0       24.0   \n",
       "...         ...        ...         ...        ...   \n",
       "186317  general  Masculino       449.0       37.0   \n",
       "186319  general   Feminino       567.0       47.0   \n",
       "186320  general   Feminino       216.0       18.0   \n",
       "186321  general   Feminino       310.0       25.0   \n",
       "186322  general  Masculino       431.0       35.0   \n",
       "186323  general   Feminino       459.0       38.0   \n",
       "186325  general   Feminino       594.0       49.0   \n",
       "186327  general   Feminino       644.0       53.0   \n",
       "186328  general   Feminino       349.0       29.0   \n",
       "186330  general   Feminino       584.0       48.0   \n",
       "186331  general   Feminino       614.0       51.0   \n",
       "186333  general   Feminino       672.0       56.0   \n",
       "186334  general   Feminino       679.0       56.0   \n",
       "186335  general   Feminino       730.0       60.0   \n",
       "186336  general   Feminino       758.0       63.0   \n",
       "186338  general   Feminino       433.0       36.0   \n",
       "186339  general  Masculino       556.0       46.0   \n",
       "186340  general   Feminino       304.0       25.0   \n",
       "186341  general   Feminino       432.0       36.0   \n",
       "186342  general   Feminino       503.0       41.0   \n",
       "186344  general   Feminino       610.0       50.0   \n",
       "186345  general   Feminino       696.0       58.0   \n",
       "186346  general   Feminino       793.0       66.0   \n",
       "186347  general   Feminino       809.0       67.0   \n",
       "186348  general   Feminino       815.0       67.0   \n",
       "186349  general   Feminino       526.0       43.0   \n",
       "186350  general   Feminino       652.0       54.0   \n",
       "186351  general   Feminino       690.0       57.0   \n",
       "186352  general   Feminino       823.0       68.0   \n",
       "186353  general   Feminino       888.0       74.0   \n",
       "\n",
       "                                                education  \\\n",
       "0                                       Superior completo   \n",
       "1                                       Superior completo   \n",
       "2                                       Superior completo   \n",
       "4                                       Superior completo   \n",
       "5                                       Superior completo   \n",
       "6                                                Mestrado   \n",
       "7                                       Superior completo   \n",
       "8                                                Mestrado   \n",
       "9                                       Superior completo   \n",
       "10                                      Superior completo   \n",
       "11                                      Superior completo   \n",
       "12                                      Superior completo   \n",
       "15                                              Doutorado   \n",
       "16                                                    NaN   \n",
       "18                                      Superior completo   \n",
       "19                                      Superior completo   \n",
       "20                                      Superior completo   \n",
       "21                                                    NaN   \n",
       "22                                      Superior completo   \n",
       "23                                      Superior completo   \n",
       "24                                      Superior completo   \n",
       "25                                      Superior completo   \n",
       "26                                      Superior completo   \n",
       "27                                      Superior completo   \n",
       "28                                      Superior completo   \n",
       "29                                      Superior completo   \n",
       "30                                      Superior completo   \n",
       "31                                      Superior completo   \n",
       "32                                      Superior completo   \n",
       "33                                      Superior completo   \n",
       "...                                                   ...   \n",
       "186317                                           Mestrado   \n",
       "186319                                           Mestrado   \n",
       "186320  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186321                                           Mestrado   \n",
       "186322  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186323                                  Superior completo   \n",
       "186325                                           Mestrado   \n",
       "186327  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186328  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186330                                  Superior completo   \n",
       "186331                                           Mestrado   \n",
       "186333                                  Superior completo   \n",
       "186334                                  Superior completo   \n",
       "186335                                  Superior completo   \n",
       "186336                                  Superior completo   \n",
       "186338                                  Superior completo   \n",
       "186339                                          Doutorado   \n",
       "186340  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186341  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186342                                  Superior completo   \n",
       "186344  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186345                                  Superior completo   \n",
       "186346                                  Superior completo   \n",
       "186347  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186348                                  Superior completo   \n",
       "186349                                  Superior completo   \n",
       "186350  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186351                                           Mestrado   \n",
       "186352                                  Superior completo   \n",
       "186353  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "\n",
       "                   marital_status ethnicity cceb_class  BSI_1  BSI_2  ...  \\\n",
       "0            Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "1            Casado(a)/Vive junto     Parda         C1    2.0    0.0  ...   \n",
       "2            Casado(a)/Vive junto     Preta         B2    1.0    1.0  ...   \n",
       "4                     Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "5                     Solteiro(a)     Parda         C2    2.0    0.0  ...   \n",
       "6                     Solteiro(a)     Parda         C2    3.0    0.0  ...   \n",
       "7                     Solteiro(a)    Branca         B2    0.0    0.0  ...   \n",
       "8            Casado(a)/Vive junto    Branca         C1    3.0    0.0  ...   \n",
       "9                     Solteiro(a)     Preta         C1    2.0    0.0  ...   \n",
       "10                    Solteiro(a)    Branca         C2    2.0    0.0  ...   \n",
       "11           Casado(a)/Vive junto     Preta         B2    0.0    0.0  ...   \n",
       "12                    Solteiro(a)     Parda         C1    1.0    0.0  ...   \n",
       "15           Casado(a)/Vive junto     Parda         B2    0.0    0.0  ...   \n",
       "16                    Solteiro(a)     Parda         DE    2.0    2.0  ...   \n",
       "18           Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "19           Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "20                    Solteiro(a)    Branca         DE    4.0    1.0  ...   \n",
       "21                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "22           Casado(a)/Vive junto    Branca         C2    0.0    0.0  ...   \n",
       "23                    Solteiro(a)       NaN        NaN    0.0    0.0  ...   \n",
       "24           Casado(a)/Vive junto     Preta         C1    0.0    0.0  ...   \n",
       "25      Separado(a)/Divorciado(a)    Branca         C1    3.0    0.0  ...   \n",
       "26                    Solteiro(a)       NaN        NaN    1.0    0.0  ...   \n",
       "27           Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "28      Separado(a)/Divorciado(a)     Parda         C2    1.0    0.0  ...   \n",
       "29                    Solteiro(a)     Parda         DE    0.0    0.0  ...   \n",
       "30                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "31           Casado(a)/Vive junto    Branca         C1    2.0    0.0  ...   \n",
       "32           Casado(a)/Vive junto    Branca         DE    1.0    0.0  ...   \n",
       "33                    Solteiro(a)    Branca         C1    1.0    0.0  ...   \n",
       "...                           ...       ...        ...    ...    ...  ...   \n",
       "186317       Casado(a)/Vive junto    Branca         B1    0.0    0.0  ...   \n",
       "186319       Casado(a)/Vive junto       NaN        NaN    3.0    1.0  ...   \n",
       "186320                Solteiro(a)       NaN        NaN    0.0    0.0  ...   \n",
       "186321       Casado(a)/Vive junto    Branca         B1    2.0    0.0  ...   \n",
       "186322                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186323                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "186325  Separado(a)/Divorciado(a)    Branca         B1    0.0    0.0  ...   \n",
       "186327       Casado(a)/Vive junto    Branca         C1    4.0    1.0  ...   \n",
       "186328                Solteiro(a)    Branca         DE    3.0    2.0  ...   \n",
       "186330  Separado(a)/Divorciado(a)     Preta         B2    4.0    0.0  ...   \n",
       "186331       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186333                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186334  Separado(a)/Divorciado(a)    Branca          A    0.0    1.0  ...   \n",
       "186335       Casado(a)/Vive junto    Branca         C2    1.0    0.0  ...   \n",
       "186336       Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "186338       Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "186339       Casado(a)/Vive junto     Parda         C1    0.0    0.0  ...   \n",
       "186340                Solteiro(a)       NaN        NaN    2.0    3.0  ...   \n",
       "186341       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186342       Casado(a)/Vive junto    Branca         B2    3.0    2.0  ...   \n",
       "186344       Casado(a)/Vive junto    Branca         C1    2.0    1.0  ...   \n",
       "186345                Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "186346                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186347  Separado(a)/Divorciado(a)    Branca         B2    1.0    0.0  ...   \n",
       "186348  Separado(a)/Divorciado(a)       NaN        NaN    2.0    1.0  ...   \n",
       "186349                Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "186350       Casado(a)/Vive junto    Branca         C1    1.0    0.0  ...   \n",
       "186351  Separado(a)/Divorciado(a)    Branca         B2    3.0    0.0  ...   \n",
       "186352       Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "186353                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "\n",
       "        BSI_Depression_EB  BSI_Anxiety_EB  BSI_Hostility_EB  BSI_Phobic_EB  \\\n",
       "0                0.333333        0.500000               0.0            0.2   \n",
       "1                0.833333        1.500000               1.0            1.0   \n",
       "2                0.166667        0.500000               0.0            0.6   \n",
       "4                0.500000        0.666667               0.0            1.6   \n",
       "5                1.833333        1.666667               1.0            1.4   \n",
       "6                1.166667        0.833333               0.4            0.4   \n",
       "7                0.000000        0.000000               0.0            0.0   \n",
       "8                1.000000        1.500000               0.8            1.2   \n",
       "9                0.166667        0.666667               0.2            0.2   \n",
       "10               0.000000        0.833333               0.0            0.0   \n",
       "11               0.166667        0.000000               0.2            0.2   \n",
       "12               0.166667        0.166667               0.0            0.0   \n",
       "15               0.000000        0.000000               0.0            0.0   \n",
       "16               1.333333        1.500000               0.4            0.2   \n",
       "18               0.166667        0.000000               0.0            0.2   \n",
       "19               1.333333        2.333333               1.6            2.0   \n",
       "20               2.166667        1.833333               2.0            0.4   \n",
       "21               1.166667        1.500000               1.6            0.6   \n",
       "22               0.166667        0.000000               0.0            0.0   \n",
       "23               1.166667        0.000000               0.2            0.2   \n",
       "24               0.166667        0.000000               0.4            0.8   \n",
       "25               1.333333        1.166667               0.8            0.4   \n",
       "26               0.333333        0.333333               0.0            0.0   \n",
       "27               0.333333        0.333333               0.0            0.0   \n",
       "28               0.500000        0.166667               0.2            0.0   \n",
       "29               0.166667        0.000000               0.0            0.0   \n",
       "30               0.166667        1.166667               0.0            1.6   \n",
       "31               0.500000        0.833333               0.2            0.6   \n",
       "32               0.333333        0.500000               0.0            0.2   \n",
       "33               0.000000        0.166667               0.2            0.0   \n",
       "...                   ...             ...               ...            ...   \n",
       "186317           0.333333        0.166667               0.2            0.0   \n",
       "186319           3.333333        2.833333               2.2            2.6   \n",
       "186320           0.500000        0.500000               1.0            0.8   \n",
       "186321           0.666667        2.333333               3.2            3.4   \n",
       "186322           0.833333        0.666667               0.2            1.4   \n",
       "186323           2.500000        2.000000               0.8            0.8   \n",
       "186325           0.166667        0.000000               0.0            0.0   \n",
       "186327           2.833333        3.000000               1.8            3.6   \n",
       "186328           3.000000        1.666667               0.4            1.6   \n",
       "186330           2.333333        3.333333               1.0            3.8   \n",
       "186331           1.166667        2.333333               2.2            2.4   \n",
       "186333           0.000000        0.000000               0.0            0.4   \n",
       "186334           1.500000        0.500000               1.2            0.2   \n",
       "186335           1.666667        1.000000               1.2            0.8   \n",
       "186336           0.666667        0.500000               0.2            0.4   \n",
       "186338           0.666667        0.666667               2.2            0.2   \n",
       "186339           2.000000        0.333333               0.2            1.2   \n",
       "186340           3.666667        2.166667               3.4            3.6   \n",
       "186341           2.500000        2.500000               2.4            3.0   \n",
       "186342           1.833333        2.166667               1.2            2.6   \n",
       "186344           0.833333        1.333333               0.2            0.8   \n",
       "186345           0.500000        1.000000               0.2            0.6   \n",
       "186346           0.166667        0.000000               0.0            1.0   \n",
       "186347           0.500000        0.333333               0.0            0.4   \n",
       "186348           3.000000        1.333333               0.6            2.6   \n",
       "186349           0.500000        0.333333               0.6            0.0   \n",
       "186350           0.500000        0.500000               0.2            0.4   \n",
       "186351           3.333333        2.000000               1.0            2.6   \n",
       "186352           0.500000        0.166667               0.0            0.0   \n",
       "186353           1.000000        0.666667               0.2            1.6   \n",
       "\n",
       "        BSI_Paranoid_EB  BSI_Psychoticism_EB  WQOL.Fisico  WQOL.Psicologico  \\\n",
       "0                  0.00                  0.0     4.285714          4.166667   \n",
       "1                  1.00                  0.4     2.857143          3.333333   \n",
       "2                  0.75                  0.0     4.166667          3.666667   \n",
       "4                  0.40                  0.0     3.428571          3.333333   \n",
       "5                  2.00                  2.4     3.714286          3.333333   \n",
       "6                  0.20                  0.4     3.285714          3.166667   \n",
       "7                  0.00                  0.0     3.857143          4.166667   \n",
       "8                  0.20                  0.6     3.428571          3.000000   \n",
       "9                  0.00                  0.2     4.000000          4.500000   \n",
       "10                 0.20                  0.0     4.000000          4.333333   \n",
       "11                 0.00                  0.0     4.571429          4.833333   \n",
       "12                 0.00                  0.0     4.000000          3.666667   \n",
       "15                 0.40                  0.0     4.857143          5.000000   \n",
       "16                 0.80                  0.4     3.285714          3.000000   \n",
       "18                 0.20                  0.0     4.428571          4.333333   \n",
       "19                 1.20                  1.6     4.000000          3.833333   \n",
       "20                 1.40                  1.4     3.285714          2.166667   \n",
       "21                 1.40                  1.6     3.857143          3.333333   \n",
       "22                 0.20                  0.2     4.857143          4.833333   \n",
       "23                 0.60                  0.4     4.285714          4.166667   \n",
       "24                 0.20                  0.0     4.142857          4.333333   \n",
       "25                 0.20                  0.8     3.857143          2.833333   \n",
       "26                 0.00                  0.0     4.714286          4.833333   \n",
       "27                 0.00                  0.0     4.428571          3.500000   \n",
       "28                 0.80                  0.0     4.714286          3.666667   \n",
       "29                 0.40                  0.2     4.000000          4.333333   \n",
       "30                 0.60                  0.0     4.428571          3.666667   \n",
       "31                 0.60                  0.4     4.285714          3.833333   \n",
       "32                 1.60                  0.2     4.285714          3.833333   \n",
       "33                 0.00                  0.0     4.142857          3.833333   \n",
       "...                 ...                  ...          ...               ...   \n",
       "186317             0.20                  0.0     3.857143          4.333333   \n",
       "186319             2.00                  2.2     2.000000          1.833333   \n",
       "186320             1.00                  0.4     3.714286          3.666667   \n",
       "186321             1.00                  1.2     4.142857          3.666667   \n",
       "186322             0.00                  0.6     3.428571          2.166667   \n",
       "186323             1.80                  1.2     3.142857          3.666667   \n",
       "186325             0.00                  0.0     3.571429          3.666667   \n",
       "186327             2.20                  2.0     1.857143          2.666667   \n",
       "186328             1.20                  1.8     2.000000          2.333333   \n",
       "186330             1.80                  1.6     2.000000          2.500000   \n",
       "186331             1.00                  1.0     2.428571          2.666667   \n",
       "186333             0.20                  0.0     3.571429          4.166667   \n",
       "186334             2.20                  0.6     3.285714          2.500000   \n",
       "186335             1.00                  0.6     2.714286          1.833333   \n",
       "186336             0.60                  0.4     3.428571          3.500000   \n",
       "186338             1.00                  0.8     4.142857          3.500000   \n",
       "186339             1.60                  1.0     4.000000          2.833333   \n",
       "186340             2.60                  2.2     1.142857          2.000000   \n",
       "186341             2.20                  2.0     2.714286          2.333333   \n",
       "186342             0.60                  0.0     3.000000          2.500000   \n",
       "186344             1.20                  0.4     3.000000          3.166667   \n",
       "186345             0.80                  0.2     3.571429          3.333333   \n",
       "186346             0.00                  0.0     4.000000          4.333333   \n",
       "186347             0.20                  0.4     4.142857          4.333333   \n",
       "186348             2.40                  1.8     1.571429          1.500000   \n",
       "186349             0.40                  0.0     3.857143          2.666667   \n",
       "186350             0.40                  0.0     3.142857          3.333333   \n",
       "186351             1.40                  1.6     2.142857          2.000000   \n",
       "186352             0.00                  0.2     4.285714          4.666667   \n",
       "186353             0.20                  0.2     4.571429          4.166667   \n",
       "\n",
       "        WQOL.RSociais  WQOL_MAmbiente  \n",
       "0            4.000000        3.714286  \n",
       "1            2.333333        3.142857  \n",
       "2            4.000000        2.857143  \n",
       "4            3.000000        4.142857  \n",
       "5            3.666667        3.857143  \n",
       "6            2.666667        3.285714  \n",
       "7            4.666667        4.142857  \n",
       "8            2.666667        3.428571  \n",
       "9            5.000000        3.571429  \n",
       "10           4.000000        4.428571  \n",
       "11           4.333333        4.000000  \n",
       "12           3.333333        2.714286  \n",
       "15           4.333333        3.857143  \n",
       "16           2.666667        3.142857  \n",
       "18           4.666667        3.714286  \n",
       "19           4.000000        3.857143  \n",
       "20           1.333333        2.285714  \n",
       "21           3.333333        3.142857  \n",
       "22           4.000000        3.857143  \n",
       "23           2.666667        3.142857  \n",
       "24           3.333333        3.428571  \n",
       "25           2.666667        3.428571  \n",
       "26           4.333333        4.285714  \n",
       "27           3.666667        3.571429  \n",
       "28           4.333333        3.000000  \n",
       "29           3.000000        2.571429  \n",
       "30           4.000000        3.714286  \n",
       "31           3.666667        3.000000  \n",
       "32           2.333333        4.000000  \n",
       "33           3.333333        3.857143  \n",
       "...               ...             ...  \n",
       "186317       4.000000        3.857143  \n",
       "186319       1.666667        1.714286  \n",
       "186320       3.333333        4.142857  \n",
       "186321       3.333333        4.428571  \n",
       "186322       2.666667        4.142857  \n",
       "186323       2.666667        2.571429  \n",
       "186325       3.666667        3.000000  \n",
       "186327       2.333333        2.571429  \n",
       "186328       2.333333        2.428571  \n",
       "186330       2.666667        2.857143  \n",
       "186331       3.333333        2.714286  \n",
       "186333       4.000000        3.285714  \n",
       "186334       2.000000        3.714286  \n",
       "186335       1.666667        2.857143  \n",
       "186336       3.666667        3.142857  \n",
       "186338       3.666667        3.571429  \n",
       "186339       1.666667        3.428571  \n",
       "186340       2.666667        1.142857  \n",
       "186341       2.333333        2.571429  \n",
       "186342       3.000000        3.142857  \n",
       "186344       4.000000        2.428571  \n",
       "186345       3.666667        3.000000  \n",
       "186346       3.666667        4.142857  \n",
       "186347       4.000000        4.285714  \n",
       "186348       2.000000        1.857143  \n",
       "186349       3.000000        3.428571  \n",
       "186350       2.666667        2.428571  \n",
       "186351       2.666667        3.428571  \n",
       "186352       4.333333        4.285714  \n",
       "186353       4.000000        4.285714  \n",
       "\n",
       "[153514 rows x 100 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.fillna(-1, inplace = True)\n",
    "#data.dropna( inplace = True)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_months</th>\n",
       "      <th>age_years</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>cceb_class</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BSI_Depression_EB</th>\n",
       "      <th>BSI_Anxiety_EB</th>\n",
       "      <th>BSI_Hostility_EB</th>\n",
       "      <th>BSI_Phobic_EB</th>\n",
       "      <th>BSI_Paranoid_EB</th>\n",
       "      <th>BSI_Psychoticism_EB</th>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <th>WQOL.RSociais</th>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>436.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>400.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>468.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>292.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>383.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>536.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>419.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>273.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>376.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>563.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>689.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>351.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>377.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>443.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>485.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>404.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>585.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>321.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>DE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>324.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>335.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>334.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>288.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>438.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Preta</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>421.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>381.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>300.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SUS</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>407.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186306</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>450.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186307</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>512.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186311</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>205.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Fundamental completo/MÃ©dio incompleto (GinÃ¡s...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186314</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186317</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>449.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186321</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>310.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186322</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>431.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186323</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>459.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186325</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>594.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186327</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>644.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186328</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>349.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>DE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186330</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>584.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Preta</td>\n",
       "      <td>B2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186331</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>614.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186333</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>672.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186334</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>679.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.285714</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186335</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>730.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186336</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>758.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186338</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>433.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186339</th>\n",
       "      <td>general</td>\n",
       "      <td>Masculino</td>\n",
       "      <td>556.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Doutorado</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Parda</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186341</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>432.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186342</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>503.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186344</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>610.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186345</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>696.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186346</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>793.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186347</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>809.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4.142857</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186349</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>526.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186350</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>652.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>C1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.142857</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186351</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>690.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Mestrado</td>\n",
       "      <td>Separado(a)/Divorciado(a)</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186352</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>823.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Superior completo</td>\n",
       "      <td>Casado(a)/Vive junto</td>\n",
       "      <td>Branca</td>\n",
       "      <td>B2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186353</th>\n",
       "      <td>general</td>\n",
       "      <td>Feminino</td>\n",
       "      <td>888.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>MÃ©dio completo (Colegial completo)/Superior i...</td>\n",
       "      <td>Solteiro(a)</td>\n",
       "      <td>Parda</td>\n",
       "      <td>B2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>4.166667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112726 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       database        sex  age_months  age_years  \\\n",
       "0           SUS   Feminino       436.0       36.0   \n",
       "1           SUS   Feminino       400.0       33.0   \n",
       "4           SUS   Feminino       468.0       39.0   \n",
       "5           SUS   Feminino       292.0       24.0   \n",
       "6           SUS   Feminino       383.0       31.0   \n",
       "7           SUS   Feminino       321.0       26.0   \n",
       "8           SUS   Feminino       536.0       44.0   \n",
       "9           SUS   Feminino       419.0       34.0   \n",
       "10          SUS   Feminino       273.0       22.0   \n",
       "11          SUS   Feminino       376.0       31.0   \n",
       "12          SUS   Feminino       563.0       46.0   \n",
       "15          SUS  Masculino       689.0       57.0   \n",
       "18          SUS  Masculino       351.0       29.0   \n",
       "19          SUS   Feminino       321.0       26.0   \n",
       "20          SUS   Feminino       377.0       31.0   \n",
       "22          SUS   Feminino       443.0       36.0   \n",
       "24          SUS  Masculino       485.0       40.0   \n",
       "25          SUS   Feminino       404.0       33.0   \n",
       "27          SUS   Feminino       690.0       57.0   \n",
       "28          SUS   Feminino       585.0       48.0   \n",
       "29          SUS   Feminino       321.0       26.0   \n",
       "30          SUS   Feminino       324.0       27.0   \n",
       "31          SUS   Feminino       335.0       27.0   \n",
       "32          SUS   Feminino       334.0       27.0   \n",
       "33          SUS   Feminino       288.0       24.0   \n",
       "35          SUS   Feminino       438.0       36.0   \n",
       "36          SUS   Feminino       421.0       35.0   \n",
       "37          SUS   Feminino       381.0       31.0   \n",
       "38          SUS   Feminino       300.0       25.0   \n",
       "40          SUS  Masculino       407.0       33.0   \n",
       "...         ...        ...         ...        ...   \n",
       "186306  general   Feminino       450.0       37.0   \n",
       "186307  general  Masculino       512.0       42.0   \n",
       "186311  general   Feminino       205.0       17.0   \n",
       "186314  general   Feminino       290.0       24.0   \n",
       "186317  general  Masculino       449.0       37.0   \n",
       "186321  general   Feminino       310.0       25.0   \n",
       "186322  general  Masculino       431.0       35.0   \n",
       "186323  general   Feminino       459.0       38.0   \n",
       "186325  general   Feminino       594.0       49.0   \n",
       "186327  general   Feminino       644.0       53.0   \n",
       "186328  general   Feminino       349.0       29.0   \n",
       "186330  general   Feminino       584.0       48.0   \n",
       "186331  general   Feminino       614.0       51.0   \n",
       "186333  general   Feminino       672.0       56.0   \n",
       "186334  general   Feminino       679.0       56.0   \n",
       "186335  general   Feminino       730.0       60.0   \n",
       "186336  general   Feminino       758.0       63.0   \n",
       "186338  general   Feminino       433.0       36.0   \n",
       "186339  general  Masculino       556.0       46.0   \n",
       "186341  general   Feminino       432.0       36.0   \n",
       "186342  general   Feminino       503.0       41.0   \n",
       "186344  general   Feminino       610.0       50.0   \n",
       "186345  general   Feminino       696.0       58.0   \n",
       "186346  general   Feminino       793.0       66.0   \n",
       "186347  general   Feminino       809.0       67.0   \n",
       "186349  general   Feminino       526.0       43.0   \n",
       "186350  general   Feminino       652.0       54.0   \n",
       "186351  general   Feminino       690.0       57.0   \n",
       "186352  general   Feminino       823.0       68.0   \n",
       "186353  general   Feminino       888.0       74.0   \n",
       "\n",
       "                                                education  \\\n",
       "0                                       Superior completo   \n",
       "1                                       Superior completo   \n",
       "4                                       Superior completo   \n",
       "5                                       Superior completo   \n",
       "6                                                Mestrado   \n",
       "7                                       Superior completo   \n",
       "8                                                Mestrado   \n",
       "9                                       Superior completo   \n",
       "10                                      Superior completo   \n",
       "11                                      Superior completo   \n",
       "12                                      Superior completo   \n",
       "15                                              Doutorado   \n",
       "18                                      Superior completo   \n",
       "19                                      Superior completo   \n",
       "20                                      Superior completo   \n",
       "22                                      Superior completo   \n",
       "24                                      Superior completo   \n",
       "25                                      Superior completo   \n",
       "27                                      Superior completo   \n",
       "28                                      Superior completo   \n",
       "29                                      Superior completo   \n",
       "30                                      Superior completo   \n",
       "31                                      Superior completo   \n",
       "32                                      Superior completo   \n",
       "33                                      Superior completo   \n",
       "35                                      Superior completo   \n",
       "36                                      Superior completo   \n",
       "37                                      Superior completo   \n",
       "38                                      Superior completo   \n",
       "40                                      Superior completo   \n",
       "...                                                   ...   \n",
       "186306                                           Mestrado   \n",
       "186307                                          Doutorado   \n",
       "186311  Fundamental completo/MÃ©dio incompleto (GinÃ¡s...   \n",
       "186314                                  Superior completo   \n",
       "186317                                           Mestrado   \n",
       "186321                                           Mestrado   \n",
       "186322  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186323                                  Superior completo   \n",
       "186325                                           Mestrado   \n",
       "186327  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186328  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186330                                  Superior completo   \n",
       "186331                                           Mestrado   \n",
       "186333                                  Superior completo   \n",
       "186334                                  Superior completo   \n",
       "186335                                  Superior completo   \n",
       "186336                                  Superior completo   \n",
       "186338                                  Superior completo   \n",
       "186339                                          Doutorado   \n",
       "186341  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186342                                  Superior completo   \n",
       "186344  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186345                                  Superior completo   \n",
       "186346                                  Superior completo   \n",
       "186347  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186349                                  Superior completo   \n",
       "186350  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "186351                                           Mestrado   \n",
       "186352                                  Superior completo   \n",
       "186353  MÃ©dio completo (Colegial completo)/Superior i...   \n",
       "\n",
       "                   marital_status ethnicity cceb_class  BSI_1  BSI_2  ...  \\\n",
       "0            Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "1            Casado(a)/Vive junto     Parda         C1    2.0    0.0  ...   \n",
       "4                     Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "5                     Solteiro(a)     Parda         C2    2.0    0.0  ...   \n",
       "6                     Solteiro(a)     Parda         C2    3.0    0.0  ...   \n",
       "7                     Solteiro(a)    Branca         B2    0.0    0.0  ...   \n",
       "8            Casado(a)/Vive junto    Branca         C1    3.0    0.0  ...   \n",
       "9                     Solteiro(a)     Preta         C1    2.0    0.0  ...   \n",
       "10                    Solteiro(a)    Branca         C2    2.0    0.0  ...   \n",
       "11           Casado(a)/Vive junto     Preta         B2    0.0    0.0  ...   \n",
       "12                    Solteiro(a)     Parda         C1    1.0    0.0  ...   \n",
       "15           Casado(a)/Vive junto     Parda         B2    0.0    0.0  ...   \n",
       "18           Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "19           Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "20                    Solteiro(a)    Branca         DE    4.0    1.0  ...   \n",
       "22           Casado(a)/Vive junto    Branca         C2    0.0    0.0  ...   \n",
       "24           Casado(a)/Vive junto     Preta         C1    0.0    0.0  ...   \n",
       "25      Separado(a)/Divorciado(a)    Branca         C1    3.0    0.0  ...   \n",
       "27           Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "28      Separado(a)/Divorciado(a)     Parda         C2    1.0    0.0  ...   \n",
       "29                    Solteiro(a)     Parda         DE    0.0    0.0  ...   \n",
       "30                    Solteiro(a)    Branca         DE    2.0    0.0  ...   \n",
       "31           Casado(a)/Vive junto    Branca         C1    2.0    0.0  ...   \n",
       "32           Casado(a)/Vive junto    Branca         DE    1.0    0.0  ...   \n",
       "33                    Solteiro(a)    Branca         C1    1.0    0.0  ...   \n",
       "35           Casado(a)/Vive junto     Preta         C1    2.0    0.0  ...   \n",
       "36                    Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "37                    Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "38                    Solteiro(a)    Branca         DE    3.0    0.0  ...   \n",
       "40           Casado(a)/Vive junto    Branca         C1    0.0    0.0  ...   \n",
       "...                           ...       ...        ...    ...    ...  ...   \n",
       "186306       Casado(a)/Vive junto    Branca          A    1.0    0.0  ...   \n",
       "186307                Solteiro(a)     Parda         B1    3.0    0.0  ...   \n",
       "186311                Solteiro(a)    Branca          A    2.0    0.0  ...   \n",
       "186314       Casado(a)/Vive junto    Branca         C1    3.0    1.0  ...   \n",
       "186317       Casado(a)/Vive junto    Branca         B1    0.0    0.0  ...   \n",
       "186321       Casado(a)/Vive junto    Branca         B1    2.0    0.0  ...   \n",
       "186322                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186323                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "186325  Separado(a)/Divorciado(a)    Branca         B1    0.0    0.0  ...   \n",
       "186327       Casado(a)/Vive junto    Branca         C1    4.0    1.0  ...   \n",
       "186328                Solteiro(a)    Branca         DE    3.0    2.0  ...   \n",
       "186330  Separado(a)/Divorciado(a)     Preta         B2    4.0    0.0  ...   \n",
       "186331       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186333                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186334  Separado(a)/Divorciado(a)    Branca          A    0.0    1.0  ...   \n",
       "186335       Casado(a)/Vive junto    Branca         C2    1.0    0.0  ...   \n",
       "186336       Casado(a)/Vive junto    Branca         B2    1.0    0.0  ...   \n",
       "186338       Casado(a)/Vive junto     Parda         C2    1.0    0.0  ...   \n",
       "186339       Casado(a)/Vive junto     Parda         C1    0.0    0.0  ...   \n",
       "186341       Casado(a)/Vive junto    Branca         B2    3.0    1.0  ...   \n",
       "186342       Casado(a)/Vive junto    Branca         B2    3.0    2.0  ...   \n",
       "186344       Casado(a)/Vive junto    Branca         C1    2.0    1.0  ...   \n",
       "186345                Solteiro(a)    Branca         C1    2.0    0.0  ...   \n",
       "186346                Solteiro(a)    Branca         C1    0.0    0.0  ...   \n",
       "186347  Separado(a)/Divorciado(a)    Branca         B2    1.0    0.0  ...   \n",
       "186349                Solteiro(a)    Branca         B2    1.0    0.0  ...   \n",
       "186350       Casado(a)/Vive junto    Branca         C1    1.0    0.0  ...   \n",
       "186351  Separado(a)/Divorciado(a)    Branca         B2    3.0    0.0  ...   \n",
       "186352       Casado(a)/Vive junto    Branca         B2    0.0    0.0  ...   \n",
       "186353                Solteiro(a)     Parda         B2    2.0    0.0  ...   \n",
       "\n",
       "        BSI_Depression_EB  BSI_Anxiety_EB  BSI_Hostility_EB  BSI_Phobic_EB  \\\n",
       "0                0.333333        0.500000               0.0            0.2   \n",
       "1                0.833333        1.500000               1.0            1.0   \n",
       "4                0.500000        0.666667               0.0            1.6   \n",
       "5                1.833333        1.666667               1.0            1.4   \n",
       "6                1.166667        0.833333               0.4            0.4   \n",
       "7                0.000000        0.000000               0.0            0.0   \n",
       "8                1.000000        1.500000               0.8            1.2   \n",
       "9                0.166667        0.666667               0.2            0.2   \n",
       "10               0.000000        0.833333               0.0            0.0   \n",
       "11               0.166667        0.000000               0.2            0.2   \n",
       "12               0.166667        0.166667               0.0            0.0   \n",
       "15               0.000000        0.000000               0.0            0.0   \n",
       "18               0.166667        0.000000               0.0            0.2   \n",
       "19               1.333333        2.333333               1.6            2.0   \n",
       "20               2.166667        1.833333               2.0            0.4   \n",
       "22               0.166667        0.000000               0.0            0.0   \n",
       "24               0.166667        0.000000               0.4            0.8   \n",
       "25               1.333333        1.166667               0.8            0.4   \n",
       "27               0.333333        0.333333               0.0            0.0   \n",
       "28               0.500000        0.166667               0.2            0.0   \n",
       "29               0.166667        0.000000               0.0            0.0   \n",
       "30               0.166667        1.166667               0.0            1.6   \n",
       "31               0.500000        0.833333               0.2            0.6   \n",
       "32               0.333333        0.500000               0.0            0.2   \n",
       "33               0.000000        0.166667               0.2            0.0   \n",
       "35               1.333333        1.000000               1.0            0.8   \n",
       "36               1.333333        0.666667               0.8            1.2   \n",
       "37               0.333333        0.666667               0.2            1.0   \n",
       "38               2.000000        1.666667               0.6            1.6   \n",
       "40               0.666667        0.333333               0.2            0.6   \n",
       "...                   ...             ...               ...            ...   \n",
       "186306           0.166667        0.500000               0.2            1.2   \n",
       "186307           1.666667        1.666667               0.4            2.0   \n",
       "186311           1.833333        0.833333               1.2            0.8   \n",
       "186314           2.333333        1.500000               1.2            1.8   \n",
       "186317           0.333333        0.166667               0.2            0.0   \n",
       "186321           0.666667        2.333333               3.2            3.4   \n",
       "186322           0.833333        0.666667               0.2            1.4   \n",
       "186323           2.500000        2.000000               0.8            0.8   \n",
       "186325           0.166667        0.000000               0.0            0.0   \n",
       "186327           2.833333        3.000000               1.8            3.6   \n",
       "186328           3.000000        1.666667               0.4            1.6   \n",
       "186330           2.333333        3.333333               1.0            3.8   \n",
       "186331           1.166667        2.333333               2.2            2.4   \n",
       "186333           0.000000        0.000000               0.0            0.4   \n",
       "186334           1.500000        0.500000               1.2            0.2   \n",
       "186335           1.666667        1.000000               1.2            0.8   \n",
       "186336           0.666667        0.500000               0.2            0.4   \n",
       "186338           0.666667        0.666667               2.2            0.2   \n",
       "186339           2.000000        0.333333               0.2            1.2   \n",
       "186341           2.500000        2.500000               2.4            3.0   \n",
       "186342           1.833333        2.166667               1.2            2.6   \n",
       "186344           0.833333        1.333333               0.2            0.8   \n",
       "186345           0.500000        1.000000               0.2            0.6   \n",
       "186346           0.166667        0.000000               0.0            1.0   \n",
       "186347           0.500000        0.333333               0.0            0.4   \n",
       "186349           0.500000        0.333333               0.6            0.0   \n",
       "186350           0.500000        0.500000               0.2            0.4   \n",
       "186351           3.333333        2.000000               1.0            2.6   \n",
       "186352           0.500000        0.166667               0.0            0.0   \n",
       "186353           1.000000        0.666667               0.2            1.6   \n",
       "\n",
       "        BSI_Paranoid_EB  BSI_Psychoticism_EB  WQOL.Fisico  WQOL.Psicologico  \\\n",
       "0                   0.0                  0.0     4.285714          4.166667   \n",
       "1                   1.0                  0.4     2.857143          3.333333   \n",
       "4                   0.4                  0.0     3.428571          3.333333   \n",
       "5                   2.0                  2.4     3.714286          3.333333   \n",
       "6                   0.2                  0.4     3.285714          3.166667   \n",
       "7                   0.0                  0.0     3.857143          4.166667   \n",
       "8                   0.2                  0.6     3.428571          3.000000   \n",
       "9                   0.0                  0.2     4.000000          4.500000   \n",
       "10                  0.2                  0.0     4.000000          4.333333   \n",
       "11                  0.0                  0.0     4.571429          4.833333   \n",
       "12                  0.0                  0.0     4.000000          3.666667   \n",
       "15                  0.4                  0.0     4.857143          5.000000   \n",
       "18                  0.2                  0.0     4.428571          4.333333   \n",
       "19                  1.2                  1.6     4.000000          3.833333   \n",
       "20                  1.4                  1.4     3.285714          2.166667   \n",
       "22                  0.2                  0.2     4.857143          4.833333   \n",
       "24                  0.2                  0.0     4.142857          4.333333   \n",
       "25                  0.2                  0.8     3.857143          2.833333   \n",
       "27                  0.0                  0.0     4.428571          3.500000   \n",
       "28                  0.8                  0.0     4.714286          3.666667   \n",
       "29                  0.4                  0.2     4.000000          4.333333   \n",
       "30                  0.6                  0.0     4.428571          3.666667   \n",
       "31                  0.6                  0.4     4.285714          3.833333   \n",
       "32                  1.6                  0.2     4.285714          3.833333   \n",
       "33                  0.0                  0.0     4.142857          3.833333   \n",
       "35                  1.4                  1.2     3.428571          3.333333   \n",
       "36                  0.4                  1.0     4.285714          3.833333   \n",
       "37                  0.0                  0.0     4.714286          4.166667   \n",
       "38                  0.2                  0.8     3.285714          2.833333   \n",
       "40                  0.4                  0.0     3.857143          3.833333   \n",
       "...                 ...                  ...          ...               ...   \n",
       "186306              0.2                  0.0     4.428571          3.666667   \n",
       "186307              1.0                  2.2     3.714286          2.833333   \n",
       "186311              1.0                  1.2     4.000000          4.166667   \n",
       "186314              1.0                  1.4     3.428571          3.666667   \n",
       "186317              0.2                  0.0     3.857143          4.333333   \n",
       "186321              1.0                  1.2     4.142857          3.666667   \n",
       "186322              0.0                  0.6     3.428571          2.166667   \n",
       "186323              1.8                  1.2     3.142857          3.666667   \n",
       "186325              0.0                  0.0     3.571429          3.666667   \n",
       "186327              2.2                  2.0     1.857143          2.666667   \n",
       "186328              1.2                  1.8     2.000000          2.333333   \n",
       "186330              1.8                  1.6     2.000000          2.500000   \n",
       "186331              1.0                  1.0     2.428571          2.666667   \n",
       "186333              0.2                  0.0     3.571429          4.166667   \n",
       "186334              2.2                  0.6     3.285714          2.500000   \n",
       "186335              1.0                  0.6     2.714286          1.833333   \n",
       "186336              0.6                  0.4     3.428571          3.500000   \n",
       "186338              1.0                  0.8     4.142857          3.500000   \n",
       "186339              1.6                  1.0     4.000000          2.833333   \n",
       "186341              2.2                  2.0     2.714286          2.333333   \n",
       "186342              0.6                  0.0     3.000000          2.500000   \n",
       "186344              1.2                  0.4     3.000000          3.166667   \n",
       "186345              0.8                  0.2     3.571429          3.333333   \n",
       "186346              0.0                  0.0     4.000000          4.333333   \n",
       "186347              0.2                  0.4     4.142857          4.333333   \n",
       "186349              0.4                  0.0     3.857143          2.666667   \n",
       "186350              0.4                  0.0     3.142857          3.333333   \n",
       "186351              1.4                  1.6     2.142857          2.000000   \n",
       "186352              0.0                  0.2     4.285714          4.666667   \n",
       "186353              0.2                  0.2     4.571429          4.166667   \n",
       "\n",
       "        WQOL.RSociais  WQOL_MAmbiente  \n",
       "0            4.000000        3.714286  \n",
       "1            2.333333        3.142857  \n",
       "4            3.000000        4.142857  \n",
       "5            3.666667        3.857143  \n",
       "6            2.666667        3.285714  \n",
       "7            4.666667        4.142857  \n",
       "8            2.666667        3.428571  \n",
       "9            5.000000        3.571429  \n",
       "10           4.000000        4.428571  \n",
       "11           4.333333        4.000000  \n",
       "12           3.333333        2.714286  \n",
       "15           4.333333        3.857143  \n",
       "18           4.666667        3.714286  \n",
       "19           4.000000        3.857143  \n",
       "20           1.333333        2.285714  \n",
       "22           4.000000        3.857143  \n",
       "24           3.333333        3.428571  \n",
       "25           2.666667        3.428571  \n",
       "27           3.666667        3.571429  \n",
       "28           4.333333        3.000000  \n",
       "29           3.000000        2.571429  \n",
       "30           4.000000        3.714286  \n",
       "31           3.666667        3.000000  \n",
       "32           2.333333        4.000000  \n",
       "33           3.333333        3.857143  \n",
       "35           3.333333        3.000000  \n",
       "36           3.333333        2.714286  \n",
       "37           3.000000        4.000000  \n",
       "38           2.333333        2.142857  \n",
       "40           2.333333        2.428571  \n",
       "...               ...             ...  \n",
       "186306       3.333333        4.285714  \n",
       "186307       1.666667        3.714286  \n",
       "186311       5.000000        4.428571  \n",
       "186314       3.333333        3.000000  \n",
       "186317       4.000000        3.857143  \n",
       "186321       3.333333        4.428571  \n",
       "186322       2.666667        4.142857  \n",
       "186323       2.666667        2.571429  \n",
       "186325       3.666667        3.000000  \n",
       "186327       2.333333        2.571429  \n",
       "186328       2.333333        2.428571  \n",
       "186330       2.666667        2.857143  \n",
       "186331       3.333333        2.714286  \n",
       "186333       4.000000        3.285714  \n",
       "186334       2.000000        3.714286  \n",
       "186335       1.666667        2.857143  \n",
       "186336       3.666667        3.142857  \n",
       "186338       3.666667        3.571429  \n",
       "186339       1.666667        3.428571  \n",
       "186341       2.333333        2.571429  \n",
       "186342       3.000000        3.142857  \n",
       "186344       4.000000        2.428571  \n",
       "186345       3.666667        3.000000  \n",
       "186346       3.666667        4.142857  \n",
       "186347       4.000000        4.285714  \n",
       "186349       3.000000        3.428571  \n",
       "186350       2.666667        2.428571  \n",
       "186351       2.666667        3.428571  \n",
       "186352       4.333333        4.285714  \n",
       "186353       4.000000        4.285714  \n",
       "\n",
       "[112726 rows x 100 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSI_Somatization_EB</th>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSI_Somatization_EB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.497689</td>\n",
       "      <td>-0.557834</td>\n",
       "      <td>-0.317014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WQOL.Psicologico</th>\n",
       "      <td>-0.497689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730442</td>\n",
       "      <td>0.533360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WQOL.Fisico</th>\n",
       "      <td>-0.557834</td>\n",
       "      <td>0.730442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.522760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WQOL_MAmbiente</th>\n",
       "      <td>-0.317014</td>\n",
       "      <td>0.533360</td>\n",
       "      <td>0.522760</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BSI_Somatization_EB  WQOL.Psicologico  WQOL.Fisico  \\\n",
       "BSI_Somatization_EB             1.000000         -0.497689    -0.557834   \n",
       "WQOL.Psicologico               -0.497689          1.000000     0.730442   \n",
       "WQOL.Fisico                    -0.557834          0.730442     1.000000   \n",
       "WQOL_MAmbiente                 -0.317014          0.533360     0.522760   \n",
       "\n",
       "                     WQOL_MAmbiente  \n",
       "BSI_Somatization_EB       -0.317014  \n",
       "WQOL.Psicologico           0.533360  \n",
       "WQOL.Fisico                0.522760  \n",
       "WQOL_MAmbiente             1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['BSI_Somatization_EB', 'WQOL.Psicologico', 'WQOL.Fisico','WQOL_MAmbiente']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "Y1 = data['BSI_Somatization_EB']\n",
    "Y2 = data[whoqol]\n",
    "#data['mean'] = np.round(data['mean']/10)\n",
    "\n",
    "#Y2 = data['\"ARTERIAL_DIAS\"']\n",
    "data.drop(whoqol + bsi ,axis = 1, inplace = True)\n",
    "X = data[bsi_feat]\n",
    "X2 = data[new_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHOQoL_6     4.0\n",
       "WHOQoL_10    4.0\n",
       "WHOQoL_14    5.0\n",
       "WHOQoL_16    4.0\n",
       "WHOQoL_18    4.0\n",
       "WHOQoL_19    4.0\n",
       "WHOQoL_20    3.0\n",
       "WHOQoL_22    2.0\n",
       "WHOQoL_25    5.0\n",
       "WHOQoL_26    3.0\n",
       "BSI_1        1.0\n",
       "BSI_9        0.0\n",
       "BSI_12       0.0\n",
       "BSI_23       0.0\n",
       "BSI_37       0.0\n",
       "BSI_38       1.0\n",
       "BSI_45       0.0\n",
       "BSI_49       0.0\n",
       "Name: 38194, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.iloc[idn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y2 = Y2['WQOL.Fisico']\n",
    "Y2 = Y2['WQOL.Psicologico']\n",
    "#Y2 = Y2['WQOL.RSociais']\n",
    "#Y2 = Y2['WQOL_MAmbiente']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = Y1/np.max(Y1)\n",
    "#Y1 = Y1['BSI_GSI']\n",
    "Y2 = Y2/np.max(Y2)\n",
    "#Y2 = Y2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, Y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "     X2, Y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2.loc[185283]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(X2_train.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "# Encoder Layers\n",
    "\n",
    "\n",
    "encoded1 = Dense(50, activation = 'tanh')(input_dim)\n",
    "#drop1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(50, activation = 'tanh')(encoded1)\n",
    "encoded3 = Dense(50, activation = 'tanh')(encoded2)\n",
    "encoded4 = Dense(50, activation = 'tanh')(encoded3)\n",
    "encoded5 = Dense(50, activation = 'tanh')(encoded4)\n",
    "decoded13 = Dense(1, activation = 'sigmoid')(encoded5)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder = Model(inputs = input_dim, outputs = [decoded13])\n",
    "optimizers.Adam()\n",
    "# Compile the Model\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0465 - val_loss: 0.0438\n",
      "Epoch 2/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0408 - val_loss: 0.0416\n",
      "Epoch 3/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0401 - val_loss: 0.0396\n",
      "Epoch 4/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0399 - val_loss: 0.0398\n",
      "Epoch 5/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0398 - val_loss: 0.0439\n",
      "Epoch 6/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0397 - val_loss: 0.0404\n",
      "Epoch 7/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0396 - val_loss: 0.0394\n",
      "Epoch 8/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0399\n",
      "Epoch 9/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0399\n",
      "Epoch 10/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0395 - val_loss: 0.0403\n",
      "Epoch 11/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0400\n",
      "Epoch 12/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0394 - val_loss: 0.0396\n",
      "Epoch 13/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0392 - val_loss: 0.0398\n",
      "Epoch 14/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0392 - val_loss: 0.0396\n",
      "Epoch 15/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0396\n",
      "Epoch 16/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0393\n",
      "Epoch 17/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0409\n",
      "Epoch 18/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0400\n",
      "Epoch 19/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0390 - val_loss: 0.0393\n",
      "Epoch 20/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0394\n",
      "Epoch 21/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0391 - val_loss: 0.0410\n",
      "Epoch 22/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0390 - val_loss: 0.0412\n",
      "Epoch 23/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0400\n",
      "Epoch 24/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0392\n",
      "Epoch 25/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0398\n",
      "Epoch 26/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0388 - val_loss: 0.0403\n",
      "Epoch 27/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0393\n",
      "Epoch 28/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0397\n",
      "Epoch 29/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0388 - val_loss: 0.0393\n",
      "Epoch 30/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 31/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0397\n",
      "Epoch 32/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 33/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0393\n",
      "Epoch 34/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0393\n",
      "Epoch 35/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0395\n",
      "Epoch 36/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0393\n",
      "Epoch 37/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0395\n",
      "Epoch 38/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0406\n",
      "Epoch 39/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0395\n",
      "Epoch 40/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0396\n",
      "Epoch 41/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0397\n",
      "Epoch 42/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0387 - val_loss: 0.0392\n",
      "Epoch 43/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0393\n",
      "Epoch 44/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0386 - val_loss: 0.0392\n",
      "Epoch 45/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0393\n",
      "Epoch 46/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0395\n",
      "Epoch 47/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0399\n",
      "Epoch 48/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0391\n",
      "Epoch 49/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0384 - val_loss: 0.0393\n",
      "Epoch 50/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0393\n",
      "Epoch 51/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0384 - val_loss: 0.0396\n",
      "Epoch 52/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0384 - val_loss: 0.0393\n",
      "Epoch 53/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0385 - val_loss: 0.0394\n",
      "Epoch 54/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 55/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0401\n",
      "Epoch 56/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0393\n",
      "Epoch 57/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 58/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0392\n",
      "Epoch 59/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0396\n",
      "Epoch 60/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 61/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0394\n",
      "Epoch 62/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0383 - val_loss: 0.0393\n",
      "Epoch 63/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0382 - val_loss: 0.0397\n",
      "Epoch 64/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0396\n",
      "Epoch 65/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0392\n",
      "Epoch 66/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0394\n",
      "Epoch 67/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0395\n",
      "Epoch 68/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0394\n",
      "Epoch 69/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0393\n",
      "Epoch 70/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0397\n",
      "Epoch 71/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0396\n",
      "Epoch 72/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0381 - val_loss: 0.0393\n",
      "Epoch 73/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0393\n",
      "Epoch 74/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0394\n",
      "Epoch 75/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0405\n",
      "Epoch 76/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0396\n",
      "Epoch 77/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 78/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0380 - val_loss: 0.0393\n",
      "Epoch 79/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0395\n",
      "Epoch 80/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0393\n",
      "Epoch 81/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0396\n",
      "Epoch 82/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0399\n",
      "Epoch 83/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0379 - val_loss: 0.0404\n",
      "Epoch 84/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0396\n",
      "Epoch 85/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 86/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0400\n",
      "Epoch 87/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0394\n",
      "Epoch 88/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0394\n",
      "Epoch 89/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0376 - val_loss: 0.0404\n",
      "Epoch 90/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0378 - val_loss: 0.0396\n",
      "Epoch 91/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0377 - val_loss: 0.0396\n",
      "Epoch 92/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0398\n",
      "Epoch 93/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0376 - val_loss: 0.0396\n",
      "Epoch 94/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0396\n",
      "Epoch 95/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0395\n",
      "Epoch 96/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0395\n",
      "Epoch 97/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0398\n",
      "Epoch 98/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0396\n",
      "Epoch 99/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0395\n",
      "Epoch 100/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0395\n",
      "Epoch 101/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0399\n",
      "Epoch 102/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0395\n",
      "Epoch 103/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0374 - val_loss: 0.0399\n",
      "Epoch 104/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0375 - val_loss: 0.0399\n",
      "Epoch 105/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0396\n",
      "Epoch 106/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0399\n",
      "Epoch 107/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0396\n",
      "Epoch 108/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0397\n",
      "Epoch 109/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0396\n",
      "Epoch 110/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0373 - val_loss: 0.0399\n",
      "Epoch 111/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 112/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0397\n",
      "Epoch 113/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 114/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0403\n",
      "Epoch 115/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 116/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0397\n",
      "Epoch 117/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0399\n",
      "Epoch 118/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0400\n",
      "Epoch 119/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0399\n",
      "Epoch 120/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0399\n",
      "Epoch 121/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0402\n",
      "Epoch 122/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 123/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 124/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0411\n",
      "Epoch 125/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0402\n",
      "Epoch 126/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 127/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0400\n",
      "Epoch 128/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0369 - val_loss: 0.0399\n",
      "Epoch 129/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 130/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0399\n",
      "Epoch 131/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0402\n",
      "Epoch 132/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0399\n",
      "Epoch 133/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 134/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0400\n",
      "Epoch 135/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0402\n",
      "Epoch 136/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0401\n",
      "Epoch 137/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 138/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0366 - val_loss: 0.0403\n",
      "Epoch 139/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0409\n",
      "Epoch 140/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0400\n",
      "Epoch 141/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0400\n",
      "Epoch 142/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 143/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0402\n",
      "Epoch 144/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0402\n",
      "Epoch 145/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0367 - val_loss: 0.0397\n",
      "Epoch 146/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0399\n",
      "Epoch 147/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0402\n",
      "Epoch 148/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0368 - val_loss: 0.0401\n",
      "Epoch 149/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0364 - val_loss: 0.0402\n",
      "Epoch 150/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0400\n",
      "Epoch 151/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0364 - val_loss: 0.0399\n",
      "Epoch 152/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0399\n",
      "Epoch 153/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0400\n",
      "Epoch 154/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0402\n",
      "Epoch 155/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0404\n",
      "Epoch 156/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0365 - val_loss: 0.0402\n",
      "Epoch 157/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0400\n",
      "Epoch 158/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0402\n",
      "Epoch 159/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0403\n",
      "Epoch 160/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0400\n",
      "Epoch 162/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0401\n",
      "Epoch 163/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0403\n",
      "Epoch 164/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0407\n",
      "Epoch 165/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0401\n",
      "Epoch 166/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0363 - val_loss: 0.0404\n",
      "Epoch 167/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0401\n",
      "Epoch 168/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0407\n",
      "Epoch 169/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0362 - val_loss: 0.0400\n",
      "Epoch 170/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0361 - val_loss: 0.0402\n",
      "Epoch 171/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0402\n",
      "Epoch 172/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0403\n",
      "Epoch 173/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0401\n",
      "Epoch 174/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0403\n",
      "Epoch 175/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0402\n",
      "Epoch 176/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0402\n",
      "Epoch 177/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0404\n",
      "Epoch 178/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0403\n",
      "Epoch 179/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0360 - val_loss: 0.0404\n",
      "Epoch 180/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0401\n",
      "Epoch 181/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0402\n",
      "Epoch 182/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0404\n",
      "Epoch 183/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0404\n",
      "Epoch 184/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0404\n",
      "Epoch 185/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0404\n",
      "Epoch 186/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0402\n",
      "Epoch 187/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0404\n",
      "Epoch 188/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0358 - val_loss: 0.0402\n",
      "Epoch 189/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0403\n",
      "Epoch 190/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0407\n",
      "Epoch 191/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0406\n",
      "Epoch 192/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0402\n",
      "Epoch 193/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0404\n",
      "Epoch 194/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0404\n",
      "Epoch 195/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0405\n",
      "Epoch 196/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0403\n",
      "Epoch 197/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0404\n",
      "Epoch 198/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0404\n",
      "Epoch 199/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0404\n",
      "Epoch 200/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0406\n",
      "Epoch 201/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 202/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0403\n",
      "Epoch 203/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0403\n",
      "Epoch 204/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0403\n",
      "Epoch 205/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0406\n",
      "Epoch 206/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0404\n",
      "Epoch 207/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0406\n",
      "Epoch 208/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0404\n",
      "Epoch 209/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 210/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0406\n",
      "Epoch 211/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0406\n",
      "Epoch 212/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0407\n",
      "Epoch 213/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0403\n",
      "Epoch 214/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0404\n",
      "Epoch 215/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0405\n",
      "Epoch 216/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 217/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 218/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 219/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0356 - val_loss: 0.0407\n",
      "Epoch 220/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0404\n",
      "Epoch 221/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0354 - val_loss: 0.0405\n",
      "Epoch 222/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0405\n",
      "Epoch 223/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0406\n",
      "Epoch 224/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0405\n",
      "Epoch 225/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0406\n",
      "Epoch 226/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0407\n",
      "Epoch 227/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0406\n",
      "Epoch 228/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0405\n",
      "Epoch 229/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0408\n",
      "Epoch 230/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0404\n",
      "Epoch 231/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0406\n",
      "Epoch 232/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 233/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0408\n",
      "Epoch 234/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0407\n",
      "Epoch 235/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0404\n",
      "Epoch 236/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0407\n",
      "Epoch 237/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0404\n",
      "Epoch 238/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0406\n",
      "Epoch 239/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0407\n",
      "Epoch 240/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0408\n",
      "Epoch 241/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0410\n",
      "Epoch 242/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0406\n",
      "Epoch 243/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0408\n",
      "Epoch 244/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0408\n",
      "Epoch 245/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0406\n",
      "Epoch 246/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0405\n",
      "Epoch 247/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0405\n",
      "Epoch 248/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0406\n",
      "Epoch 249/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0410\n",
      "Epoch 250/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0353 - val_loss: 0.0406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3441b7908>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=30,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "autoencoder.fit(x = X2_train, y = y_train, epochs = 250, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                 validation_data=(X2_test, y_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "#     X2, Y2, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = autoencoder.predict(X2_test)\n",
    "#X2_train['pred'] = pred\n",
    "#X2_train['BSI_1'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = autoencoder.predict(X2_train.drop('pred',axis=1))\n",
    "#X2_train['cf'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(X2_train[X2_train['cf']- X2_train['pred']>0.001])/len(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10070564516127954"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7121124858998555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04057277293775309"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r2_score(pred,y_test))\n",
    "mean_absolute_error(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(X2.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "# Encoder Layers\n",
    "\n",
    "encoded1 = Dense(50, activation = 'tanh')(input_dim)\n",
    "#drop1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(50, activation = 'tanh')(encoded1)\n",
    "encoded3 = Dense(50, activation = 'tanh')(encoded2)\n",
    "encoded4 = Dense(50, activation = 'tanh')(encoded3)\n",
    "encoded5 = Dense(50, activation = 'tanh')(encoded4)\n",
    "decoded13 = Dense(1, activation = 'sigmoid')(encoded5)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "autoencoder2 = Model(inputs = input_dim, outputs = [decoded13])\n",
    "\n",
    "# Compile the Model\n",
    "autoencoder2.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0470 - val_loss: 0.0516\n",
      "Epoch 2/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0389 - val_loss: 0.0421\n",
      "Epoch 3/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0371 - val_loss: 0.0514\n",
      "Epoch 4/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0364 - val_loss: 0.0369\n",
      "Epoch 5/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0359 - val_loss: 0.0359\n",
      "Epoch 6/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0357 - val_loss: 0.0345\n",
      "Epoch 7/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0355 - val_loss: 0.0406\n",
      "Epoch 8/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0376\n",
      "Epoch 9/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0350 - val_loss: 0.0376\n",
      "Epoch 10/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0351 - val_loss: 0.0344\n",
      "Epoch 11/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0349 - val_loss: 0.0338\n",
      "Epoch 12/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0352 - val_loss: 0.0341\n",
      "Epoch 13/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0354\n",
      "Epoch 14/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0386\n",
      "Epoch 15/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0348 - val_loss: 0.0361\n",
      "Epoch 16/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0347 - val_loss: 0.0352\n",
      "Epoch 17/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0341\n",
      "Epoch 18/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0346 - val_loss: 0.0375\n",
      "Epoch 19/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0382\n",
      "Epoch 20/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0381\n",
      "Epoch 21/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0352\n",
      "Epoch 22/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 23/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0344 - val_loss: 0.0413\n",
      "Epoch 24/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0342\n",
      "Epoch 25/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0353\n",
      "Epoch 26/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0374\n",
      "Epoch 27/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0366\n",
      "Epoch 28/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0343 - val_loss: 0.0337\n",
      "Epoch 29/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0336\n",
      "Epoch 30/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0392\n",
      "Epoch 31/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0343\n",
      "Epoch 32/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0358\n",
      "Epoch 33/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0338\n",
      "Epoch 34/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0340 - val_loss: 0.0338\n",
      "Epoch 35/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0338\n",
      "Epoch 36/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0342 - val_loss: 0.0461\n",
      "Epoch 37/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0340 - val_loss: 0.0342\n",
      "Epoch 38/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0337\n",
      "Epoch 39/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0367\n",
      "Epoch 40/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0375\n",
      "Epoch 41/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0341 - val_loss: 0.0343\n",
      "Epoch 42/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0340 - val_loss: 0.0338\n",
      "Epoch 43/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0344\n",
      "Epoch 44/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0345\n",
      "Epoch 45/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0344\n",
      "Epoch 46/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0394\n",
      "Epoch 47/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0351\n",
      "Epoch 48/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0339\n",
      "Epoch 49/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0351\n",
      "Epoch 50/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0342\n",
      "Epoch 51/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 52/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0336\n",
      "Epoch 53/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0339 - val_loss: 0.0344\n",
      "Epoch 54/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0338 - val_loss: 0.0347\n",
      "Epoch 55/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0346\n",
      "Epoch 56/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0336\n",
      "Epoch 57/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0397\n",
      "Epoch 58/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0368\n",
      "Epoch 59/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0337 - val_loss: 0.0346\n",
      "Epoch 60/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0347\n",
      "Epoch 61/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0335\n",
      "Epoch 62/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0352\n",
      "Epoch 63/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0339\n",
      "Epoch 64/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0336 - val_loss: 0.0346\n",
      "Epoch 65/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0338\n",
      "Epoch 66/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0340\n",
      "Epoch 67/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0334\n",
      "Epoch 68/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0335 - val_loss: 0.0335\n",
      "Epoch 69/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0337\n",
      "Epoch 70/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0346\n",
      "Epoch 71/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0341\n",
      "Epoch 72/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0352\n",
      "Epoch 73/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0354\n",
      "Epoch 74/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0334 - val_loss: 0.0355\n",
      "Epoch 75/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0343\n",
      "Epoch 76/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0333 - val_loss: 0.0347\n",
      "Epoch 77/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0340\n",
      "Epoch 78/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 79/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0389\n",
      "Epoch 80/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0332 - val_loss: 0.0356\n",
      "Epoch 81/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0336\n",
      "Epoch 82/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0338\n",
      "Epoch 83/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0341\n",
      "Epoch 84/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0331 - val_loss: 0.0344\n",
      "Epoch 85/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0337\n",
      "Epoch 86/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0347\n",
      "Epoch 87/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0330 - val_loss: 0.0336\n",
      "Epoch 88/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0337\n",
      "Epoch 89/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0334\n",
      "Epoch 90/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0335\n",
      "Epoch 91/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0336\n",
      "Epoch 92/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0350\n",
      "Epoch 93/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0347\n",
      "Epoch 94/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0329 - val_loss: 0.0356\n",
      "Epoch 95/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0336\n",
      "Epoch 96/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0341\n",
      "Epoch 97/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0339\n",
      "Epoch 98/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0335\n",
      "Epoch 99/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0326 - val_loss: 0.0338\n",
      "Epoch 100/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0339\n",
      "Epoch 101/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0328 - val_loss: 0.0349\n",
      "Epoch 102/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0347\n",
      "Epoch 103/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0345\n",
      "Epoch 104/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0327 - val_loss: 0.0345\n",
      "Epoch 105/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0336\n",
      "Epoch 106/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0346\n",
      "Epoch 107/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0336\n",
      "Epoch 108/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0345\n",
      "Epoch 109/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0338\n",
      "Epoch 110/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0324 - val_loss: 0.0339\n",
      "Epoch 111/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0325 - val_loss: 0.0339\n",
      "Epoch 112/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0324 - val_loss: 0.0336\n",
      "Epoch 113/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0346\n",
      "Epoch 114/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0342\n",
      "Epoch 115/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0337\n",
      "Epoch 116/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0344\n",
      "Epoch 117/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0323 - val_loss: 0.0337\n",
      "Epoch 118/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0337\n",
      "Epoch 119/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0324 - val_loss: 0.0338\n",
      "Epoch 120/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0359\n",
      "Epoch 121/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0340\n",
      "Epoch 122/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0340\n",
      "Epoch 123/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0341\n",
      "Epoch 124/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0339\n",
      "Epoch 125/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0340\n",
      "Epoch 126/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.0340\n",
      "Epoch 127/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0339\n",
      "Epoch 128/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0322 - val_loss: 0.0352\n",
      "Epoch 129/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0320 - val_loss: 0.0345\n",
      "Epoch 130/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.0339\n",
      "Epoch 131/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.0351\n",
      "Epoch 132/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0320 - val_loss: 0.0337\n",
      "Epoch 133/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0320 - val_loss: 0.0340\n",
      "Epoch 134/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.0338\n",
      "Epoch 135/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0321 - val_loss: 0.0343\n",
      "Epoch 136/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0339\n",
      "Epoch 137/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0339\n",
      "Epoch 138/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0342\n",
      "Epoch 139/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0364\n",
      "Epoch 140/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0355\n",
      "Epoch 141/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0341\n",
      "Epoch 142/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0318 - val_loss: 0.0344\n",
      "Epoch 143/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0339\n",
      "Epoch 144/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0338\n",
      "Epoch 145/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0349\n",
      "Epoch 146/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0345\n",
      "Epoch 147/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0319 - val_loss: 0.0341\n",
      "Epoch 148/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0339\n",
      "Epoch 149/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0340\n",
      "Epoch 150/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0343\n",
      "Epoch 151/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0345\n",
      "Epoch 152/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0339\n",
      "Epoch 153/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0354\n",
      "Epoch 154/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0317 - val_loss: 0.0343\n",
      "Epoch 155/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0342\n",
      "Epoch 156/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0341\n",
      "Epoch 157/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0355\n",
      "Epoch 158/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0338\n",
      "Epoch 159/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0342\n",
      "Epoch 160/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0316 - val_loss: 0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0341\n",
      "Epoch 162/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0340\n",
      "Epoch 163/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0344\n",
      "Epoch 164/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0342\n",
      "Epoch 165/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0315 - val_loss: 0.0340\n",
      "Epoch 166/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0343\n",
      "Epoch 167/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0345\n",
      "Epoch 168/250\n",
      "591/591 [==============================] - 1s 2ms/step - loss: 0.0314 - val_loss: 0.0339\n",
      "Epoch 169/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0346\n",
      "Epoch 170/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0341\n",
      "Epoch 171/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0346\n",
      "Epoch 172/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0340\n",
      "Epoch 173/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0350\n",
      "Epoch 174/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0353\n",
      "Epoch 175/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0314 - val_loss: 0.0342\n",
      "Epoch 176/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0342\n",
      "Epoch 177/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0341\n",
      "Epoch 178/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0342\n",
      "Epoch 179/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0313 - val_loss: 0.0352\n",
      "Epoch 180/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0358\n",
      "Epoch 181/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0343\n",
      "Epoch 182/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0312 - val_loss: 0.0341\n",
      "Epoch 183/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0342\n",
      "Epoch 184/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0345\n",
      "Epoch 185/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0341\n",
      "Epoch 186/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0348\n",
      "Epoch 187/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0347\n",
      "Epoch 188/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0351\n",
      "Epoch 189/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0349\n",
      "Epoch 190/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0352\n",
      "Epoch 191/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0345\n",
      "Epoch 192/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0347\n",
      "Epoch 193/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0350\n",
      "Epoch 194/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0343\n",
      "Epoch 195/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0310 - val_loss: 0.0345\n",
      "Epoch 196/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0311 - val_loss: 0.0344\n",
      "Epoch 197/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0342\n",
      "Epoch 198/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0344\n",
      "Epoch 199/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0344\n",
      "Epoch 200/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0347\n",
      "Epoch 201/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0347\n",
      "Epoch 202/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0348\n",
      "Epoch 203/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0355\n",
      "Epoch 204/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0346\n",
      "Epoch 205/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0343\n",
      "Epoch 206/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0309 - val_loss: 0.0345\n",
      "Epoch 207/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0352\n",
      "Epoch 208/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0342\n",
      "Epoch 209/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0353\n",
      "Epoch 210/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0350\n",
      "Epoch 211/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0346\n",
      "Epoch 212/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0354\n",
      "Epoch 213/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0353\n",
      "Epoch 214/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0344\n",
      "Epoch 215/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0344\n",
      "Epoch 216/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0352\n",
      "Epoch 217/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0349\n",
      "Epoch 218/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0345\n",
      "Epoch 219/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0345\n",
      "Epoch 220/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0361\n",
      "Epoch 221/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 222/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0307 - val_loss: 0.0354\n",
      "Epoch 223/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0349\n",
      "Epoch 224/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0351\n",
      "Epoch 225/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0308 - val_loss: 0.0346\n",
      "Epoch 226/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0351\n",
      "Epoch 227/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0348\n",
      "Epoch 228/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0353\n",
      "Epoch 229/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0345\n",
      "Epoch 230/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 231/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0347\n",
      "Epoch 232/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0347\n",
      "Epoch 233/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 234/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0346\n",
      "Epoch 235/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0346\n",
      "Epoch 236/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0347\n",
      "Epoch 237/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0347\n",
      "Epoch 238/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0346\n",
      "Epoch 239/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0345\n",
      "Epoch 240/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0347\n",
      "Epoch 241/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0349\n",
      "Epoch 242/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0349\n",
      "Epoch 243/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0348\n",
      "Epoch 244/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0305 - val_loss: 0.0347\n",
      "Epoch 245/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0353\n",
      "Epoch 246/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0346\n",
      "Epoch 247/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0349\n",
      "Epoch 248/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0303 - val_loss: 0.0348\n",
      "Epoch 249/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0302 - val_loss: 0.0351\n",
      "Epoch 250/250\n",
      "591/591 [==============================] - 1s 1ms/step - loss: 0.0304 - val_loss: 0.0349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff33d8377f0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=30,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "autoencoder2.fit(x = X2_train, y = y2_train, epochs = 250, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                 validation_data=(X2_test, y2_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = autoencoder2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "     X2, Y2, test_size=0.33, random_state=42)\n",
    "#pred = autoencoder2.predict(X2_train)\n",
    "#X2_train['pred'] = pred\n",
    "#X2_train['WHOQoL_11'] = 1\n",
    "#pred = autoencoder2.predict(X2_train.drop('pred',axis=1))\n",
    "#X2_train['cf'] = pred\n",
    "#len(X2_train[X2_train['cf']- X2_train['pred']>0.001])/len(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8819531 ],\n",
       "       [0.68613636],\n",
       "       [0.39792645],\n",
       "       [0.83069956],\n",
       "       [0.8648404 ]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91267     0.866667\n",
       "121226    0.700000\n",
       "98895     0.400000\n",
       "14001     0.800000\n",
       "14356     0.900000\n",
       "Name: WQOL.Psicologico, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8957977003920102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03490222726222862"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(r2_score(pred2,y2_test))\n",
    "mean_absolute_error(pred2,y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train2 = pd.DataFrame(autoencoder2.predict(X2_test))\n",
    "encoded_train2 = encoded_train2.add_prefix('feature_')\n",
    "encoded_train = pd.DataFrame(autoencoder.predict(X2_test))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_test = y_test.values - encoded_train['feature_0']\n",
    "error_test2 = y2_test.values - encoded_train2['feature_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train2 = pd.DataFrame(autoencoder2.predict(X2_train))\n",
    "encoded_train2 = encoded_train2.add_prefix('feature_')\n",
    "encoded_train = pd.DataFrame(autoencoder.predict(X2_train))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_train.values - encoded_train['feature_0']\n",
    "error2 = y2_train.values - encoded_train2['feature_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WHOQoL_6</th>\n",
       "      <th>WHOQoL_10</th>\n",
       "      <th>WHOQoL_14</th>\n",
       "      <th>WHOQoL_16</th>\n",
       "      <th>WHOQoL_18</th>\n",
       "      <th>WHOQoL_19</th>\n",
       "      <th>WHOQoL_20</th>\n",
       "      <th>WHOQoL_22</th>\n",
       "      <th>WHOQoL_25</th>\n",
       "      <th>WHOQoL_26</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_9</th>\n",
       "      <th>BSI_12</th>\n",
       "      <th>BSI_23</th>\n",
       "      <th>BSI_37</th>\n",
       "      <th>BSI_38</th>\n",
       "      <th>BSI_45</th>\n",
       "      <th>BSI_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119590</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159619</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163257</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16647</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114054</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WHOQoL_6  WHOQoL_10  WHOQoL_14  WHOQoL_16  WHOQoL_18  WHOQoL_19  \\\n",
       "119590       4.0        3.0        2.0        4.0        4.0        2.0   \n",
       "159619       5.0        4.0        3.0        4.0        5.0        5.0   \n",
       "163257       2.0        2.0        2.0        2.0        5.0        4.0   \n",
       "16647        4.0        3.0        3.0        4.0        4.0        4.0   \n",
       "114054       3.0        1.0        2.0        1.0        2.0        3.0   \n",
       "\n",
       "        WHOQoL_20  WHOQoL_22  WHOQoL_25  WHOQoL_26  BSI_1  BSI_9  BSI_12  \\\n",
       "119590        4.0        3.0        1.0        4.0    2.0    0.0     2.0   \n",
       "159619        5.0        5.0        5.0        5.0    0.0    0.0     0.0   \n",
       "163257        5.0        5.0        1.0        1.0    2.0    1.0     1.0   \n",
       "16647         4.0        4.0        1.0        4.0    1.0    0.0     0.0   \n",
       "114054        3.0        4.0        3.0        3.0    3.0    0.0     0.0   \n",
       "\n",
       "        BSI_23  BSI_37  BSI_38  BSI_45  BSI_49  \n",
       "119590     0.0     0.0     2.0     0.0     0.0  \n",
       "159619     0.0     0.0     0.0     0.0     0.0  \n",
       "163257     2.0     1.0     3.0     0.0     2.0  \n",
       "16647      0.0     0.0     1.0     0.0     0.0  \n",
       "114054     0.0     1.0     2.0     0.0     2.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/guilherme/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X2_train['error'] = error.values\n",
    "X2_test['error'] = error_test.values\n",
    "X2_train['y'] = y_train.values\n",
    "X2_test['y'] = y_test.values\n",
    "\n",
    "X2_train['error2'] = error2.values\n",
    "X2_test['error2'] = error_test2.values\n",
    "X2_train['y2'] = y2_train.values\n",
    "X2_test['y2'] = y2_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_encoder_train = X_train.merge(X2_train,left_index=True,right_index=True)\n",
    "#df_encoder_test = X_test.merge(X2_test,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.layers import Input, Dense, merge\n",
    "from keras.models import Model\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 1\n",
    "ncol = len(df_encoder_train.columns)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_dim = Input(shape = (ncol, ))\n",
    "input_dim2 = Input(shape = (ncol - 4, ))\n",
    "# Encoder Layers\n",
    "encoded1 = Dense(40, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(20, activation = 'relu')(encoded1)\n",
    "encoded5 = Dense(5, activation = 'relu')(encoded2)\n",
    "encoded13 = Dense(encoding_dim, activation = 'linear')(encoded5)\n",
    "merged = keras.layers.concatenate([encoded13, input_dim2], axis=-1)\n",
    "# Decoder Layers\n",
    "decoded1 = Dense(100, activation = 'relu')(merged)\n",
    "decoded2 = Dense(500, activation = 'relu')(decoded1)\n",
    "#drop = Dropout(0.05)(decoded2)\n",
    "decoded3 = Dense(500, activation = 'relu')(decoded2)\n",
    "decoded4 = Dense(250, activation = 'relu')(decoded3)\n",
    "decoded5 = Dense(50, activation = 'relu')(decoded4)\n",
    "#drop2 = Dropout(0.)(decoded4)\n",
    "#decoded5 = Dense(50, activation = 'tanh')(drop2)\n",
    "\n",
    "decoded13 = Dense(2, activation = 'sigmoid')(decoded4)\n",
    "\n",
    "# Combine Encoder and Deocder layers\n",
    "counter = Model(inputs = [input_dim, input_dim2], outputs = [decoded13])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr= 0.0001)\n",
    "# Compile the Model\n",
    "counter.compile(optimizer = 'adam', loss = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff34d5be908>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.load_weights('./models/psy_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0396 - val_loss: 0.0426\n",
      "Epoch 2/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0248 - val_loss: 0.0234\n",
      "Epoch 3/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0224 - val_loss: 0.0253\n",
      "Epoch 4/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 5/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0208 - val_loss: 0.0225\n",
      "Epoch 6/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0202 - val_loss: 0.0225\n",
      "Epoch 7/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 8/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0195 - val_loss: 0.0196\n",
      "Epoch 9/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0197 - val_loss: 0.0268\n",
      "Epoch 10/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0191 - val_loss: 0.0213\n",
      "Epoch 11/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0187 - val_loss: 0.0231\n",
      "Epoch 12/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0191 - val_loss: 0.0251\n",
      "Epoch 13/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0190 - val_loss: 0.0259\n",
      "Epoch 14/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0186 - val_loss: 0.0179\n",
      "Epoch 15/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0184 - val_loss: 0.0184\n",
      "Epoch 16/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0183 - val_loss: 0.0216\n",
      "Epoch 17/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0182 - val_loss: 0.0211\n",
      "Epoch 18/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0177 - val_loss: 0.0194\n",
      "Epoch 19/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0170 - val_loss: 0.0223\n",
      "Epoch 20/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0166 - val_loss: 0.0197\n",
      "Epoch 21/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0160 - val_loss: 0.0226\n",
      "Epoch 22/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0157 - val_loss: 0.0135\n",
      "Epoch 23/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0151 - val_loss: 0.0243\n",
      "Epoch 24/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0151 - val_loss: 0.0165\n",
      "Epoch 25/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0150 - val_loss: 0.0153\n",
      "Epoch 26/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 27/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0147 - val_loss: 0.0164\n",
      "Epoch 28/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0144 - val_loss: 0.0250\n",
      "Epoch 29/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0141 - val_loss: 0.0172\n",
      "Epoch 30/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0137 - val_loss: 0.0155\n",
      "Epoch 31/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0138 - val_loss: 0.0142\n",
      "Epoch 32/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0137 - val_loss: 0.0225\n",
      "Epoch 33/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0132 - val_loss: 0.0181\n",
      "Epoch 34/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0132 - val_loss: 0.0129\n",
      "Epoch 35/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 36/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 37/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 38/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 39/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 40/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 41/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0123 - val_loss: 0.0178\n",
      "Epoch 42/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 43/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 44/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0121 - val_loss: 0.0162\n",
      "Epoch 45/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0117 - val_loss: 0.0136\n",
      "Epoch 46/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 47/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 48/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0109 - val_loss: 0.0141\n",
      "Epoch 49/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0107 - val_loss: 0.0177\n",
      "Epoch 50/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0109 - val_loss: 0.0163\n",
      "Epoch 51/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0110 - val_loss: 0.0227\n",
      "Epoch 52/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 53/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 54/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 55/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0105 - val_loss: 0.0321\n",
      "Epoch 56/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 57/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 58/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 59/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0104 - val_loss: 0.0202\n",
      "Epoch 60/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 61/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 62/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 63/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 64/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0101 - val_loss: 0.0265\n",
      "Epoch 65/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 66/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 67/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 68/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 69/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0093 - val_loss: 0.0104\n",
      "Epoch 70/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 71/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0102 - val_loss: 0.0153\n",
      "Epoch 72/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 73/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0092 - val_loss: 0.0145\n",
      "Epoch 74/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0096 - val_loss: 0.0087\n",
      "Epoch 75/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0094 - val_loss: 0.0130\n",
      "Epoch 76/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0093 - val_loss: 0.0084\n",
      "Epoch 77/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 78/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0091 - val_loss: 0.0132\n",
      "Epoch 79/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 80/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0091 - val_loss: 0.0167\n",
      "Epoch 81/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0091 - val_loss: 0.0159\n",
      "Epoch 82/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 83/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 84/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0092 - val_loss: 0.0112\n",
      "Epoch 85/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 86/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0086 - val_loss: 0.0223\n",
      "Epoch 87/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0090 - val_loss: 0.0083\n",
      "Epoch 88/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 89/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 90/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0087 - val_loss: 0.0146\n",
      "Epoch 91/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0078\n",
      "Epoch 92/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0136\n",
      "Epoch 93/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 94/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0081\n",
      "Epoch 95/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 96/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0084\n",
      "Epoch 97/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 98/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0084 - val_loss: 0.0087\n",
      "Epoch 99/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0086 - val_loss: 0.0120\n",
      "Epoch 100/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0086 - val_loss: 0.0087\n",
      "Epoch 101/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0084 - val_loss: 0.0080\n",
      "Epoch 102/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 103/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 104/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0084 - val_loss: 0.0082\n",
      "Epoch 105/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0084 - val_loss: 0.0098\n",
      "Epoch 106/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0148\n",
      "Epoch 107/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0081 - val_loss: 0.0137\n",
      "Epoch 108/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 109/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0081 - val_loss: 0.0093\n",
      "Epoch 110/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 111/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0081 - val_loss: 0.0096\n",
      "Epoch 112/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 113/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 114/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 115/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0089\n",
      "Epoch 116/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 117/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 118/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0082 - val_loss: 0.0118\n",
      "Epoch 119/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0075\n",
      "Epoch 120/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0078 - val_loss: 0.0074\n",
      "Epoch 121/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 122/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0077 - val_loss: 0.0087\n",
      "Epoch 123/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0094\n",
      "Epoch 124/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 125/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0080 - val_loss: 0.0092\n",
      "Epoch 126/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 127/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 128/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0113\n",
      "Epoch 129/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 130/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0067\n",
      "Epoch 131/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 132/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0074 - val_loss: 0.0073\n",
      "Epoch 133/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0065\n",
      "Epoch 134/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0077 - val_loss: 0.0091\n",
      "Epoch 135/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0111\n",
      "Epoch 136/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 137/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0085\n",
      "Epoch 138/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0128\n",
      "Epoch 139/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 140/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0074 - val_loss: 0.0143\n",
      "Epoch 141/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 142/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0075 - val_loss: 0.0174\n",
      "Epoch 143/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0076 - val_loss: 0.0069\n",
      "Epoch 144/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 145/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0069\n",
      "Epoch 146/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 147/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 148/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 149/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 150/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0072 - val_loss: 0.0104\n",
      "Epoch 151/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0076 - val_loss: 0.0127\n",
      "Epoch 152/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0072 - val_loss: 0.0134\n",
      "Epoch 153/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0103\n",
      "Epoch 154/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 155/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 156/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 157/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0106\n",
      "Epoch 158/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 159/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 160/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0069 - val_loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 162/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0276\n",
      "Epoch 163/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0085 - val_loss: 0.0066\n",
      "Epoch 164/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 165/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0078 - val_loss: 0.0092\n",
      "Epoch 166/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0076 - val_loss: 0.0075\n",
      "Epoch 167/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0114\n",
      "Epoch 168/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0064\n",
      "Epoch 169/500\n",
      "591/591 [==============================] - 2s 4ms/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 170/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0072 - val_loss: 0.0124\n",
      "Epoch 171/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 172/500\n",
      "591/591 [==============================] - 2s 4ms/step - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 173/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0071 - val_loss: 0.0096\n",
      "Epoch 174/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0071 - val_loss: 0.0089\n",
      "Epoch 175/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0075 - val_loss: 0.0089\n",
      "Epoch 176/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0068 - val_loss: 0.0119\n",
      "Epoch 177/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0068 - val_loss: 0.0064\n",
      "Epoch 178/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0075 - val_loss: 0.0077\n",
      "Epoch 179/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0070 - val_loss: 0.0072\n",
      "Epoch 180/500\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 181/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0068 - val_loss: 0.0080\n",
      "Epoch 182/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 183/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0065\n",
      "Epoch 184/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 185/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0063 - val_loss: 0.0092\n",
      "Epoch 186/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 187/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0071\n",
      "Epoch 188/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0070 - val_loss: 0.0061\n",
      "Epoch 189/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0069 - val_loss: 0.0093\n",
      "Epoch 190/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0071 - val_loss: 0.0177\n",
      "Epoch 191/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 192/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0067\n",
      "Epoch 193/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 194/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0068\n",
      "Epoch 195/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0094\n",
      "Epoch 196/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 197/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 198/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0090\n",
      "Epoch 199/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 200/500\n",
      "591/591 [==============================] - 4s 7ms/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 201/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0067 - val_loss: 0.0096\n",
      "Epoch 202/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 203/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0074 - val_loss: 0.0066\n",
      "Epoch 204/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 205/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0069 - val_loss: 0.0098\n",
      "Epoch 206/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 207/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0060\n",
      "Epoch 208/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 209/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0123\n",
      "Epoch 210/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 211/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 212/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 213/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0116\n",
      "Epoch 214/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0126\n",
      "Epoch 215/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0080\n",
      "Epoch 216/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0058\n",
      "Epoch 217/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0061 - val_loss: 0.0095\n",
      "Epoch 218/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 219/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 220/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 221/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 222/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0065 - val_loss: 0.0098\n",
      "Epoch 223/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 224/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0062 - val_loss: 0.0059\n",
      "Epoch 225/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0063 - val_loss: 0.0069\n",
      "Epoch 226/500\n",
      "591/591 [==============================] - 4s 6ms/step - loss: 0.0059 - val_loss: 0.0082\n",
      "Epoch 227/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 228/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0061 - val_loss: 0.0113\n",
      "Epoch 229/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0397\n",
      "Epoch 230/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 231/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0094 - val_loss: 0.0146\n",
      "Epoch 232/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 233/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0092 - val_loss: 0.0085\n",
      "Epoch 234/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0087 - val_loss: 0.0085\n",
      "Epoch 235/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 236/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 237/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0099\n",
      "Epoch 238/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 239/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 240/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 241/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 242/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0083 - val_loss: 0.0149\n",
      "Epoch 243/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0082 - val_loss: 0.0093\n",
      "Epoch 244/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 245/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0083 - val_loss: 0.0114\n",
      "Epoch 246/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 247/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 248/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 249/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 250/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 251/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 252/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0081 - val_loss: 0.0086\n",
      "Epoch 253/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 254/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 255/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 256/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0079 - val_loss: 0.0086\n",
      "Epoch 257/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0077 - val_loss: 0.0134\n",
      "Epoch 258/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 259/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0078 - val_loss: 0.0096\n",
      "Epoch 260/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0073 - val_loss: 0.0120\n",
      "Epoch 261/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 262/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 263/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0071 - val_loss: 0.0102\n",
      "Epoch 264/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0090\n",
      "Epoch 265/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0072 - val_loss: 0.0124\n",
      "Epoch 266/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0073 - val_loss: 0.0075\n",
      "Epoch 267/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 268/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 269/500\n",
      "591/591 [==============================] - 2s 4ms/step - loss: 0.0069 - val_loss: 0.0099\n",
      "Epoch 270/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0070 - val_loss: 0.0074\n",
      "Epoch 271/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0069 - val_loss: 0.0076\n",
      "Epoch 272/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 273/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0071 - val_loss: 0.0081\n",
      "Epoch 274/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 275/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0070 - val_loss: 0.0068\n",
      "Epoch 276/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0067 - val_loss: 0.0087\n",
      "Epoch 277/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0118\n",
      "Epoch 278/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Epoch 279/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0070\n",
      "Epoch 280/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 281/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0069 - val_loss: 0.0103\n",
      "Epoch 282/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 283/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 284/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 285/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 286/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 287/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 288/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0068 - val_loss: 0.0073\n",
      "Epoch 289/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 290/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0064 - val_loss: 0.0136\n",
      "Epoch 291/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0063 - val_loss: 0.0101\n",
      "Epoch 292/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 293/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0341\n",
      "Epoch 294/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 295/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 296/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 297/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 298/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 299/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0061 - val_loss: 0.0072\n",
      "Epoch 300/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 301/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 302/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 303/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 304/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - val_loss: 0.0067\n",
      "Epoch 305/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 306/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0110\n",
      "Epoch 307/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 308/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0096\n",
      "Epoch 309/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0115\n",
      "Epoch 310/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - val_loss: 0.0086\n",
      "Epoch 311/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 312/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - val_loss: 0.0087\n",
      "Epoch 313/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 314/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 315/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 316/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 317/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 318/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 320/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 321/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0106\n",
      "Epoch 322/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0106\n",
      "Epoch 323/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0089\n",
      "Epoch 324/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0079\n",
      "Epoch 325/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 326/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 327/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 328/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 329/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 330/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0068\n",
      "Epoch 331/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 332/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0123\n",
      "Epoch 333/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0094\n",
      "Epoch 334/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0057 - val_loss: 0.0086\n",
      "Epoch 335/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0059\n",
      "Epoch 336/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 337/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0073\n",
      "Epoch 338/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 339/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0062\n",
      "Epoch 340/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0059\n",
      "Epoch 341/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 342/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 343/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 344/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0167\n",
      "Epoch 345/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 346/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0099\n",
      "Epoch 347/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 348/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0077\n",
      "Epoch 349/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 350/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 351/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 352/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 353/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 354/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 355/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 356/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 357/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 358/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 359/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0089\n",
      "Epoch 360/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 361/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 362/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 363/500\n",
      "591/591 [==============================] - 2s 4ms/step - loss: 0.0051 - val_loss: 0.0067\n",
      "Epoch 364/500\n",
      "591/591 [==============================] - 2s 4ms/step - loss: 0.0049 - val_loss: 0.0086\n",
      "Epoch 365/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 366/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 367/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0050 - val_loss: 0.0049\n",
      "Epoch 368/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 369/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 370/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 371/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 372/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 373/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 374/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 375/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0065\n",
      "Epoch 376/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 377/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 378/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0128\n",
      "Epoch 379/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 380/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Epoch 381/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0085\n",
      "Epoch 382/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 383/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0061\n",
      "Epoch 384/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0123\n",
      "Epoch 385/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 386/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 387/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0079\n",
      "Epoch 388/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0148\n",
      "Epoch 389/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0082\n",
      "Epoch 390/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 391/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 392/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 393/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 394/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 395/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 396/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 397/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 398/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0056 - val_loss: 0.0076\n",
      "Epoch 399/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 400/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 401/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 402/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 403/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 404/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 405/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0052 - val_loss: 0.0054\n",
      "Epoch 406/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 407/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 408/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 409/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 410/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 411/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0081\n",
      "Epoch 412/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 413/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0054\n",
      "Epoch 414/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0055\n",
      "Epoch 415/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 416/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 417/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0064\n",
      "Epoch 418/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 419/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0052\n",
      "Epoch 420/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0053\n",
      "Epoch 421/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 422/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 423/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 424/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0113\n",
      "Epoch 425/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0051 - val_loss: 0.0068\n",
      "Epoch 426/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 427/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 428/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0061\n",
      "Epoch 429/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 430/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 431/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 432/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 433/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 434/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 435/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 436/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0073\n",
      "Epoch 437/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 438/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0067\n",
      "Epoch 439/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 440/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 441/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0055 - val_loss: 0.0065\n",
      "Epoch 442/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0080\n",
      "Epoch 443/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0077\n",
      "Epoch 444/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 445/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0048 - val_loss: 0.0125\n",
      "Epoch 446/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0077\n",
      "Epoch 447/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0113\n",
      "Epoch 448/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0043 - val_loss: 0.0139\n",
      "Epoch 449/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 450/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 451/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0077\n",
      "Epoch 452/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 453/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 454/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 455/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 456/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 457/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 458/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 459/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0056\n",
      "Epoch 460/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 461/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 462/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 463/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0074\n",
      "Epoch 464/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 465/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 466/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0115\n",
      "Epoch 467/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0120\n",
      "Epoch 468/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 469/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 470/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 471/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 472/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 473/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0071\n",
      "Epoch 474/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0114\n",
      "Epoch 475/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 476/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0079\n",
      "Epoch 477/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 478/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 479/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0043 - val_loss: 0.0057\n",
      "Epoch 480/500\n",
      "591/591 [==============================] - 3s 4ms/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Epoch 481/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 482/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 483/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0078\n",
      "Epoch 484/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 485/500\n",
      "591/591 [==============================] - 3s 6ms/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 486/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 487/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 488/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 489/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0045 - val_loss: 0.0061\n",
      "Epoch 490/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 491/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 492/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 493/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 494/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 495/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0041 - val_loss: 0.0078\n",
      "Epoch 496/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 497/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0042 - val_loss: 0.0082\n",
      "Epoch 498/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 499/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0041 - val_loss: 0.0055\n",
      "Epoch 500/500\n",
      "591/591 [==============================] - 3s 5ms/step - loss: 0.0044 - val_loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8824e670b8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=1000,\n",
    "                              verbose=0, mode='auto',\n",
    "                                  restore_best_weights=True)\n",
    "\n",
    "\n",
    "callbacks = [es]\n",
    "counter.fit(x = [df_encoder_train, df_features_train], y = df_outs_train, epochs = 500, \n",
    "                batch_size = 128, shuffle = True,\n",
    "                validation_data=([df_encoder_test,df_features_test],df_outs_test),\n",
    "               #callbacks = callbacks\n",
    "                \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter.save('./models/psy_model2')\n",
    "#counter.save_weights('./models/psy_weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test = pd.DataFrame(counter.predict([df_encoder_test,df_features_test]))\n",
    "encoded_test = encoded_test.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7756     1.071522e-01\n",
       "17964    4.469583e-08\n",
       "35923    3.904400e-12\n",
       "1307     2.852375e-01\n",
       "27968    7.137644e-02\n",
       "Name: feature_0, dtype: float32"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(encoded_test['feature_0']).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0005193339671170955, 0.009472540076274594)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(encoded_test['feature_0'], df_outs_test['y']), mean_absolute_error(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.7984110104043285e-06, 0.0004960997369701326)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(encoded_test['feature_0'], df_outs_test['y']), mean_squared_error(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9997969195209235, 0.9748728266748627)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(encoded_test['feature_0'], df_outs_test['y']), r2_score(encoded_test['feature_1'], df_outs_test['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0004524605091689878, 0.007130854030000341)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(encoded_train['feature_0'], df_outs_train['y']), mean_absolute_error(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.15246409332044e-06, 0.00024244622498621732)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(encoded_train['feature_0'], df_outs_train['y']), mean_squared_error(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998838598861778, 0.9877326340480836)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(encoded_train['feature_0'], df_outs_train['y']), r2_score(encoded_train['feature_1'], df_outs_train['y2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ind = 59\n",
    "encoded_train.iloc[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_print = []#list(data.columns)[42:141]\n",
    "#new_feat_print += [\n",
    "#    'WHOQoL_8', 'WHOQoL_9',\n",
    "#    'WHOQoL_12','WHOQoL_14', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', \n",
    "#             'BSI_9', 'BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "#            ]\n",
    "m=2\n",
    "val =4\n",
    "equal_limit = 0.01\n",
    "        \n",
    "\n",
    "if m == 1:\n",
    "    new_feat_print = [\n",
    "           \n",
    "           'WHOQoL_6', 'WHOQoL_10', 'WHOQoL_14', 'WHOQoL_16', 'WHOQoL_18', 'WHOQoL_19', \n",
    "    'WHOQoL_20', 'WHOQoL_22', 'WHOQoL_25', 'WHOQoL_26',          \n",
    "    #'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]\n",
    "if m==2:\n",
    "    new_feat_print = [\n",
    "    \n",
    "    'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3373\n",
      "586\n",
      "1494\n",
      "980\n",
      "805\n",
      "5006\n",
      "863\n",
      "774\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    print(len(df_encoder_train))\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0030961002598031955\n",
      "0.012107545067719029\n",
      "0.009542311867893264\n",
      "0.044447324089672155\n",
      "0.02729989387253533\n",
      "0.0012821396567174468\n",
      "0.06344242457204237\n",
      "0.04193103824689236\n",
      "0.05765919621484665\n",
      "0.0022033757379230066\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    print (pup)\n",
    "    #print (pdo)\n",
    "    #print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011087550067218272\n",
      "8.00640512409928e-05\n",
      "0.0002026150853684893\n",
      "5.365814396480026e-05\n",
      "6.69155926714043e-05\n",
      "7.090187180941577e-05\n",
      "5.357405944041895e-05\n",
      "0.00020066352739726026\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    #print (pup)\n",
    "    print (pdo)\n",
    "    #print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258284478815849\n",
      "0.2601281024819856\n",
      "0.6285119948130539\n",
      "0.004520698629034422\n",
      "0.001311545616359524\n",
      "0.8777651730005672\n",
      "0.17313796659657393\n",
      "0.4989699272260274\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat_print:\n",
    "    #print(feata)\n",
    "    value = val\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0']\n",
    "    f1_a = encoded_train['feature_1']\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0']\n",
    "    f1_d = encoded_train['feature_1']\n",
    "    if m ==2:\n",
    "        f0r = f0_d - f0_a \n",
    "    if m ==1:\n",
    "        f0r = f1_d - f1_a \n",
    "    pup = len(f0r[f0r>equal_limit])/len(f0r)\n",
    "    pdo = len(f0r[f0r<-equal_limit])/len(f0r)\n",
    "    peq = len(f0r[abs(f0r)<equal_limit])/len(f0r)\n",
    "    \n",
    "    #print (pup)\n",
    "    #print (pdo)\n",
    "    print (peq)\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "    \n",
    "#feata = 'BSI_17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7303730249404907 0.6973024010658264 BSI_9\n",
      "0.7303730249404907 0.6970582604408264 BSI_12\n",
      "0.7303730249404907 0.7063497304916382 BSI_37\n",
      "0.7303730249404907 0.6995754241943359 BSI_45\n",
      "0.7303730249404907 0.6789579391479492 BSI_49\n"
     ]
    }
   ],
   "source": [
    "for feata in new_feat:\n",
    "    #print(feata)\n",
    "    value = 5\n",
    "    df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "    df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_a = encoded_train['feature_0'].median()\n",
    "    f1_a = encoded_train['feature_1'].median()\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_features_train[feata] = value\n",
    "    counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "    encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "    encoded_train = encoded_train.add_prefix('feature_')\n",
    "    f0_d = encoded_train['feature_0'].median()\n",
    "    f1_d = encoded_train['feature_1'].median()\n",
    "    if f1_a> f1_d:\n",
    "        print(f1_a,f1_d,feata)\n",
    "    #print(encoded_train['feature_0'].median())\n",
    "    #print(encoded_train['feature_1'].median())\n",
    "    df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "    df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "    df_outs_train = df_encoder_train[['y','y2']]\n",
    "    df_outs_test = df_encoder_test[['y','y2']]\n",
    "    df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "    df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "#feata = 'BSI_17'\n",
    "#feata = 'BSI_46'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-78-eaadf95b78a1>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-78-eaadf95b78a1>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    'WHOQoL_17', 'WHOQoL_10',\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "'WHOQoL_1','WHOQoL_6','WHOQoL_9','WHOQoL_14','WHOQoL_19', 'WHOQoL_23',\n",
    "             'WHOQoL_17', 'WHOQoL_10',\n",
    "             'BSI_9', 'BSI_49', 'BSI_45','BSI_38','BSI_12', 'BSI_37', 'BSI_23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_features_train[feata] = 1\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train[feata] = 5\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "encoded_train['feature_0'].median(),encoded_train['feature_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X2_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a34bba2cf7cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_encoder_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX2_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.merge(X2_train,left_index=True,right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_encoder_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX2_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.merge(X2_test,left_index=True,right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_outs_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_encoder_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_outs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_encoder_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_encoder_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'error2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'y2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X2_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "\n",
    "feata = 'WHOQoL_17'\n",
    "value = 1\n",
    "idn = 851\n",
    "#df_features_train = df_features_train[df_features_train[feata] != value]\n",
    "#df_encoder_train = df_encoder_train[df_encoder_train[feata]!=value]\n",
    "    \n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "#print(encoded_train['feature_0'].iloc[idn])\n",
    "#print(encoded_train['feature_1'].iloc[idn])\n",
    "df_features_train[feata] = value\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "print(encoded_train['feature_0'].iloc[idn])\n",
    "print(encoded_train['feature_1'].iloc[idn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f6d00c84fa13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_encoder_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_features_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mencoded_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_prefix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mencoded_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_outs_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "encoded_train = encoded_train.add_prefix('feature_')\n",
    "np.mean(encoded_train['feature_0']), np.mean(encoded_train['feature_1'])\n",
    "encoded_train.index = df_outs_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WHOQoL_6</th>\n",
       "      <th>WHOQoL_10</th>\n",
       "      <th>WHOQoL_14</th>\n",
       "      <th>WHOQoL_16</th>\n",
       "      <th>WHOQoL_18</th>\n",
       "      <th>WHOQoL_19</th>\n",
       "      <th>WHOQoL_20</th>\n",
       "      <th>WHOQoL_22</th>\n",
       "      <th>WHOQoL_25</th>\n",
       "      <th>WHOQoL_26</th>\n",
       "      <th>BSI_1</th>\n",
       "      <th>BSI_9</th>\n",
       "      <th>BSI_12</th>\n",
       "      <th>BSI_23</th>\n",
       "      <th>BSI_37</th>\n",
       "      <th>BSI_38</th>\n",
       "      <th>BSI_45</th>\n",
       "      <th>BSI_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149614</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111765</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WHOQoL_6  WHOQoL_10  WHOQoL_14  WHOQoL_16  WHOQoL_18  WHOQoL_19  \\\n",
       "149614       4.0        4.0        3.0        2.0        3.0        3.0   \n",
       "111765       4.0        4.0        3.0        2.0        3.0        3.0   \n",
       "\n",
       "        WHOQoL_20  WHOQoL_22  WHOQoL_25  WHOQoL_26  BSI_1  BSI_9  BSI_12  \\\n",
       "149614        3.0        2.0        3.0        4.0    2.0    0.0     0.0   \n",
       "111765        3.0        2.0        3.0        4.0    2.0    0.0     0.0   \n",
       "\n",
       "        BSI_23  BSI_37  BSI_38  BSI_45  BSI_49  \n",
       "149614     0.0     0.0     1.0     0.0     0.0  \n",
       "111765     0.0     0.0     1.0     0.0     0.0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#41,20476\n",
    "l = 0 \n",
    "for ii in df_features_train.index:\n",
    "    eq = df_features_train[df_features_train.eq(df_features_train.loc[ii],axis=1).sum(axis = 1)==len(df_features_train.columns)]\n",
    "    if len(eq) >1:\n",
    "        if np.any(df_outs_train.loc[eq.index]['y2']<0.7):\n",
    "            break\n",
    "        l+=1\n",
    "eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149614</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111765</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               y        y2\n",
       "149614  0.071429  0.633333\n",
       "111765  0.035714  0.733333"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outs_train.loc[eq.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "idn = 149614\n",
    "idn2 = 111765\n",
    "idn3 = 33390\n",
    "idn4 = 40435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti =idn\n",
    "#df_encoder_train.iloc[ti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07142857142857142 0.6333333333333333\n",
      "0.03571428571428571 0.7333333333333333\n",
      "0.0 0.9\n",
      "0.0 0.9\n"
     ]
    }
   ],
   "source": [
    "print(df_outs_train['y'].loc[idn],df_outs_train['y2'].loc[idn])\n",
    "print(df_outs_train['y'].loc[idn2],df_outs_train['y2'].loc[idn2])\n",
    "print(df_outs_train['y'].loc[idn3],df_outs_train['y2'].loc[idn3])\n",
    "print(df_outs_train['y'].loc[idn4],df_outs_train['y2'].loc[idn4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_train[encoded_train['feature_0']>0.7].sample(5)\n",
    "encoded_train.index = df_outs_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.071210325 0.035495102 1.9719728e-07 1.9719691e-07\n",
      "0.6293038 0.72952807 0.897729 0.897729\n"
     ]
    }
   ],
   "source": [
    "print(encoded_train['feature_0'].loc[idn],encoded_train['feature_0'].loc[idn2],encoded_train['feature_0'].loc[idn3],encoded_train['feature_0'].loc[idn4])\n",
    "print(encoded_train['feature_1'].loc[idn],encoded_train['feature_1'].loc[idn2],encoded_train['feature_1'].loc[idn3],encoded_train['feature_1'].loc[idn4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_print = []#list(data.columns)[42:141]\n",
    "#new_feat_print += [\n",
    "#    'WHOQoL_8', 'WHOQoL_9',\n",
    "#    'WHOQoL_12','WHOQoL_14', 'WHOQoL_23', 'WHOQoL_24', 'WHOQoL_25', \n",
    "#             'BSI_9', 'BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "#            ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "ind = idn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m == 1:\n",
    "    all_values = [0,1,2,3,4]\n",
    "    new_feat_print = [\n",
    "        \n",
    "        'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "                ]\n",
    "if m == 2:\n",
    "    all_values = [1,2,3,4,5]\n",
    "    new_feat_print = [\n",
    "           'WHOQoL_6', 'WHOQoL_10', 'WHOQoL_14', 'WHOQoL_16', 'WHOQoL_18', 'WHOQoL_19', \n",
    "    'WHOQoL_20', 'WHOQoL_22', 'WHOQoL_25', 'WHOQoL_26',              \n",
    "    #'BSI_1',  'BSI_9','BSI_12', 'BSI_23','BSI_37','BSI_38', 'BSI_45','BSI_49'\n",
    "    \n",
    "            ]\n",
    "#all_values = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.035434723\n",
      "0.035495102\n",
      "0.035495102\n",
      "0.035495102\n",
      "0.035495102\n",
      "0.035451114\n",
      "0.035495102\n",
      "0.035495102\n",
      "1\n",
      "0.035408825\n",
      "0.03565982\n",
      "0.035583198\n",
      "0.07100424\n",
      "0.07110381\n",
      "0.035495102\n",
      "0.0356839\n",
      "0.03560567\n",
      "2\n",
      "0.035495102\n",
      "0.03557512\n",
      "0.035669833\n",
      "0.07150975\n",
      "0.0713945\n",
      "0.03556344\n",
      "0.035490394\n",
      "0.03566426\n",
      "3\n",
      "0.035607487\n",
      "0.071177274\n",
      "0.03566736\n",
      "0.072625756\n",
      "0.107997835\n",
      "0.03565523\n",
      "0.071181834\n",
      "0.044402152\n",
      "4\n",
      "0.035672814\n",
      "0.07129884\n",
      "0.071279556\n",
      "0.10701656\n",
      "0.106978625\n",
      "0.035570443\n",
      "0.071294725\n",
      "0.07124144\n"
     ]
    }
   ],
   "source": [
    "for c_value in all_values:\n",
    "    print(c_value)\n",
    "    for feata in new_feat_print:\n",
    "        df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "        df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "        df_outs_train = df_encoder_train[['y','y2']]\n",
    "        df_outs_test = df_encoder_test[['y','y2']]\n",
    "        df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "        df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)\n",
    "        df_features_train[feata] = c_value\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        #counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "        counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "        encoded_input = Input(shape = (encoding_dim, ))\n",
    "        encoded_train = pd.DataFrame(counter.predict([df_encoder_train,df_features_train]))\n",
    "        encoded_train = encoded_train.add_prefix('feature_')\n",
    "        encoded_train.index = df_outs_train.index\n",
    "        if m == 1:\n",
    "            print(encoded_train['feature_0'].loc[[ind]].values[0])\n",
    "        if m == 2:\n",
    "            print(encoded_train['feature_1'].loc[[ind]].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train.iloc[idn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder_train = X2_train.copy()#.merge(X2_train,left_index=True,right_index=True)\n",
    "df_encoder_test = X2_test.copy()#.merge(X2_test,left_index=True,right_index=True)\n",
    "df_outs_train = df_encoder_train[['y','y2']]\n",
    "df_outs_test = df_encoder_test[['y','y2']]\n",
    "df_features_train = df_encoder_train.drop(['error','error2','y','y2'], axis = 1)\n",
    "df_features_test = df_encoder_test.drop(['error','error2','y','y2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feata = 'BSI_10'\n",
    "\n",
    "df_features_test[feata] = 1\n",
    "\n",
    "#counter = Model(inputs = [input_dim,input_dim2], outputs = encoded13)\n",
    "counter = Model(inputs = [input_dim,input_dim2], outputs = decoded13)\n",
    "encoded_input = Input(shape = (encoding_dim, ))\n",
    "encoded_test = pd.DataFrame(counter.predict([df_encoder_test,df_features_test]))\n",
    "encoded_test = encoded_test.add_prefix('feature_')\n",
    "encoded_test['feature_1'].iloc[[ind]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1143   -0.251098\n",
    "1432   -0.050221\n",
    "774     0.472253\n",
    "863     2.349966\n",
    "380    -0.142225\n",
    "Name: feature_0, dtype: float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['BSI_23','BSI_36','BSI_20','BSI_17','BSI_38','BSI_46','BSI_31','BSI_10','BSI_53',\n",
    "             'WHOQoL_16','WHOQoL_17','WHOQoL_18','WHOQoL_19','WHOQoL_20','WHOQoL_21','WHOQoL_22',\n",
    "            'WHOQoL_23','WHOQoL_24','WHOQoL_25','WHOQoL_26']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
